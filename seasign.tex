\documentclass{llncs}

%\usepackage{amsmath,amssymb}
\usepackage{amsmath,amssymb,fullpage}
\usepackage{times}
\usepackage{algorithm,algorithmicx,algpseudocode}
\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{pdflscape}
\usepackage{fp}
\usepackage{tikz}
\usepgflibrary{fpu,fixedpointarithmetic}

\usepackage{hyperref}
\hypersetup{
	unicode=true,
	colorlinks=true,
	citecolor=blue!70!black,
	filecolor=black,
	linkcolor=red!70!black,
	urlcolor=blue,
	pdfstartview={FitH},
}

%\renewcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Fpbar}{\overline{\mathbb{F}}_p}
\newcommand{\Fqbar}{\overline{\mathbb{F}}_q}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\OO}{\mathcal{O}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
%\newcommand{\ch}{\text{ch}}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Cl}{Cl}
\newcommand{\seed}{\mathsf{seed}}
\newcommand{\msg}{\mathsf{msg}}
\newcommand{\PK}{\mathsf{PK}}
\newcommand{\SK}{\mathsf{SK}}

\renewcommand{\a}{\mathfrak{a}}
\renewcommand{\b}{\mathfrak{b}}
\let\cedil\c
\renewcommand{\c}{\mathfrak{c}}
\renewcommand{\l}{\mathfrak{l}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\f}{\mathbf{f}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\z}{\mathbf{z}}

\DeclareMathOperator{\Adv}{Adv}

\newcommand{\KeyGen}{\mathsf{KeyGen}}
\newcommand{\Sign}{\mathsf{Sign}}
\newcommand{\Verify}{\mathsf{Verify}}
\newcommand{\IGen}{\mathsf{IGen}}
\newcommand{\PP}{\mathsf{P}}
\newcommand{\VV}{\mathsf{V}}
\newcommand{\Wset}{\mathcal{W}}
\newcommand{\Zset}{\mathcal{Z}}
\newcommand{\ChSet}{\textsf{ChSet}}
\newcommand{\St}{\textsf{St}}
\newcommand{\LossIGen}{\mathsf{LossIGen}}
\newcommand{\PRF}{\mathsf{PRF}}
\newcommand{\PRFk}{\PRF_{\mathrm{key}}}
\newcommand{\PRFm}{\PRF_{\mathrm{mask}}}
\newcommand{\PRFs}{\PRF_{\mathrm{secret}}}

% THEOREM ENVIRONMENTS
%\newtheorem{definition}{Definition}
%\newtheorem{example}{Example}
%\newtheorem{theorem}{Theorem}



\title{SeaSign: Compact isogeny signatures from class group actions}

\author{Luca De Feo \and Steven D. Galbraith}
\institute{Mathematics Department, University of Auckland, NZ.
\email{s.galbraith@auckland.ac.nz}
\and
Paris, France.
\email{luca.de-feo@uvsq.fr}}



\date{\today}


\begin{document}
\pagestyle{plain}

\maketitle


\begin{abstract}
We give a new signature scheme for isogenies that combines the class group actions of CSIDH with the notion of Fiat-Shamir with aborts.

This is a draft paper that is work-in-progress. Please do not distribute. Contents will change.
\end{abstract}



\section{Intro}

Stolbunov~\cite{Sto12} was the first to sketch a signature scheme based on isogeny problems.
Stolbunov's scheme was in the framework of class group actions.
However his scheme leaked the private key.
Due to renewed interest in class group actions, especially CSIDH~\cite{CLMPR18} (due to Castryck, Lange, Martindale, Panny and Renes) and the scheme by De Feo, Kieffer and Smith~\cite{DFKS18}, it is of interest to develop a secure signature scheme in this setting.
Our main contribution is to use Lyubashevsky's ``Fiat-Shamir with aborts'' strategy to obtain a secure signature scheme.




Currently it is a major problem to get practical signatures from isogeny problems.
Yoo et al (see Table~1 of~\cite{YAJJS17}) state signatures of over 100 kilobytes.
This can be reduced using some optimisations. For example~\cite{GPS17} state approximately 12 kilobytes for their signature scheme (for classical 128-bit security level).
In contrast, in this paper we should be able to get signatures smaller than a kilobyte, which is better even than lattice signatures.
Unfortunately, signing and verification are very slow, but we might just about be able to live with that in certain applications.


The paper is organised as follows.
Section~\ref{sec:basic-scheme} gives the basic signature scheme concept, that was proposed by Stolbunov, and our secure variant based on Fiat-Shamir with aborts.
Section~\ref{sec:smaller-sigs} explains how to get shorter signatures, at the expense of public key size, by using challenges that are more than just a single bit.
Section~\ref{sec:smaller-keys} shows how to retain the benefit of shorter signatures, while also having a short public key, by using modified Merkle trees.
In Appendix~\ref{sec:lossy-keys} we show how to use our scheme in the context of lossy keys, from which we obtain tight security in the quantum random oracle model via the results of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18} (and this security enhancement involves no increase in signature size, though the primes are larger so computations will be somewhat slower).


The name: The name ``SeaSign'' is a reference to the name CSIDH, which is pronounced ``sea-side''.




\section{Background}

\subsection{Elliptic curves, isogenies, ideal class groups, class group actions}

We recall some standard facts and fix our notation.

\begin{itemize}
\item For $B \in \N$ we use the notation $[-B,B]$ for the set of integers $u$ with $-B \le u \le B$.
\item We use the symbol $\log$ for the logarithm in base $2$.

\item For an elliptic curve $E$ over a field $K$ we define $\End(E)$ to be the the ring of endomorphisms of $E$ defined over the algebraic closure of $K$, and $\End_K(E)$ to be the the ring of endomorphisms defined over $K$.
\item Given two $\OO$-ideals $\a, \b$ we write $\a \equiv \b$ if $\a$ and $\b$ are equivalent (meaning that $\a \b^{-1}$ is a principal fractional $\OO$-ideal). 
\end{itemize}


Let $p$ be a prime.
Let $E$ be an ordinary elliptic curve over $\F_p$ with $\End(E) \cong \OO$ or $E$ a supersingular curve over $\F_p$ with $\End_{\F_p}(E) \cong \OO$ where $\OO$ is an order in an imaginary quadratic field.
Let $\Cl(\OO )$ be the ideal class group of $\OO$.
One can define the action of an $\OO$-ideal $\a$ on the curve $E$ as the image curve $E'$ under the isogeny $\phi : E \to E'$ whose kernel is equal to the subgroup $E[ \a ] = \{ P \in E( \Fpbar ) : \alpha(P) = 0 \; \forall \alpha \in \a \}$.
We denote $E'$ by $\a * E$.

The set $\{ j(E) \}$ of isomorphism classes of elliptic curves with $\End(E) \cong \OO$ is a principal homogenous space for $\Cl(\OO )$.
General references for all this are Couveignes~\cite{Couv06}
and Stolbunov~\cite{Sto12}.
The key exchange protocol proposed by Couveignes and Stolbunov is for Alice to send $\a * E$ to Bob and Bob to send $\b * E$ to Alice; the shared key is $(\a\b) * E$.

Given a generic ideal $\a\subset\OO$, there is an algorithm to compute $\a*E$ has subexponential complexity in $\log(\#\Cl(\OO))$~\cite{JS10,biasse_fieker_jacobson_2016}.
To make this action efficient one must work instead with ideals $\a = \prod_{i=1}^n \l_i^{e_i}$ where $\l_1, \dots, \l_n$ are prime $\OO$-ideals of small norm $\ell_i$ and where $(e_1, \dots, e_n)$ is an appropriately chosen vector of exponents.
Then, the action of $\a$ can be computed as a composition of isogenies of degree $\ell_i$.
Throughout the paper we assume that $\{ \l_1, \dots, \l_n \}$ is a set of non-principal prime ideals in $\OO$, generating $\Cl(\OO)$, of norm polynomial in the size of the class group.
Theoretically we have the bounds $\#\Cl(\OO) = O( \sqrt{p} \log(p) )$ and, assuming a generalised Riemann hypothesis, $\ell_i = O( \log(p)^2 )$.
% NdL: Is #Cl(O) = O(..) really what we want to say? â‰ˆ seems more appropriate
In practice one usually takes $\ell_i=O(\log(p))$ for efficiency reasons; heuristically, this is more than enough to generate the class group.

The basic computational assumption is the ideal action problem.
Stolbunov called it ``Group Action Inverse Problem (GAIP)''.
The CSIDH paper speaks of hard homogenous spaces and calls the below problem ``Key recovery''.

\begin{definition}\label{defn:ass1}
% (GAIP ?? ClAP (Cl Action Problem) ??)
Given two elliptic curves $E$ and $E_A$ over the same field with $\End(E) = \End(E_A) = \OO$. Find an ideal $\a$ such that $j( E_A ) = j( \a * E )$.
\end{definition}

The best classical algorithms for this problem have exponential time, but there are subexponential-time quantum algorithms for it~\cite{Kup,regev04,childs2014constructing,Kuperberg2013,BS18,BIJ18}
(Expand: Kuperberg, Regev, Childs-Jao-Soukharev~\cite{childs2014constructing}, Biasse-Iezzi-Jacobson~\cite{BIJ18}, Bonnetain-Schrottenloher~\cite{BS18}, Jao-LeGrow-Leonardi-Ruiz-Lopez (MathCrypt 2018)).

Note that this problem admits a random self-reduction: given an instance $(E, E_A)$ one can choose random ideal classes $\b_1, \b_2$ and construct the instance $(E_1, E_2) = (\b_1 * E, \b_2 * E_A )$, which is now uniformly distributed across the set of pairs of isomorphism classes of curves in the isogeny class.
If $\a'$ is a solution to the instance $(E_1, E_2)$ then any ideal equivalent to the fractional ideal $\a'\b_1 \b_2^{-1}$ is a solution to the original instance.

When instantiating the group action in practice, one must choose parameters that make evaluating isogenies of degree $\ell_i$ as efficient as possible.
In the ordinary case, De Feo, Kieffer and Smith~\cite{DFKS18} introduced a method to use the more efficient V\'elu's formulas~\cite{velu71} for some primes $\ell_i$, but were unable to generalize it for sufficiently many.
By using supersingular curves over a field $\F_p$ with $p+1 = 4\prod_{i=1}^n\ell_i$, CSIDH~\cite{CLMPR18} manages to apply V\'elu's formulas to all primes $\ell_i$.
For key exchange, CSIDH samples the exponent vectors $\e = (e_1, \dots, e_n) \in [-B,B]^n \subseteq \Z^n$ for a suitable constant $B$.
% such that $(2B+1)^n\ge\#\Cl(\OO)\approx p\log p$; this ensures that, heuristically, the key space covers all of $\Cl(\OO)$.



An issue that arises in our security arguments is whether or not we are sampling ideal classes uniformly during key generation and signing (for precise details see Definition~\ref{defn:sampling-distributions} and the discussion that follows it).

Recall there is a straightforward meet-in-the-middle attack when given $E$ and $\a * E$ for $\a = \prod_{i=1}^n \l_i^{e_i}$ over $e_i \in [-B, B]$.
We compute lists (assume $n$ is even)
\[
   L_1 = \left\{ \left( \prod_{i=1}^{n/2} \l_i^{e_i} \right) * E : e_i \in [-B,B] \right\} \text{ \ \  and \ \  }
   L_2 = \left\{ \left( \prod_{i=n/2 + 1}^{n} \l_i^{e_i} \right) * E_A : e_i \in [-B,B] \right\}.
\]
If $L_1 \cap L_2 \ne \varnothing$ then we have solved the isogeny problem.
This attack can be used even when the set of ideal classes generated is a small subset of $\Cl( \OO )$.
Hence for security we require $(2B+1)^n > 2^{2 \lambda}$, where $\lambda$ is the security parameter.
Further, there is a quantum algorithm due to Tani, which is straightforward to adapt to this problem (we refer to Section~5.2 of  De Feo, Jao and Pl{\^{u}}t~\cite{FJP14} for details).
This means we might need to take $(2B+1)^n > 2^{3 \lambda}$ to have post-quantum security.

Note that Kuperberg's algorithm uses the entire class group, and so there seems to be no improvement to the subexponential attack even if we only sample a subset of the class group, or if the sampling of ideal classes is biased from the uniform distribution.

%OPEN Q: Can Kuperberg be done if we sample from a subset of $\Cl(\OO)$????




By taking into account the best known attacks, the CSIDH authors propose parameters for the three NIST categories~\cite{NIST2016}, as summarized in Table~\ref{tab:csidh-parms}.
Their implementation of the smallest parameter size CSIDH-1 computes one class group action in under 100ms on a 3.5GHz processor.


\begin{table}
  \centering
  \begin{tabular}{l | r | r | r | r | r | r | r | r}
    & $n$ & $\log_2 p$ & $B$ & NIST level & classical security & quantum security & message size & private key size \\
    \hline
    CSIDH-1 &  74 &  500 &  5 & 1 & 125 bits &  61 qbits &  63B &  32B\\
    CSIDH-3 & 131 & 1020 &  7 & 3 & 255 bits &  93 qbits & 128B &  64B\\
    CSIDH-5 & 208 & 1787 & 10 & 5 & 447 bits & 129 qbits & 224B & 115B
  \end{tabular}
  \caption{Proposed parameters for CSIDH~\cite{CLMPR18}.  Effective
    parameters $p$, $n$ and $B$ for CSIDH-3 and CSIDH-5 were not given
    in the paper, and are produced here following their methodology.
    Message size is the number of bytes to represent a $j$-invariant, and private key size is the space required to store the exponent vector $\e \in \Z^n$.}
  \label{tab:csidh-parms}
\end{table}

% NOTE: do the ``quantum security'' columns need to be updated due to the Bonnetain-Schrottenloher paper?



For our signature schemes we may work with less specific primes than considered in CSIDH~\cite{CLMPR18}. For example, CSIDH takes $p+1 = 4\prod_{i=1}^n\ell_i$, whereas we may be able to use fewer primes and need a larger $p$.




\subsection{Public key signature schemes}

One can discuss Fiat-Shamir-type signatures in various ways, including the language of sigma protocols or identification schemes.
In the main body of our paper we work directly with the language of signatures, and give proofs directly in this formulation.
In Section~\ref{sec:KLS-defns} we use the language of identification schemes, and introduce the terminology there.


A \emph{public key signature scheme} consists of algorithms $\KeyGen, \Sign, \Verify$.
The randomised algorithm $\KeyGen( 1^\lambda )$ outputs a pair $(pk,sk)$, where $\lambda$ is a security parameter.
The randomised algorithm $\Sign$ takes input the private key $sk$ and a message $\msg$, and  outputs $\sigma = \Sign( sk, \msg )$.
The verification algorithm $\Verify( pk, \msg, \sigma )$ returns $0$ or $1$.
We require $\Verify( pk, \msg, \Sign( sk, \msg )) = 1$.


The standard notion of security is unforgeability against chosen-message attack (UF-CMA).
A UF-CMA adversary against the signature scheme is a randomised polynomial-time algorithm $A$ that plays the following game against a challenger.
The challenger runs $\KeyGen$ to get $(pk,sk)$ and runs $A( pk )$.
The adversary $A$ sends messages $\msg$ to the challenger, and receives $\sigma = \Sign(sk, \msg)$ in return.
The adversary outputs $(\msg^*, \sigma^*)$ and wins if $\Verify( pk, \msg^*, \sigma^* ) = 1$ and if $\msg^*$ was not one of the messages previously sent by the adversary to the challenger.
A signature scheme is UF-CMA secure if there is no polynomial-time adversary that wins with non-negligible probability.



%There are various transforms to turn an ID protocol into a sig scheme for classical or post-quantum security~\cite{AABN02,DFG13,GCZ16,Katz10,Un15,Un17}.



\section{Basic Signature Scheme}\label{sec:basic-scheme}

This section contains our main ideas and presents a basic signature scheme.
We focus in this section on classical adversaries and proofs in the random oracle model.
Hence our signature is based on the traditional Fiat-Shamir transform.
For schemes and analysis against a post-quantum adversary see Section~\ref{sec:KLS-defns}.

\subsection{Stolbunov's scheme}

Section 2.B of Stolbunov's PhD thesis~\cite{Sto12} contains a sketch of a signature scheme based on isogeny problems (though his description is not complete and he does not give a proof of security).
It is a Fiat-Shamir scheme based on an identification protocol.
Section 4 of Couveignes~\cite{Couv06} also sketches the identification protocol, but does not mention signature schemes.


The public key consists of $E$ and $E_A = \a * E$, where $\a = \prod_{i=1}^n \l_i^{e_i}$ is the private key.
To construct the private key one uniformly chooses an exponent vector $\e = (e_1, \dots, e_n) \in [-B,B]^n \subseteq \Z^n$ for some suitably chosen constant $B$.
Stolbunov assumes the relation lattice for the ideal class group is known and using this he explains in Section 2.6.1 how to sample ideal classes uniformly at random.
Section~2.6.2 of~\cite{Sto12} suggests an approach to approximate the uniform distribution.

In the identification protocol the prover generates $t$ random ideals $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ for $1 \le k \le t$ and computes $\E_k = \b_k * E$.
Here the exponent vectors $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ are uniformly and independently sampled in a region like $[-B,B]^n$ (Stolbunov assumes these ideal classes are uniformly sampled).
The prover sends $(j( \E_k ) : 1 \le k \le t )$ to the verifier.
The verifier responds with $t$ uniformly chosen challenge bits $b_1, \dots, b_t \in \{0,1\}$.
If $b_k = 0$ the prover responds with $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ and the verifier checks that $j(\E_k) = j( (\prod_{i=1}^n \l_i^{f_{k,i}}) * E )$.
If $b_k = 1$ the prover responds with a representation of $\b_k \a^{-1}$.
When $b_k=1$ the verifier checks that $j(\E_k) = j( (\b_k \a^{-1}) * E_A )$.
A cheating prover (who does not know the private key) can succeed with probability $1/2^t$.

The major problem with the above description is how to represent the ideal class of $\b_k \a^{-1}$ in a way that does not leak $\a$.
Stolbunov notes that sending the vector $\f_k - \e = (f_{k,i} - e_i )$ would not be secure as it would leak the private key, instead he mentions in one sentence a solution that can be applied assuming the discrete logs of the primes $\l_i$ in the class group are known.
Couveignes also does not explain how to prevent this leakage.
A main contribution of our paper is to give solutions to this problem.

To obtain a signature scheme Stolbunov applies the Fiat-Shamir transform, and hence obtains the challenge bits $b_k$ as the hash value $H( j(\E_1), \dots, j(\E_t) , \msg )$ where $H$ is a cryptographic hash function with $t$-bit output and $\msg$ is the message to be signed.
The signature consists of the binary string $b_1\cdots b_t$ and the representations of the ideal classes $\b_k$ when $b_k = 0$ and $\b_k \a^{-1}$ when $b_k = 1$.

The verifier computes, for $1 \le k \le t$, $\E_k = \b_k * E$ when $b_k = 0$ and $\E_k = \b_k \a^{-1} * E_A$ when $b_k = 1$. The verifier then computes $H( j( \E_1), \dots, j(\E_t), \msg )$ and checks whether this is equal to the binary string $b_1\cdots b_t$, and accepts the signature if and only if the strings agree.


We stress that neither Couveignes nor Stolbunov give a secure signature scheme as they do not explain how to prevent leakage of the private key. The main contribution of this paper is to give two solutions to the problem of representing $\b_k \a^{-1}$ without leaking the private key.
Our main solution uses ideas from lattice cryptography (Fiat-Shamir with aborts) and we describe this in the remainder of the section.
An alternative solution requires a basis of a relation lattice in the ideal class group, which can be computed efficiently using a quantum computer. We describe this alternative solution in Appendix~\ref{sec:sig-relation-lattice}.





\subsection{Using rejection sampling}\label{sec:sig-reject-sample}

% The approach in Section~\ref{sec:sig-relation-lattice} is theoretically elegant, but the assumption that the relation lattice $L$ can be computed is doubtful for practical post-quantum signatures.
%Hence this section contains our main solution to the problem of representing the ideal class $\b_k \a^{-1}$.
The idea is to use rejection sampling in exactly the way proposed by Lyubashevsky~\cite{Lyu09} in the context of lattice signatures.

Let $B > 0$ be a constant. When generating the private key we sample uniformly $e_i \in [-B, B]$ for $1 \le i \le n$. Let $\e = ( e_1, \dots, e_n )$.
The value $B$ is presumably chosen large enough that $\prod_{i=1}^n \l_i^{e_i}$ covers most ideal classes and so that the output distribution is close to uniformly distributed in $\Cl(\OO)$, but we avoid any explicit requirement or assumption that this distribution is uniform.
We refer to Definition~\ref{defn:sampling-distributions} for more discussion of this issue.

Exponents $f_{k,i}$ are sampled uniformly in $[-(nt+1)B, (nt+1)B]$, where $t$ is the number of parallel rounds of the identification protocol and $n$ is the number of primes.
Let $\f_k = (f_{k,1}, \dots, f_{k,n} )$, $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ and define $\E_k = \b_k * E $.


If the $k$-th challenge bit $b_k$ is zero then the prover responds with $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ and the verifier checks that $j(\E_k) = j( (\prod_{i=1}^n \l_i^{f_{k,i}}) * E )$ as in the basic scheme above.\footnote{In the scheme and analysis I actually apply rejection sampling to the case $b_k = 0$. It doesn't really matter one way or the other.}
If $b_k = 1$ then the prover is required to provide a representation of $\b_k \a^{-1}$, the idea is to compute the vector $\z_k = (z_{k,1}, \dots, z_{k,n}) $ defined by $z_{k,i} = f_{k,i} - e_i $ for $1 \le i \le n$.
As already noted, outputting $\z$ directly would potentially leak the secret.
To prevent this leakage we only output $\z_k$ if all its entries satisfy $| z_{k,i} | \le nt B$.
We give the signature scheme in Figure~\ref{fig:sig-scheme}.
It remains to show that in the accepting case the vector leaks no information about the private key, and that the rejecting case occurs with low probability. We do this in the following two lemmas.

\begin{lemma} \label{lem:sim2}
The distribution of vectors $\z_k$ output by the signing algorithm is the uniform distribution and therefore is independent of the private key $\e$.
\end{lemma}

\begin{proof}
Let $U = [-(nt+1)B, (nt+1)B]$. Then $\#U = 2(nt + 1)B + 1$.
If $e \in [-B, B]$ then 
\[
    [-ntB, ntB] \subseteq  U - e = \{ f - e : f \in U \} \subseteq [-(nt+2)B, (nt+2)B ].
\]
Hence, when rejection sampling (only outputting values $f_{k,i} - e_i$ in the range $[-ntB, ntB]$) is applied then the output distribution of $\z_k$ is the uniform distribution on $[-ntB, ntB]^n$.
This argument does not depend on the choice of $\e$, so the output distribution is independent of $\e$. \qed
\end{proof}












%\begin{figure}[!htb]
\begin{figure}
\begin{minipage}{.45\textwidth}
\begin{algorithm}[H]
	\caption{KeyGen \label{alg:KeyGen}}
%	\caption{KeyGen}
	\textbf{Input:} $B$, $\l_1, \dots. \l_n$, $E$

	\textbf{Output:} $sk =\e$ and $pk = E_A$

	\begin{algorithmic}[1]
		\State $\e \leftarrow [-B,B]^n$ 
		\State $E_A = ( \prod_{i=1}^n \l_i^{e_i} ) * E$
		\State \Return $sk= \e$, $pk = E_A$
	\end{algorithmic}
\end{algorithm}

\vskip -1.2cm

\begin{algorithm}[H]
	\caption{Sign \label{alg:Sign}}
	\textbf{Input:} $\msg$, $(E,E_A)$, $\e$

	\textbf{Output:} $(\z_1, \dots, \z_t)$, $(b_1 , \dots, b_t)$

	\begin{algorithmic}[1]
		\For {$k=1 , \dots , t$}
		\State $\f_k \leftarrow [-(nt+1)B,(nt+1)B]^n$ 
		\State $\E_k = ( \prod_{i=1}^n \l_i^{f_{k,i}} ) * E$
		\EndFor
		\State $b_1 \Vert \cdots \Vert b_t = H( j(\E_1) , \dots, j(\E_t), \msg )$
		\For {$k=1, \dots, t$}
		\If{$b_k=0$}
		\State $\z_k = \f_k$
		\Else
		\State $\z_k = \f_k - \e$
		\EndIf
		\If{$\z_{k} \not\in [-ntB,ntB]^n$} \State \Return $\bot$ \EndIf
		\EndFor
		\State \Return $\sigma = (\z_1, \dots, \z_t, b_1 , \dots, b_t)$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{Verify \label{alg:Verify}}
	\textbf{Input:} $\msg$, $(E,E_A)$, $\sigma$

	\textbf{Output:} Valid/Invalid

	\begin{algorithmic}[1]
		\State Parse $\sigma$ as $(\z_1, \dots, \z_t, b_1 , \dots, b_t)$
		\For {$k=1 , \dots , t$}
		\If{$b_k=0$}
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E$
		\Else
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E_A$
		\EndIf
		\EndFor
		\State $b_1' \Vert \cdots \Vert b_t' = H( j(\E_1) , \dots, j(\E_t), \msg )$
		\If{$(b_1', \dots, b_t') = (b_1 , \dots, b_t)$} \State \Return Valid
		\Else \State \Return Invalid \EndIf
	\end{algorithmic}
\end{algorithm}
\end{minipage}
\caption{The basic signature scheme using rejection sampling.\label{fig:sig-scheme}}
\end{figure}






\begin{lemma}\label{lem:rejection}
The probability that the signing algorithm outputs a signature (i.e., does not output $\bot$) is at least $1/e > 1/3$.
\end{lemma}

\begin{proof}
Let notation be as in the proof of Lemma~\ref{lem:sim2}.
For fixed $e \in [-B, B]$ and uniformly sampled $f \in U = [-(nt+1)B, (nt+1)B]$, the probability that a value $f-e$ lies in $[-ntB, ntB]$ is
\[
   \frac{2ntB + 1}{2(nt+1)B + 1}  = 1 - \frac{2B}{2(nt+1)B + 1} \ge 1 - \frac{1}{nt+1}.
\]
Hence, the probability that all of the values $z_{k,i}$ over $1 \le k \le t, 1 \le i \le n$ lie in $[-ntB, ntB]$ is at least $(1 - 1/(nt+1))^{nt}$.
% Proof of the inequality: graph the functions
Using the inequality $1 - 1/(x+1) \ge e^{-1/x}$ for $x \ge 1$ it follows that the probability that all values are in the desired range is at least
\[
   \left( e^{-1/nt} \right)^{nt} = e^{-1}.
\]
This completes the proof. \qed
\end{proof}





We can therefore get a rough idea of parameters and efficiency for the scheme.
Let $\lambda$ be a security parameter (e.g., $\lambda=128$ or $\lambda=256$), for security
we need at least $t=\lambda$ so that an attacker cannot guess the hash value or invert the hash function (see also the proof of Theorem~\ref{thm:security-basic}).
We also need a large enough set of private keys, so we need $(2B+1)^n$ large enough.
The signature contains one hash value of $\lambda$ bits, plus $t$ vectors $\f_k$ or $\z_k$ with entries of size bounded by $(nt+1)B$, for a total of $\lambda + t\lceil n\log(2(nt+1)B + 1)\rceil$ bits (assuming each vector is represented optimally). If we take $t=\lambda=128$, and $(n,B)=(74,5)$ as in CSIDH-1, we obtain signatures of 19.6 kilobytes (see also Table~\ref{tab:comparison}).

To sign/verify one needs to evaluate the action of either of $\b_k$ and $\b_k\a^{-1}$ for every $1\le k\le t$,
which means that for each $k$ and each prime $\l_i$ one needs to compute up to $ntB$ isogenies of degree $\ell_i$.
Hence, the total number of isogeny computations is upper bounded by $(nt)^2 B$.
The quadratic dependence on $nt$ is a major inconvenience.
For example, taking again $(t,n,B)=(128,74,5)$ gives around $2^{28}$ isogeny computations in signature/verification.
We can make $t$ small using the techniques in later sections, but one needs $n$ large unless $B$ is going to get very large. So even going down to $t=8$ still has signatures requiring around $2^{20}$ isogeny computations.
The acceptance probability estimate from Lemma~\ref{lem:rejection} is very close to the true value: for $(n,t,B)=(74,128,5)$ then the true acceptance probability is approximately $0.36790$, while $e^{-1} \approx 0.36788$.

We discuss some possible optimisations in Appendix~\ref{sec:variants}, including the idea to use discrete Gaussians instead of uniform distributions for the vectors.


%*** Below is not post-quantum secure as it does not accommodate Tani algorithm. ***
%
%% NOTE: $n=50, B=6$ is too small, as $(2B+1)^n \approx 2^{185}$. So I updated the above.
%Here is a table, for various $n$, of the smallest $B$ such that $(2B+1)^n > 2^{255}$.
%Maybe it would be better the other way around: smallest $n$ for various values of $B$.
%
%TODO: do we need this table? It's complicated going beyond $n\ge 74$, because then we have to take a larger $p$ and we're out of the CSIDH setting. And, among the other pairs, (74,5) is the optimum in terms of computation time (the worst in terms of sig size, though).
%
%\begin{center}
%\begin{tabular}{c||c|c|c|c|c|c|c|c|c|c}
% $n$     & 50 & 55 & 60 & 65 & 70 & 75 & 80 & 85 & 90 & 95 \\
%\hline
% min $B$ & 17 & 12 & 10 &  8 &  6 &  5 &  5 &  4 &  4 &  3 \\
%\end{tabular}
%\end{center}






\subsection{Security proof}
\label{sec:security-proof}

We now prove security of the basic scheme in the random oracle model against a classical adversary. 
%The proof covers both cases.
The proof technique is the standard approach that uses the forking lemma.
In this section we do not consider quantum adversaries, or give a proof in the quantum random oracle model (QROM).
A proof in the QROM follows from the approach in Appendix~\ref{sec:lossy-keys}.

First we need to discuss some subtleties about the distribution of ideal classes coming from the key generation and signing algorithms.

\begin{definition} \label{defn:sampling-distributions}
Fix distinct ideals $\l_1, \dots, \l_n$.
For $B \in \N$, consider the random variable $\a$ which is the ideal class of $\prod_{i=1}^n \l_i^{e_i}$ over a uniformly random $\e \in [-B,B]^n$.
Define $\D_B$ to be the distribution on $\Cl( \OO )$ corresponding to this random variable.
%
Define $M_B$ to be an upper bound on the probability, over $\a, \b$ sampled from $\D_B$, that $\a \equiv \b$.
\end{definition}

In other words, $\D_B$ is the output distribution of the public key generation algorithm.
Understanding the distribution $\D_B$ is non-trivial in general.
For small $B$ and $n$ (so that $(2B+1)^n \ll \#\Cl(\OO)$) we expect $\D_B$ to be the uniform distribution on a subset of $\Cl(\OO)$ of size $(2B+1)^n$. For fixed $n$ and large enough $B$ it should be the case that $\D_B$ is very close to the uniform distribution on $\Cl(\OO)$.
A full study of the distribution $\D_B$ is beyond the scope of this paper, but is a good problem for future work.

For the isogeny problem to be hard for public keys we certainly need $M_B \le 1/2^\lambda$, where $\lambda$ is the security parameter.
In the proof we will need to use $M_{ntB}$, since the concern is about the auxiliary curves generated during the signing algorithm. We do not require these curves to be uniformly sampled, but in practice we can certainly assume that $M_{ntB} = O( 1/\sqrt{p} )$. In any case, it is negligible in the security parameter.



\begin{definition} \label{defn:ass1p}
% (Restricted ideal action problem ***)
Let notation be as in the key generation protocol of the scheme.
Given $(E, E_A)$, where $E_A = \a * E$ for some ideal $\a = \prod_{i=1}^n \l_i^{e_i}$ and the exponent vector $\e = (e_1, \dots, e_n)$ is uniformly sampled in $[-B,B]^n \subseteq \Z^n$, to compute any ideal equivalent to $\a$.
\end{definition}

Depending on how close to uniform is the distribution $\D_B$, this problem may or may not be equivalent to Definition~\ref{defn:ass1} and may or may not have a random self-reduction.
Nevertheless, we believe this is a plausible assumption.


We recall the forking lemma, in the formulation of Bellare and Neven~\cite{BN06}.

\begin{lemma} \label{forking-lemma} (Bellare and Neven~\cite{BN06})
Fix an integer $Q \ge 1$. Let $A$ be a randomized algorithm that takes as input $h_1, \dots, h_Q \in \{0,1\}^t$ and outputs $(J, \sigma)$ where $ 1\le J \le Q$ with probability $\wp$.
Consider the following experiment: $h_1, \dots, h_Q$ are chosen uniformly at random in $\{0,1\}^t$; $A(h_1, \dots, h_Q )$ returns $(I,\sigma)$ such that $I \ge 1$; $h_I', \dots, h_Q'$ are chosen uniformly at random in $\{0,1\}^t$; $A( h_1, \dots, h_{I-1}, h_I', \dots, h_Q' )$ returns $(I', \sigma')$.
Then the probability that $I' = I$ and $h_{I}' \ne h_I$ is at least $\wp( \wp/Q - 1/2^t )$.
\end{lemma}


\begin{theorem}\label{thm:security-basic}
In the random oracle model, the basic signature scheme is unforgeable under a chosen message attack under the assumption of Definition~\ref{defn:ass1p}.
\end{theorem}

\begin{proof}
Consider a polynomial-time adversary $A$ against the signature scheme. So $A$ takes a public key, makes queries to the hash function $H$ and the signing oracle, and outputs a forgery of a signature with respect the public key.

Let $(E, E_A = \a * E )$ be an instance of Definition~\ref{defn:ass1p}.
The simulator runs the adversary $A$ with public key $(E, E_A)$.
% (or apply the random self-reduction mentioned earlier) in the random oracle model.

Suppose the adversary $A$ makes at most $Q$ (polynomial in the security parameter) queries in total to either the random oracle $H$ or the signing oracle. We now explain how the simulator responds to these queries. The simulator maintains a list, initially empty, of pairs $(x, H(x))$ for each value of the random oracle that has been defined.

\vskip 0.1cm

\noindent \textbf{Sign queries:}
To answer a Sign query on message $\msg$ the simulator chooses 
$t$ uniformly chosen bits $b_1, \dots, b_t \in \{0,1\}$.
When $b_k = 0$ the simulator randomly samples $z_k \leftarrow [-ntB,ntB]^n$ and sets $\b_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ and computes $\E_k = \b_k * E$, just like in the real signing algorithm.
When $b_k = 1$ the simulator chooses a random ideal $\c_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ for $z_{k,i} \in [-ntB, ntB]$
%(consistent with the protocol under consideration; so using Lemma~\ref{lem:sim2}) 
and computes $\E_k = \c_k * E_A$.
By Lemma~\ref{lem:sim2}, the values $j( \E_k )$ and $\z_k$ are distributed exactly as in the real signing algorithm.
We program the random oracle (update the hash list) so that $H( j( \E_1), \dots, j(\E_t), \msg ) := b_1 \cdots b_t$, unless the random oracle has already been defined on this input in which case the simulation fails and outputs $\perp$.
The probability of failure is at most $Q/M_{ntB}^t$, 
where $M_{ntB}$ is defined in Definition~\ref{defn:sampling-distributions} to be an upper bound on the probability of a collision in the sampling of ideal classes.
Note that $Q/M_{ntB}^t$ is negligible.
Assuming the simulation does not fail, the output is a valid signature and is indistinguishable from signatures output by the real scheme in the random oracle model.

\vskip 0.1cm

\noindent \textbf{Hash queries:}
To answer a random oracle query on input $x$ one checks if $(x,y)$ already appears in the list, and if so returns $y$. Otherwise one chooses uniformly at random $y \in \{0,1\}^t$ and sets $H(x) := y$ and adds $(x,y)$ to the list.

\vskip 0.1cm

Eventually $A$ outputs a forgery $(\msg, \z_1, \dots, \z_t, b_1\cdots b_t)$ that passes the verification equation.
Define $\c_k = \prod_i \l_i^{z_{k,i}}$.
The proof now invokes the Forking Lemma (see Bellare-Neven~\cite{BN06}). The adversary is replayed with the same random tape and the exact same simulation, except that one of the hash queries is answered with a different binary string.
With non-negligible probability the adversary outputs a forgery with the same message $\msg$ and the same input $(j(\E_1), \dots, j(\E_t), \msg)$ to $H$, but a different output string $b_1'\cdots b_t'$. Let $k$ be an index such that $b_k \ne b_k'$ (without loss of generality $b_k = 0$ and $b_k' = 1$). Then the ideal classes $\c_k$ and $\c_k'$ in the two signatures are such that $j( \c_k * E ) = j( \c_k' * E_A )$ and so $\c_k' \c_k^{-1}$ is a solution to the problem instance. \qed
\end{proof}


We make two observations about the use of the forking lemma.
First, as always, the proof is not tight since if the adversary succeeds with probability $\epsilon$ then the simulator solves the computational problem with probability proportional to $\epsilon^2$.
Second, the hash output length $t$ in Lemma~\ref{forking-lemma} only appears in the term $1/2^t$, so it suffices to take $t = \lambda$.
There may be situations where a larger hash output is needed; for more discussion about hash output sizes we refer to Neven, Smart and Warinschi~\cite{NSW09}.





\section{Smaller sigs}\label{sec:smaller-sigs}


The signature size of the basic scheme is very large, since the sigma protocol that underlies the identification scheme only has single bit challenges. 
In practice we need $t \ge 128$, which means signatures are very large.
To get shorter signatures it is natural to try to increase the size of the challenges.
In this section we sketch an approach to obtain $s$-bit challenge values for any $s \in \N$, by trading the challenge size with the public key size. In the next section we explain how to shorten the public keys again.


The basic idea is to have public keys $( E_{A,1} = \a_1 * E , \dots , E_{A,2^s} = \a_{2^s} * E )$.
For each $1 \le m \le 2^s$ we choose $\e_m \leftarrow [-B,B]^n$ and set $E_{A,m} = ( \prod_{i=1}^n \l_i^{e_{m,i}} ) * E$.
The signing algorithm for user A chooses $t$ random ideals $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ and computes $\E_k = \b_k * E$, as before.
Now we have $s$-bit challenges $b_1, \dots, b_t \in \{1, 2, \dots, 2^s \}$.
For each $1 \le k \le t$ the signer computes $\z_k = \f_k - \e_{b_k}$, which corresponds to the ideal class $\c_k := \a_{b_k}^{-1} \b_k$ and the verifier can check that $j( \E_k ) = j( \c_k * E_{A, b_k})$.

A signature is still made of one hash value, plus $t$ vectors $\z_k$ with entries of size bounded by $ntB$, i.e., a total of $\lambda + t\lceil n\log(2ntB + 1)\rceil$ bits, similar to the previous section.
But now for security we now only require $ts \ge \lambda$.
Taking, say, $\lambda = 128$ and $s = 16$ can mean $t$ as low as 8, and so only 8 vectors need to be transmitted as part of the signature, giving signatures of only 944 bytes!
Of course the public key now includes $2^{16}$ $j$-invariants (elements of $\F_p$) which would be around 4 megabytes, and key generation is also $2^{16}$ times slower.


As far as we can tell, this idea cannot be applied to the schemes of Yoo et al~\cite{YAJJS17} or Galbraith et al~\cite{GPS17}.



\subsection{Security}

A trivial modification to the proof of Theorem~\ref{thm:security-basic} can be applied in this setting. But note that the forking lemma produces two signatures such that $b_k \ne b_k'$ for some index $k$.
Hence from a successful forger we derive two ideal classes $\c_k$ and $\c_k'$ such that $j( \c_k * E_{A, b_k} ) = j( \c_k' * E_{A, b_k'})$. It follows that $(\c_k')^{-1} \c_k$ is an ideal class corresponding to an isogeny $E_{A,b_k} \to E_{A,b_k'}$.
Hence the computational assumption underlying the scheme is the following.

\begin{definition}\label{defn:one-out-of-2s-problem}
% (One out of $2^s$ ideal action problem ***)
Let notation be as in the key generation protocol of the scheme.
Consider a set of $2^s$ elliptic curves $\{ E_{A,1}, \dots, E_{A,2^s} \}$, all of the form $E_{A,m} = \a_m * E$ for some ideal $\a_m = \prod_{i=1}^n \l_i^{e_{m,i}}$ where the exponent vectors $\e_m $ are uniformly sampled in $[-B,B]^n \subseteq \Z^n$. The ``one out of $2^s$'' isogeny problem is to compute an ideal corresponding to any isogeny $E_{A,m} \to E_{A,m'}$ for some $m \ne m'$.
\end{definition}



We believe this problem is hard for classical and quantum computers. One can easily obtain a non-tight reduction of this problem to the problem of Definition~\ref{defn:ass1p}.
However we do not know how to obtain a random-self-reduction for this problem, which prevents us from having a tight reduction to the problem of Definition~\ref{defn:ass1p}.


\begin{theorem}
In the random oracle model, the signature scheme of this section is unforgeable under a chosen message attack under the assumption of Definition~\ref{defn:one-out-of-2s-problem}.
\end{theorem}

The proof of this theorem is almost identical to the proof of Theorem~\ref{thm:security-basic} and so is omitted.



\subsection{Variant based on a more natural problem}


Definition~\ref{defn:one-out-of-2s-problem}  is a little un-natural.
It would be more pleasing to prove security based on the problems in Definition~\ref{defn:ass1} or~\ref{defn:ass1p}.
We now explain that one can prove security based on the problem in Definition~\ref{defn:ass1}, under an assumption about uniform sampling of ideal classes.

So suppose in this section that the distribution $\D_B$ of Definition~\ref{defn:sampling-distributions} has negligible statistical distance from the uniform distribution.
This assumption is reasonable for bounded $n$ and very large $B$; but we leave for future work to determine whether practical parameters for isogeny crypto can be obtained under this constraint.


We add an extra $1/2$ factor in the success probability, but this is not a big issue since the security proof isn't tight anyway.


\begin{theorem}
Let parameters be such that the statistical distance between $\D_B$ and the uniform distribution on $\Cl(\OO)$ is negligible.
In the random oracle model, the signature scheme of this section is unforgeable under a chosen message attack under the assumption of Definition~\ref{defn:ass1}.
\end{theorem}


\begin{proof}
Let $A$ be an adversary against the scheme and $(E, E_A = \a * E )$ be an instance of Definition~\ref{defn:ass1}.

Choose random ideal classes $\b_1, \dots, \b_{2^s}$
(chosen as $\b_m = \prod_{i=1}^n \l_i^{u_{i,m}}$ for $1 \le m \le 2^s$ and $u_{i,m} \in [-B,B]$)
and compute $E_{A,m}' = \b_m * E$ for $1 \le m \le 2^{s-1}$ and $E_{A,m}' = \b_m * E_A$ for $2^{s-1} < m \le 2^s$. Choose a random permutation $\pi$ on $\{ 1, 2, \dots, 2^s \}$ and set the public key to be the sequence $E_{A,m} = E_{A,\pi(m)}'$.
Note that these curves are all uniformly sampled in the isogeny class, and so there is no way to distinguish whether the curve has been generated from $E$ or $E_A$.
Now run the adversary on this public key.

This is where the subtlety about distributions appears: it is crucial that the public key derived from the pair $(E, E_A)$ is indistinguishable from public keys output by the key generation algorithm.


The simulator will handle hash and sign queries similarly to the proof of Theorem~\ref{thm:security-basic}.
When simulating the sign oracle we first choose the $t$ values $b_1, \dots, b_1 \in \{0,1\}^s$, which are interpreted as the challenge values $1 \le b_k \le 2^s$.
For each $1 \le k \le t$ we choose a random ideal class $\c_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ by choosing $z_{k,i} \in [-ntB, ntB]$, and then compute $\E_k = c_k * E_{A,b_k}$.
One then defines the hash value $H( j(\E_1), \dots, j(\E_t), \msg )$ to be $b_1 \Vert b_2 \Vert \cdots \Vert b_t$.
This simulation is indistinguishable to the real cryptosystem, assuming the distributions on ideal classes have negligible statistical distance.

When the forking lemma is applied we have, for some index $k$, two different ideals $\c_k, \c_k'$ such that $j( \c_k * E_{A, b_k} ) = j( \c_k' * E_{A, b_k'})$ and $b_k' \ne b_k$
With probability $1/2$ we have that one of the $E_{A,b_k}$ is known to the simulator as  $\b * E$ and the other is known as $\b' * E_A$. If this event occurs then we have $\c_k \b * E = \c_k' \b' * E_A$ (or vice versa) in which case $(c_k' \b')^{-1} c_k \b$ is a solution to the original instance. \qed
\end{proof}


%Version 2: Have a computational assumption $(E, \a * E, \a^2 * E, \a^3 * E , \dots, a^{2^s - 1} * E )$ and 3-special soundness implies can get $\a$ with a good probability. This is cute but ultimately pointless.


\subsection{Reducing storage for private keys}\label{sec:private-key-compress}

Rather than storing all the private keys $\a_i$ one could have generated them using a pseudorandom function as $\PRF( \seed, i )$ where $\seed$ is a seed and $i$ is used to generate the $i$-th private key (which is an integer exponent vector).
The prover only needs to store $\seed$ and can then recompute the private keys as needed.
Of course, during key generation one needs to compute all the public keys, but during signing one only needs to determine $t \approx 8$ private keys (although this adds a cost to the signing algorithm).




\section{Smaller public keys} \label{sec:smaller-keys}

The approach of Section~\ref{sec:smaller-sigs} gives signatures that are potentially quite small, but at the expense of very large public keys. In some settings (e.g., software signing) large public keys can be easily accommodated, while in other settings (e.g., certificate chains) it makes no sense to shorten signatures at the expense of public key size.
In this section we explain how to use techniques from hash-based signatures to compress the public key while also maintaining compact signatures.
The key idea is to use a Merkle tree~\cite{10.1007/0-387-34805-0_21} with leaves the public curves $E_{A,1}, \dots, E_{A,2^s}$, and use the tree root (a single hash value) as public key.
However, the security of plain Merkle trees depends on collision resistance of the underlying hash function, thus requiring hashes of size at least twice the security parameter.
Instead, we use a modified Merkle tree, as introduced in the hash-based signatures XMSS-T~\cite{10.1007/978-3-662-49384-7_15} and SPHINCS+~\cite{sphincs+}, whose security relies on the second preimage resistance of a keyed hash function.

Let $\lambda$ be a security parameter, and let $n,B,s,t,p$ be as in the previous sections; we assume that $\lceil\log p\rceil > 2\lambda$, as this is the case in any secure instantiation.
Let the following (public) functions be given:

\begin{itemize}
\item $\PRFs: \{0,1\}^\lambda \times \{0,1\}^s \to [-B,B]^n$,
\item $\PRFk: \{0,1\}^\lambda \times \{0,1\}^{s+1} \to \{0,1\}^\lambda$,
\item $\PRFm: \{0,1\}^\lambda \times \{0,1\}^{s+1} \to \{0,1\}^{\lceil\log p\rceil}$ three pseudo-random functions, and
\item $M: \{0,1\}^\lambda \times \{0,1\}^{\lceil\log p\rceil} \to \{0,1\}^\lambda$ a keyed hash function.
\end{itemize}

Finally, let $\PK.\seed$ and $\SK.\seed$ be two random seeds; as the names suggest, $\PK.\seed$ is part of the public key, while $\SK.\seed$ is part of the secret key.
Like in Section~\ref{sec:private-key-compress}, we define the secret ideals $\a_m = \prod_{i=1}^n \l_i^{e_{m,i}}$, where $\e_m=\PRFs(\SK.\seed, m)$, and the public curves $E_{A,m}=\a_m*E$, for $1\le m\le 2^s$.

We set up a hash tree by defining $h_{l,u}$ for $0 \le l \le s$ and $1 \le u \le 2^{s-l}$.
First we set
\[h_{s,u} = M\bigl( \PRFk(\PK.\seed,2^s+u-1),\; j( E_{A,u} ) \oplus \PRFm(\PK.\seed,2^s+u-1) \bigr)\]
for $1 \le u \le 2^s$, where $\oplus$ denotes bitwise XOR.
Now, for any $0 \le l < s$, the rows of the hash tree are defined as
\[
  h_{l,u} = M\bigl( \PRFk(\PK.\seed, 2^l+u-1),\;
  (h_{l+1,2u-1}\Vert h_{l+1,2u}) \oplus \PRFm(\PK.\seed, 2^l+u-1) \bigr).
\]
Finally, the public key is set to the pair $(\PK.\seed, h_{0,1})$.

To prove that a value $E_{A,u}$ is in the hash tree, we use its \emph{authentication path}.
That is the list of the hash values $h_{l,u'}$, for $1\le l \le s$, occurring as siblings of the nodes on the path from $h_{s,u}$ to the root.
The proof in~\cite[Appendix~B]{10.1007/978-3-662-49384-7_15} shows that having $M$ output $\lambda$-bit hashes gives a (classical) security of approximately $2^\lambda$.
See~\cite{10.1007/978-3-662-49384-7_15,sphincs+} for more details.

Typically, in hash-based signatures the secret key would only contain $\SK.\seed$, since all secret and public values can be reconstructed from it at an acceptable cost.
However, in our case recomputing the leaves of the hash tree ($2^s$ class group actions) is much more expensive than recomputing the internal nodes ($2^s-1$ hash function evaluations), thus we set the secret key to the tuple $(\SK.\seed,h_{s,1},\dots,h_{s,2^s})$.
This is a considerably large secret key, e.g., around $1$ megabyte when $\lambda=128$ and $s=16$, but it is offset by a more than tenfold gain in signing time.
Also note that the values $h_{s,u}$ can (and will) be leaked without any loss in security, they are indeed part of the uncompressed public key, thus they are more formally treated as auxiliary signer data, rather than as part of the secret key.

To sign we proceed like in Section~\ref{sec:smaller-sigs}, but the signature now needs to contain additional information.
The signer computes the random ideals $\b_1,\dots,\b_t$ and the associated curves $\E_1,\dots,\E_t$ to obtain the challenges $b_1,\dots,b_t$.
Then, using $\PRFs$, they obtain the secrets $\a_{b_1},\dots,\a_{b_t}$, recompute the public curves $E_{A,b_1},\dots,E_{A,b_t}$, and the ideals $\c_i=\a_{b_i}^{-1}\b_i$.
The signature is made of the ideals $\c_1,\dots,\c_t$, the curves $E_{A,b_1},\dots,E_{A,b_t}$, and their authentication paths in the hash tree.
The verifier computes $\E_i$ as $\c_i * E_{A,b_i}$, obtains the challenges $b_1,\dots,b_t$, and uses them to verify the authentication paths.
Hence, the signature contains $t$ ideals represented as vectors in $[-ntB,ntB]^n$, $t$ curves represented by their $j$-invariants, and $t$ authentication paths of length $s$.
The $t$ authentication paths eventually merge before the root, thus some hash values will be repeated.
We can save some space by only sending the hash values once, in some standardized order: the worst case happening when no path merges before level $\log(t)$, no more than $t(s-\log(t))$ hash values need to be sent as part of the signature.
In total, a signature requires at most $t\lceil n \log(2ntB+1)\rceil + t\log(p) + t\lambda(s-\log(t))$ bits.
For our parameters $t=8, s=16$ and $\lambda=128$, this adds about 2 kilobytes to the signature of Section~\ref{sec:smaller-sigs}.
Note that this is still an order of magnitude smaller than the best hash-based signature schemes, while being stateless.

Concerning security, the proofs of the previous sections, and that of~\cite[Appendix~B]{10.1007/978-3-662-49384-7_15} can be combined to prove the following theorem.

\begin{theorem}
  The signature scheme of this section is unforgeable under a chosen
  message attack under the following assumptions:
  \begin{itemize}
  \item The problem of Definition~\ref{defn:one-out-of-2s-problem};
%The \emph{one out of $2^s$ ideal action} of Definition~\ref{defn:one-out-of-2s-problem};
  \item The \emph{multi-function multi-target second-preimage resistance} of
    the keyed hash function $M$;
  \item The pseudo-randomness of $\PRFs$;
  \end{itemize}
  when the hash function $H$ and the pseudo-random functions $\PRFk$
  and $\PRFm$ are modeled as random oracles.
\end{theorem}

Like in the previous section, it is possible to replace the assumption of Definition~\ref{defn:one-out-of-2s-problem} with that of Defintion~\ref{defn:ass1}, modulo some additional assumptions.
Both proofs are straightforward adaptations, and we omit them for conciseness.
As already noted, the proofs are not tight, however the part concerned with the second-preimage resistance of $M$ is.


\section{Performance}


Table~\ref{tab:comparison} gives some estimates of cost for the schemes presented in Sections~\ref{sec:basic-scheme},~\ref{sec:smaller-sigs},~\ref{sec:smaller-keys}, plus the original insecure scheme.
It is divided in three sections.

Section ``Exact'' reports the parameter sizes, as a number of bits, already computed in each section.
$\lambda$ is the security parameter, $n,B$ and $s$ are as described previously.
To simplify the expressions we assume that all hash functions have $\lambda$-bit outputs, and we set the parameter $t=\lambda/s$.

Section ``Asymptotic'' gives asymptotic estimates in terms only of the security parameter $\lambda$, and the parameter of $s$ of Section~\ref{sec:smaller-sigs}.
The constraints on the parameters $p,n,B$ are determined following the methodology in CSIDH~\cite{CLMPR18}, and may not be necessary.
Here is the justification for the parameter restrictions in terms of $\lambda$:
\begin{enumerate}
\item Kuperberg's algorithm is believed to have complexity at least $\tilde{O}( 2^{\sqrt{\log(N)}} )$ in a group of size $N$. In our case $N > \sqrt{p}$. Taking $\log(p) > 2 \lambda^2$ gives 
\[
   \sqrt{ \log(N)} > \sqrt{ \tfrac{1}{2} \log(p) } > \sqrt{ \tfrac{1}{2} 2 \lambda^2 } = \lambda.
\]
\item 
To resist a classical meet-in-the-middle attack we need $(2B+1)^n > 2^{2 \lambda}$.
For security Tani's quantum algorithm we may require $(2B+1)^n > 2^{3 \lambda}$, and so $n \log(B) \sim 3 \lambda$.

The table below states  $n\log B\sim \lambda^2$, which may not be relevant in our situation as we base our security on a different assumption to other works.

%(*** So, do we abandon approximating the uniform distribution or not? This only affects the ``Asymptotic'' part of the table, of course, but then we should say that Theorem 3 does not apply.)

\item If one is choosing primes of the form $p+1 = 4\prod_{i=1}^n\ell_i$, as in CSIDH~\cite{CLMPR18}, then one is restricted to taking $n$ not too large compared with $p$.
Approximating $\ell_i \approx n \log(n)$ it follows that $p \approx (n \log(n))^n$ and so we must have $n \log(n) < \log(p)$.

In the table below this is specified as the third condition $n \log(n) \sim 2 \lambda^2$, on the assumption that it is usually appropriate to use as large as possible $n$ in any given situation.
\end{enumerate}

Finally, section ``CSIDH'' gives concrete sizes obtained by fixing $\lambda=128$ and $s=16$ and using the CSIDH-1 primitive, i.e., $(n,B,\log(p)) = (74,5,500)$.
We estimate these parameters to correspond to the NIST-1 security level.

In each section, we also give a very rough estimate of the expected running time for key generation and for signature/verification.
We measure this as a multiple of the ``unit'' $\Cl(\OO)$ action, i.e., as the equivalent number of computations of the action $(\prod_{i=1}^n\l_i^B)*E$.
We feel this is a better measure than the number of individual isogeny computations, because those are highly dependent on the isogeny degree $\ell_i$.
A second reason for using this measure is that it estimates the running time as a number of applications of the CSIDH primitive; indeed, in the last section we obtain our numerical estimates by multiplting this number by $0.1$ seconds, the worst-case time reported in~\cite{CLMPR18} for one isogeny action.

Note that these estimates are very rough, as they purposely ignore other factors such as hash tree computations and rejections in signing.
However the results in~\cite{10.1007/978-3-662-49384-7_15,sphincs+} show that hash trees, much larger than ours, can be computed in a fraction of the time we need to compute isogenies.
On the other hand, rejections that happen during signing multiply the running time by a small constant, typically less than $3$ on average.


\begin{landscape}
  \begin{table}
    \pgfkeys{/pgf/fixed point arithmetic}
    \def\lam{128}
    \def\n{74}
    \def\B{5}
    \def\logp{500}
    \def\s{16}
    \def\CSIDHsecs{0.1}
    \pgfmathtruncatemacro{\t}{\lam / \s}
    % Sig size
    \pgfmathtruncatemacro{\BasSig}{round(\lam * ceil(\n * log2(2*\B + 1)) + \lam) / 8} 
    \pgfmathtruncatemacro{\RejSig}{round(\lam * ceil(\n * log2(2*(\n*\lam+1)*\B + 1)) + \lam) / 8}
    \pgfmathtruncatemacro{\ParSig}{round(\t * ceil(\n * log2(2*\n*\t*\B + 1)) + \lam) / 8}
    \pgfmathtruncatemacro{\ComSig}{round(\ParSig + (-\lam + \t * \logp  + \lam * (\lam - \t * log2(\t))) / 8)}
    % PK size
    \pgfmathtruncatemacro{\BasPK}{ceil(\logp / 8)}
    \pgfmathtruncatemacro{\RejPK}{\BasPK}
    \pgfmathtruncatemacro{\ParPK}{round(2^\s * \RejPK / 1024)}
    \pgfmathtruncatemacro{\ComPK}{2 * \lam / 8}
    % SK size
    \pgfmathtruncatemacro{\BasSK}{ceil(\n * log2(2*\B + 1)) / 8}
    \pgfmathtruncatemacro{\RejSK}{\BasSK}
    \pgfmathtruncatemacro{\ParSK}{\lam / 8}
    \pgfmathtruncatemacro{\ComSK}{(2^\s + 1) * \lam / 8 / 1024}
    % keygen time
    \pgfmathsetmacro{\BasKG}{\CSIDHsecs}
    \pgfmathsetmacro{\RejKG}{\BasKG}
    \pgfmathtruncatemacro{\ParKG}{round(2^\s * \BasKG)}
    \pgfmathtruncatemacro{\ComKG}{\ParKG}
    % sig time
    \pgfmathtruncatemacro{\BasTime}{round(\lam * \CSIDHsecs)}
    \pgfmathtruncatemacro{\RejTime}{\n * \lam * \BasTime}
    \pgfmathtruncatemacro{\ParTime}{round(\n * \t^2 * \CSIDHsecs)}
    \pgfmathtruncatemacro{\ComTime}{\ParTime}
    \centering
    \begin{tabular}{l | c | c | c | c |}
      & Basic scheme (not secure)
      & Rejection sampling (Section~\ref{sec:sig-reject-sample})
      & Shorter signatures (Section~\ref{sec:smaller-sigs})
      & Smaller public keys (Section~\ref{sec:smaller-keys}) \\
      \hline
      \hspace{1em}\textbf{Exact} &&&&\\
      Sig size
      & $\lambda\lceil n\log (2B+1)\rceil + \lambda$
      & $\lambda\lceil n\log (2(n\lambda + 1) B + 1)\rceil + \lambda$
      & $\frac{\lambda}{s}\lceil n\log (2n\frac{\lambda}{s}B + 1)\rceil + \lambda$
      & $\frac{\lambda}{s}(\lceil n\log (2n\frac{\lambda}{s}B + 1)\rceil + \log p) + \lambda(\lambda-\frac{\lambda}{s}\log\frac{\lambda}{s})$\\
      PK size
      & $\log p$ & $\log p$ & $2^s\log p$ & $2\lambda$ \\
      SK size
      & $n\log(2B+1)$ & $n\log(2B+1)$ & $\lambda$ & $(2^s+1) \lambda$\\
      $\Cl(\OO)$ actions &&&&\\
      $\to$ keygen
      & 1 & 1 & $2^s$ & $2^s$\\
      $\to$ sig/verify
      & $\lambda$ & $n\lambda^2$ & $n(\lambda/s)^2$ & $n(\lambda/s)^2$\\
      \hline
      \hspace{1em}\textbf{Asymptotic} &&&&\\
      Sig size
      & $O(\lambda^3)$ & $O(\lambda^3)$ & $O(\lambda^3/s)$ & $O(\lambda^3/s)$\\
      PK size
      & $2\lambda^2$ & $2\lambda^2$ & $2^{s+1}\lambda^2$ & $\lambda$\\
      SK size
      & $\lambda^2$ & $\lambda^2$ & $\lambda$ & $(2^s+1)\lambda$\\
      $\Cl(\OO)$ actions &&&&\\
      $\to$ keygen
      & 1 & 1 & $2^s$ & $2^s$\\
      $\to$ sig/verify
      & $\lambda$ & $\lambda^4/\log(\lambda)$
      & $(\lambda^2/s)^2/\log(\lambda)$ & $(\lambda^2/s)^2/\log(\lambda)$\\
      \hline
      \hspace{1em}\textbf{CSIDH(128,16)} &&&&\\
      Sig size
      & \BasSig{} B & \RejSig{} B & \ParSig{} B & \ComSig{} B\\
      PK size
      & \BasPK{} B & \RejPK{} B & \ParPK{} KB & \ComPK{} B\\
      SK size
      & \BasSK{} B & \RejSK{} B & \ParSK{} B & \ComSK{} KB \\
      Est. keygen time
      & \BasKG{} s & \RejKG{} s & \ParKG{} s & \ComKG{} s\\
      Est. sig/verify time
      & \BasTime{} s & \RejTime{} s & \ParTime{} s & \ComTime{} s
    \end{tabular}
    \caption{Parameter size and performance of the various signature
      protocols.
      Equivalences used for asymptotic analysis are:
      $\log p \sim 2\lambda^2$, $n\log B\sim \lambda^2$,
      $n\log n \sim 2\lambda^2$.
The entry CSIDH(128,16) is for parameters $(\lambda,n,B,s,\log_2(p)) = (128, 74, 5, 16, 500)$ and $t=\frac{\lambda}{s}=8$.
      All logarithms are in base 2. % NdL: this is probably wrong
    }
    \label{tab:comparison}
  \end{table}
\end{landscape}

\section{Conclusions}


We have given a signature scheme suitable for the CSIDH isogeny setting.
This solves an unresolved problem in Stolbunov's thesis.
We have also shown how to get shorter signatures by increasing the public key size.
We do not know how to obtain a similar tradeoff between public key size and signature size for the schemes of Yoo et al~\cite{YAJJS17} or Galbraith et al~\cite{GPS17} based on the SIDH setting.


\section*{Acknowledgements}

Thanks to Samuel Dobson for doing some experiments with discrete Gaussians.


\bibliographystyle{plain}
\bibliography{biblio}



\appendix


\section{Variants}\label{sec:variants}

One can consider various ideas to get more efficient (i.e., faster signing and verification) or more compact signatures.

\begin{enumerate}
\item Following Stolbunov one could use higher powers for the smaller primes.

This is definitely worth looking at. We could take $B=1$ for some of the larger primes (e.g., the ones bigger than 50), and then use much larger values for $B$ for the primes $3, 5, 7$ etc. If $B_i$ is the bound used for $\l_i$ then the full key space is $\prod_i (2B_i + 1)$.

The main problem is that a change to a single $B_i$ makes very little difference to the key size. For example, doubling $B_1$ only adds roughly $+1$ to the logarithm of the product, which is the security parameter.
Hence the main factor in having a large security parameter is using lots of distinct primes $\l_i$, which automatically means a high cost for signing and verification since almost all $f_{k,i}$ will be non-zero.



\item Could sample the exponents $e_i$ from a discrete Gaussian distribution (or perhaps some other distribution) as has been done with lattice signatures.

Suppose the $e_i$ are sampled from a discrete Gaussian distribution with parameter $\sigma$, so that the standard deviation is close to $\sigma$. The entropy of the continuous Gaussian distribution with standard deviation $\sigma$ is $\log( 2 \pi e \sigma^2 )/2$.
% so we need the $n$-th multiple of this to be larger than the security parameter.

For example, take $n=70$, $s = 16, t = 8$ and choose $\sigma = 5$ (so almost all values $e_{i}$ will lie in $[-15,15]$ but occasionally one is larger than this. Then
\[
   n \log( 2 \pi e \sigma^2 )/2 \approx 212
\]
so determining the $e_i$ using a meet-in-the-middle strategy should require at least $2^{106}$ iterations, and realistically much more than this since organising a search based on the entropy is hard to do. For post-quantum security we might want to replace $2 \lambda$ with $3\lambda$ in the above.

We following the methods and results of Lyubashevsky~\cite{Lyu12}. Lemma 4.3(3) of~\cite{Lyu12} shows we can bound the norm $\Vert \e \Vert$ by $T = 2 \sigma \sqrt{n}$.
Now we need to choose the $f_{k,i}$ from a discrete Gaussian with parameter $\sigma'$, so that the distribution of $f_{k,i} - e_i$ is close (within statistical distance, though we could probably use Renyi divergence to get better results) to the discrete Gaussian with parameter $\sigma'$.
Lemma 4.6 of~\cite{Lyu12} suggests that $\sigma' = T \sqrt{\log(n)}$ is sufficient, though in practice one usually chooses $\sigma' = \alpha T $ where $\alpha \approx 10$.
In our case we need to apply rejection sampling to all $t$ vectors $\z_k$ simultaneously,
which leads to an additional factor.

For our choices $n=70, t = 8, \sigma = 5$ this gives $\sigma' > 3000$ (experiments ongoing).
If we use some kind of compact coding of integers distributed as Gaussians~\cite{DDLL13} then signature size would be at best $nt \log( 2 \pi e (\sigma')^2 )/2$ bits.
For our example parameters this would be between 7000-8000 bits, or around one kilobyte again.
% More work is needed to work out the exact details and determine the rejection sampling probabilities. 

\item One might try to trade-off the size of exponent vectors and the rejection probability. Lemma~\ref{lem:rejection} is about sampling $f_{k,i} \in [ -(nt+1)B, (nt+1)B ]$ and gives probability of acceptance $\approx 1/e \approx 0.368$.
A simple modification of the proof shows that, for any $u > 0$, if one samples $f_{k,i} \in [ -u(nt+1)B, u(nt+1)B ]$ and accepts only those $\z_{k,i} \in [ -untB, untB ]$, then the acceptance probability is approximately $e^{-1/u}$.

Taking $u = 1/2$ roughly halves the time spent on computing $\b_k * E$, but changes the acceptance probability to $e^{-2}  \approx 0.135$; overall this is worse than the original proposal since $2 e^{-2} \approx 0.271 < e^{-1}$.
Similarly, taking $u = 2$ doubles the time spent on computing $\b_k * E$, but changes the acceptance probability to $e^{-1/2} \approx 0.607$; again this is worse on average than our proposal.
\end{enumerate}


\section{Tight security reduction based on lossy keys}\label{sec:lossy-keys}


We now explain how to implement lossy keys in our setting.
This allows us to use the methods of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18} (themselves based on work of Abdalla, Fouque, Lyubashevsky and Tibouchi~\cite{AFLT12}) to obtain signatures from lossy identification schemes. This approach gives \emph{tight reductions} in the classical random oracle model and also proofs in the \emph{quantum random oracle model}.


Here's the basic idea to get a lossy scheme, using uniform distributions for simplicity (one can also use discrete Gaussians in this setting):
Take a very large class group, but use a small $n$, $B$ so that $\{ \a = \prod_{i=1}^n \l_i^{e_i} : e_i \in [-B,B] \}$ is a very small subset of the class group.\footnote{Might even be able to consider working with subgroups, in the quantum case where the class group structure is known.}
The real key is $(E, E_A = \a*E )$ for such an $\a$.
The lossy key is $(E, E_A )$ where $E_A$ is a uniformly random curve in the isogeny class.
Further, chooose parameters so that the $f_{k,i}$ are also such that $\{ \b = \prod_{i=1}^n \l_i^{f_{k,i}} : |f_{k,i}| \le (nt+1)B \}$ is a small subset.
In the case of a real key, the signatures include ideals that correspond to paths from $E$ or $E_A$ to a  curve.
In the case of a lossy key, then such ideals do not exist as for a curve $E'$ it is not the case that there is a short path from $E$ to $E'$ AND a short path from $E_A$ to $E'$.

In the remainder of this section we develop these ideas.


\subsection{Background definitions} \label{sec:KLS-defns}

We closely follow Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}.
A \emph{canonical identification scheme} consists of algorithms $(\IGen, \PP_1, \PP_2, \VV)$ and a set $\ChSet$. The randomised algorithm $\IGen( 1^\lambda )$ outputs a key pair $(pk,sk)$.
The deterministic algorithm $\PP_1$ takes $sk$ and randomness $r_1$ and computes $(W, \St) = P_1( sk, r_1 )$. 
Here $\St$ denotes state information to be passed to $P_2$.
A challenge $c$ is sampled uniformly from $\ChSet$. The deterministic algorithm $P_2$ then computes $Z = P_2( sk, W, c, \St, r_2 )$ or $\perp$, where $r_2$ is the randomness.
The output $\perp$ corresponds to an abort in the ``Fiat-Shamir with aborts'' paradigm.
We require that $\VV( pk, W, c, Z ) = 1$ for a correctly formed transcript $(W,c,Z)$.

We assume, for each value of $\lambda$, there are well-defined sets $\Wset$ and $\Zset$, such that $\Wset$ contains all $W$ output by $\PP_1$ and $\Zset$ contains all $Z$ output by $\PP_2$. 
The scheme is \emph{commitment recoverable} if, given $c$ and $Z = P_2( sk, W, c, \St )$, there is a unique $W \in \Wset$ such that $\VV( pk, W, c, Z ) = 1$ and this $W$ can be efficiently computed from $(pk, c, Z)$

A canonical identification scheme is $\epsilon_{zk}$-naHVZK \emph{non-abort honest verifier zero knowledge} if there is a simulator that given only $pk$ outputs $(W, c, Z)$ whose distribution has statistical distance at most $\epsilon_{zk}$ from the output distribution of the real protocol conditioned on $P_2( sk, W, c, \St, r_2 ) \ne \perp$.

% Don't need this:
% ***We say $W$ has $\alpha$ \emph{bits of min entropy} if the probability any -- not needed to define

A \emph{lossy identification scheme} is a canonical identification scheme as above together with a lossy key generation algorithm $\LossIGen$, which is a randomised algorithm that on input $1^\lambda$ outputs $pk$.
An adversary against a lossy identification scheme is a randomised algorithm $A$ that takes an input $pk$ and returns $0$ or $1$.
The advantage of an adversary against a lossy identification scheme is 
\[
   \Adv^{\textsf{LOSS}}(A) = \left|
   \Pr\left( A( pk ) = 1 : pk \leftarrow \LossIGen(1^\lambda) \right) - \Pr\left( A( pk ) = 1 : pk \leftarrow \IGen( 1^\lambda ) \right) \right|.
\]
The two security properties of a lossy identification scheme are:
\begin{enumerate}
\item There is no polynomial-time adversary that has non-negligible advantage $\Adv^{\textsf{LOSS}}$ in distinguishing real and lossy keys.
\item The probability, over $(pk, W, c)$ where $pk$ is an output of the lossy key generation algorithm $\LossIGen$, $W \leftarrow \Wset$ and $c \leftarrow \ChSet$, that there is some $Z \in \Zset$ with $\VV( pk, W, c, Z ) = 1$, is negligible.

This will allow to show that no unbounded quantum adversary can pass the identification protocol (or, once we have applied Fiat-Shamir, forge a signature) with respect to a lossy public key, because with overwhelming probability no such signature exists.
\end{enumerate}


\subsection{Scheme}

We can re-write our scheme in this setting, see Figure~\ref{fig:id-scheme}.
Here we are assuming that $E$ is a supersingular elliptic curve with $j(E) \in \F_p$ where $p$ satisfies the constraint
\begin{equation} \label{eq:lossy-p-bound}
  \sqrt{p} > (4(nt+1)B + 1)^{n} 2^\lambda
\end{equation}
This bound is sufficient for the keys to be lossy.


\begin{figure}
\begin{minipage}{.45\textwidth}
\begin{algorithm}[H]
	\caption{$\IGen$}
%	\caption{KeyGen}
	\textbf{Input:} $B$, $\l_1, \dots. \l_n$, $E$

	\textbf{Output:} $sk =\e$ and $pk = E_A$

	\begin{algorithmic}[1]
		\State $\e \leftarrow [-B,B]^n$ 
		\State $E_A = ( \prod_{i=1}^n \l_i^{e_i} ) * E$
		\State \Return $sk= \e$, $pk = E_A$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{$\PP_1$}
	\textbf{Input:} $(E,E_A)$,  $r_1$

	\textbf{Output:} $W = ( j(\E_1) , \dots, j(\E_t) )$, $\St = (\f_1, \dots, \f_t )$

	\begin{algorithmic}[1]
		\For {$k=1 , \dots , t$}
		\State $\f_k \leftarrow [-(nt+1)B,(nt+1)B]^n$ using $\PRF( r_1 )$
		\State $\E_k = ( \prod_{i=1}^n \l_i^{f_{k,i}} ) * E$
		\EndFor
		\State \Return $( j(\E_1) , \dots, j(\E_t) )$, $(\f_1, \dots, \f_t )$
	\end{algorithmic}
\end{algorithm}
\end{minipage}



\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{$\PP_2$}
	\textbf{Input:} $(E,E_A)$, $\e$, $W$, $c$, $\St$, $r_2$

	\textbf{Output:} $Z = (\z_1, \dots, \z_t)$

	\begin{algorithmic}[1]
		\State Parse $c$ as $b_1 \Vert \cdots \Vert b_t$
		\For {$k=1, \dots, t$}
		\If{$b_k=0$}
		\State $\z_k = \f_k$
		\Else
		\State $\z_k = \f_k - \e$
		\EndIf
		\If{$\z_{k} \not\in [-ntB,ntB]^n$} \State \Return $\bot$ \EndIf
		\EndFor
		\State \Return $\sigma = (\z_1, \dots, \z_t)$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
% \vskip -1.2cm
\begin{algorithm}[H]
	\caption{$\VV$}
	\textbf{Input:} $(E,E_A)$, $(W,c,Z)$

	\textbf{Output:} Valid/Invalid

	\begin{algorithmic}[1]
		\State Parse $W$ as $(j_1 , \dots, j_t)$
		\State Parse $c$ as $b_1 \Vert \cdots \Vert b_t$
		\State Parse $Z$ as $(\z_1, \dots, \z_t)$
		\For {$k=1 , \dots , t$}
		\If{$b_k=0$}
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E$
		\Else
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E_A$
		\EndIf
		\EndFor
		\If{$(j_1, \dots, j_t) = (j(\E_1) , \dots, j(\E_t))$} \State \Return Valid
		\Else \State \Return Invalid \EndIf
	\end{algorithmic}
\end{algorithm}
\end{minipage}
\caption{The identification protocol. Note that $P_1$ does not need $sk$, while $P_2$ does not use $r_2$ (it really is deterministic) and does not use $W$. Also note that the scheme is commitment recoverable. \label{fig:id-scheme}}
\end{figure}


Now we state the generic deterministic signature construction from Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}:
The key generation and signing algorithms are the same as Figure~\ref{fig:id-scheme}. The signing algorithm is given in Figure~\ref{fig:sign}. 

\begin{figure}
\begin{algorithm}[H]
	\caption{Deterministic Signing algorithm}
	\textbf{Input:} $(pk,sk)$, $K$, $\msg$

	\textbf{Output:} $\sigma$

	\begin{algorithmic}[1]
		\State $k = 0$, $Z = \perp$
		\While{$Z = \perp$ and $k \le k_0$}
		\State $(W,\St) = \PP_1( sk, \PRF_K( 0, \msg, k ))$
		\State $c = H( W, \msg )$ 
		\State $Z = \PP_2( sk, W, c, \St, \PRF_K( 1, \msg, k ))$
		\EndWhile
		\If{$Z = \perp$}
		\State \Return $\perp$
		\Else
		\State \Return $(W,Z)$
		\EndIf
	\end{algorithmic}
\end{algorithm}
\caption{The deterministic signature scheme of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}. Here $K$ is a PRF key that is internal to the signing algorithm and is not required for verification. \label{fig:sign}}
\end{figure}


\subsection{Proofs}

We now explain that our identification scheme satisfies the required properties, from which the security of the signature scheme will follow from Theorem 3.1 of~\cite{KLS18}.

We make some heuristic assumptions.
(I'm not sure if all these are needed)
\begin{description}
\item[Heuristic 1:] There are at least $\sqrt{p}$ supersingular elliptic curves with $j$-invariant in $\F_p$.

This assumption, combined with the bound $\sqrt{p} \gg (2(nt+1)B)^n $ of equation~(\ref{eq:lossy-p-bound}), implies that the curves $\E_k$ constructed by algorithm $\PP_1$ are a negligibly small proportion of all such curves.

\item[Heuristic 2:] Each choice of $\f_k \in [-(nt+1)B,(nt+1)B]^n$ gives a unique value for $j(\E_k)$.

This is extremely plausible given equation~(\ref{eq:lossy-p-bound}). It implies that the min-entropy of the values $W$ output by $\PP_1$ is extremely high (more than sufficient for the security proofs).

\item[Heuristic 3:] For each choice of $\f_k \in [-(nt+1)B,(nt+1)B]^{2n}$ except $\f_k = 0$, the ideal class of $\prod_{i=1}^n \l_i^{f_{k,i}}$ is non-trivial.

This is also a reasonable assumption given equation~(\ref{eq:lossy-p-bound}).
\end{description}

Under heuristic assumption 1, we now show that the keys are lossy.
The lossy key generator outputs a pair $(E,E_A$ where $E$ and $E_A$ are randomly sampled supersingular elliptic curves with $j(E), j(E_A) \in \F_p$.
To implement this one constructs a supersingular curve with $j$-invariant in $\F_p$
% using Br{\" o}ker's algorithm~\cite{Bro09} 
and then runs long pseudorandom walks in the isogeny graph until the uniform mixing bounds have applied.

\begin{lemma}\label{lem:isogeny count}
Let parameters satisfy the bound of equation~(\ref{eq:lossy-p-bound}). Assume heuristic 1. Let $(E,E_A)$ be a key output by the lossy key generator. Then with overwhelming probability there is no ideal $\a = \prod_{i=1}^n \l_i^{f_{i}}$ such that $\f \in [-2(nt+1)B,2(nt+1)B]^{n}$ and $j(E_A) = j( \a * E )$.
\end{lemma}

\begin{proof}
If $f_i \in [-2(nt+1)B,2(nt+1)B]$ then there are $4(nt+1)B + 1$ choices for each $f_i$ and so at most $(4 (nt+1)B + 1)^{n}$ choices for $\a$.
Given $E$ it means there are at most that many $j( \a * E )$. Since $E_A$ is uniformly and independently sampled from a set of size at least $\sqrt{p} > (4 (nt+1)B + 1)^{n} 2^\lambda$, the probability that $j(E_A)$ lies in the set of all possible $j( \a * E )$ is at most $1/2^\lambda$, which is negligible. \qed
\end{proof}

Note to self: it is not necessary to consider the birthday paradox in the analysis of Lemma~\ref{lem:isogeny count}. Due to the bound of equation~(\ref{eq:lossy-p-bound}), we are sampling curves far from uniformly and so the probability of a collision is not controlled by the birthday paradox.

We make the following decisional assumption.
I guess one can show, using a hybrid argument, that ability to solve the decisional assumption implies ability to solve the computational assumption of Definition~\ref{defn:ass1p}. So it is not a ``new'' assumption.

\begin{definition}
Consider two distributions on pairs $(E, E_A)$ of supersingular ellptic curves over $\F_p$.
Let $\D_1$ be the output distribution of the algorithm $\IGen$.
Let $\D_2$ be the uniform distribution (i.e., output distribution of the lossy key generation algorithm).
The \emph{decisional short isogeny problem} is to distinguish the two distributions when given one sample.
\end{definition}

The next result shows the second part of the security property for lossy keys.

\begin{lemma}
Let $pk$ be an output of the lossy key generation algorithm $\LossIGen$.
Let $W \leftarrow \Wset$ be an output of $\PP_1$.
Let $c \leftarrow \ChSet$ be a uniformly chosen challenge.
Then the probability that there is some $Z \in \Zset$ with $\VV( pk, W, c, Z ) = 1$, is negligible.
\end{lemma}

\begin{proof}
Let $pk = (E, E_A )$ be an output of $\LossIGen( 1^\lambda )$.
By Lemma~\ref{lem:isogeny count} we have that with overwhelming probability $j(E_A) \ne j( \a * E )$ for all ideals $\a$ of the form in Lemma~\ref{lem:isogeny count}.
Let $W = (j(\E_1), \dots, j(\E_t) )$ be an element of $\Wset$, so that each $\E_k$ is of the form $\a_k * E$ where $\a_k = \prod_i \l_i^{f_{k,i}}$ for $f_{k,i} \in [-(nt+1)B, (nt+1)B ]$.


Let $c \leftarrow \ChSet$ be a uniformly chosen challenge, which means that $c \ne 0$ with overwhelming probability.
Then there is some $k$ with $c_k \ne 0$ and so if $Z$ was to satisfy the verification algorithm
$\VV( pk, W, c, Z ) = 1$ then it would follow that $\z_k$ gives an ideal $\c_k$ such that $j(\E_k) = j( \c_k * E_A )$.
From $\a_k * E  \cong \E_k \cong \c_k * E_A$ it follows that $E_A \cong (\c_k^{-1} \a_k ) * E$.
But $\c_k^{-1} \a_k = \prod_i \l_i^{f_{k,i} - z_{k,i}}$, which violates the claim about $E_A$ corresponding to Lemma~\ref{lem:isogeny count}. Hence $Z$ does not exist and the result is proved. \qed
\end{proof}


Note that Heuristic 2 also shows that there are ``unique responses'' in the sense of Definition 2.7 of~\cite{KLS18} (not just computationally unique, but actually unique). But we won't need this for the result we state.


We now discuss \emph{no-abort honest verifier zero-knowledge} (naHVZK).
This is simply the requirement that there is a simulator that produces transcripts $(W,c,Z)$ that are statistically close to real transcripts output by the protocol.


\begin{lemma}
Our scheme has no-abort honest verifier zero-knowledge.
\end{lemma}

\begin{proof}
This is simple to show in our setting (due to the rejection sampling): Instead of choosing $W = ( j(\prod_i \l_i^{f_{1,i}} * E) \dots, j( \prod_i \l_i^{f_{k,i}} * E ))$, then $c$ and then $Z = (\z_1, \dots, \z_k)$ the simulator chooses $Z$ first, then $c$, and then sets, for $1 \le k \le t$, $j_k = j( \prod_i \l_i^{z_{k,i}} * E )$ when $c_k=0$ and $j_k = j( \prod_i \l_i^{z_{k,i}} * E_A )$ when $c_k = 1$.
Setting $W = (j_1,\dots, j_k)$ it follows that $(W, c, Z )$ is a transcript that satisfies the verification algorith.
Further, the distribution of triples $(W,c,Z)$ is identical to the distribution from the real protocol since, for any choice of the private key, this choice of $W$ would have arisen for some choice of the original vectors $\f_k$. \qed
\end{proof}




\begin{theorem}
Under Heuristics 1, 2, 3 and the restricted class group action problem of Definition~\ref{defn:ass1p}.
The signature scheme has UF-CMA security in the quantum random oracle, with a tight security reduction.
\end{theorem}
 

\begin{proof}
See Theorem 3.1 of~\cite{KLS18}.
In particular this theorem gives a precise statement of the advantage. \qed
\end{proof}





\section{Using the relation lattice}\label{sec:sig-relation-lattice}

This section explains an alternative solution to the problem of representing an ideal class without leaking the private key of the signature scheme.
This variant can be considered if a quantum computer is available during system setup.


Let $\{ \l_1, \dots, \l_n \}$ be a set of $\OO$-ideals that generates $\Cl( \OO )$.
Define $L = \{ (x_1, \dots, x_n ) \in \Z^n : \prod_{i=1}^n \l_i^{x_i} \equiv (1) \}$.
Then $L$ is a rank $n$ lattice with volume equal to $\#\Cl(\OO)$.
We call this the \emph{relation lattice}.

A basis for this lattice can be constructed in subexponential time using classical algorithms~\cite{hafner1989rigorous,biasse_fieker_jacobson_2016} or in probabilistic polynomial time using quantum algorithms (define $f:\Z^n\to\Cl(\OO)$ by $f(x_1,\dots,x_n)=\prod_{i=1}^n\l_i^{x_i}$, then $f$ can be evaluated in polynomial time~\cite{shanks1989gauss,Cohen1993}, and finding a basis for $L=\ker f$ is an instance of the Hidden Subgroup Problem for $\Z^n$, which can be solved in polynomial time using Kitaev's generalization of Shor's algorithm~\cite{kitaev1995hsp}).
The classical approach is not very interesting since the underlying computational assumption is only subexponentially hard for quantum computers, but it might make sense in a certain setting.
The quantum case would make sense in a post-quantum world where a quantum computer can be used to set up the system parameters for the system and then is not required for further use.
It might also be possible to construct $(E, p )$ such that computing the relation lattice is efficent (e.g., constructing $E$ so that $\Cl( \End(E))$ has smooth order), but we do not consider such approaches in this paper.

For the remainder of this section we assume that the relation lattice is known.
Let $\{ \x_1, \dots, \x_n \}$ be a basis for $L$
Let $\FF = \{ \sum_{i=1}^n : u_i \x_i : -1/2 \le u_i < 1/2 \}$ be the centered fundamental domain of the basis of $L$.
Then there is a one-to-one correspondence between $\FF \cap \Z^n$ and $\Cl(\OO)$ by
$(z_1, \dots, z_n ) \in \FF \cap \Z^n  \mapsto \prod_{i=1}^n \l_i^{z_i}$.
In practice one prefers a basis for $L$ so that all vectors in $\FF$ have relatively short norm, which is achieved by taking the basis to be as short and close to orthogonal as possible. Hence one applies lattice basis reduction to obtain as ``nice'' a basis for $L$ as possible.

Note that, given a basis $\{ \x_1, \dots, \x_n \}$ for $L$ and a vector $\z = (z_1, \dots, z_n ) \in \Z^n$ one can efficiently compute the unique vector in $\FF \cap (\z + L )$ using the Babai rounding method~\cite{Bab86}.



Returning to Stolbunov's signature scheme, the solution to the problem is then straightforward:
Given $\a = \prod_{i=1}^n \l_i^{e_i}$ and $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$,
a representation of $\b_k \a^{-1}$ is obtained by computing the vector $\z' = \f_k - \e = (f_{k,i} - e_i)$
and then using Babai rounding to get the unique vector $\z$ in $\FF \cap (\z' + L )$.
The vector $\z$ is sent as the response to the $k$-th challenge.
Since $\b_k$ is a uniformly chosen ideal class, the class $\b_k \a^{-1}$ is also uniformly distributed as an ideal class, and hence the vector $\z \in \FF \cap \Z^n$ is uniformly distributed and carries no information about the private key.

\begin{lemma}
If $\b_k$ is a uniformly chosen ideal class then the vector 
$\z \in \FF \cap \Z^n$ corresponding to $\f_k - \e$ is uniformly distributed.
\end{lemma}

\begin{proof}
For fixed $\e$ the vector $\z$ depends only on the ideal class of $\b_k$.
But $\b_k$ is uniform and independent of $\e$ and not known to verifier. \qed
\end{proof}



If the basis for $L$ is sufficiently nice then one can obtain good bounds on the size of the vectors $\z$; for example some details are given in~\cite{BS18}.

One final remark: In the security proof we need to be able to simulate the signing oracle, and hence we need to produce uniformly chosen vectors $\z \in \FF \cap \Z^n$.
The simplest way to do this is to uniformly sample $\z'$ in a large box in $\Z^n$ and then apply Babai rounding as above.
Proving anything about this seems to be hard: How large is the box? How close to uniform?
This ended up in the ``too hard'' pile.


\begin{lemma} \label{lem:sim1}
Let $B \in \N$. Let $\D_1$ be the distribution on ideal classes obtained by computing $\prod_{i=1}^n \l_i^{x_i}$ over uniformly sampled $x_i \in [-B,B]$.
Suppose the statistical distance between $\D_1$ and the uniform distribution on $\Cl(\OO)$ is bounded by $\epsilon$.
Let $\D_2$ be the distribution on $\FF \cap \Z^n$ defined by uniformly sampling vectors $\x \in [-B,B]^n$ and applying Babai rounding.
Let $U$ be the uniform distribution on $\FF \cap \Z^n$.
Then the statistical distance between $\D_2$ and $U$ is at most $\epsilon$.
\end{lemma}

Note $[-B,B]$ is the set of integers $u$ with $-B \le u \le B$.


\begin{proof}
They are the same thing. \qed
\end{proof}


One can then prove a variant of Theorem~\ref{thm:security-basic} and all the theorems in the paper. This approach should give rise to much smaller signatures -- close to optimal size given the subexponential security of the class group action problem.

\end{document}





