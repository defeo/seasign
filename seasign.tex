\documentclass{llncs}

%\usepackage{amsmath,amssymb}
\usepackage{amsmath,amssymb}
\usepackage{times}
\usepackage{algorithm,algorithmicx,algpseudocode}
\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{pdflscape}
\usepackage{fp}
\usepackage{tikz}
\usepgflibrary{fpu,fixedpointarithmetic}

\usepackage{hyperref}
\hypersetup{
	unicode=true,
	colorlinks=true,
	citecolor=blue!70!black,
	filecolor=black,
	linkcolor=red!70!black,
	urlcolor=blue,
	pdfstartview={FitH},
}

%\renewcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Fpbar}{\overline{\mathbb{F}}_p}
\newcommand{\Fqbar}{\overline{\mathbb{F}}_q}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\OO}{\mathcal{O}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
%\newcommand{\ch}{\text{ch}}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Cl}{Cl}
\newcommand{\seed}{\mathsf{seed}}
\newcommand{\msg}{\mathsf{msg}}
\newcommand{\PK}{\mathsf{PK}}
\newcommand{\SK}{\mathsf{SK}}

\renewcommand{\a}{\mathfrak{a}}
\renewcommand{\b}{\mathfrak{b}}
\let\cedil\c
\renewcommand{\c}{\mathfrak{c}}
\renewcommand{\l}{\mathfrak{l}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\f}{\mathbf{f}}
\newcommand{\g}{\mathfrak{g}}
\renewcommand{\v}{\mathbf{v}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\z}{\mathbf{z}}

\DeclareMathOperator{\Adv}{Adv}

\newcommand{\KeyGen}{\mathsf{KeyGen}}
\newcommand{\Sign}{\mathsf{Sign}}
\newcommand{\Verify}{\mathsf{Verify}}
\newcommand{\IGen}{\mathsf{IGen}}
\newcommand{\PP}{\mathsf{P}}
\newcommand{\VV}{\mathsf{V}}
\newcommand{\Wset}{\mathcal{W}}
\newcommand{\Zset}{\mathcal{Z}}
\newcommand{\ChSet}{\textsf{ChSet}}
\newcommand{\St}{\textsf{st}}
\newcommand{\LossIGen}{\mathsf{LossIGen}}
\newcommand{\PRF}{\mathsf{PRF}}
\newcommand{\PRFk}{\PRF_{\mathrm{key}}}
\newcommand{\PRFm}{\PRF_{\mathrm{mask}}}
\newcommand{\PRFs}{\PRF_{\mathrm{secret}}}

% THEOREM ENVIRONMENTS
%\newtheorem{definition}{Definition}
%\newtheorem{example}{Example}
%\newtheorem{theorem}{Theorem}

\newcommand{\longversion}[1]{}
\newcommand{\shortversion}[1]{#1}

\title{SeaSign: Compact isogeny signatures from class group actions}

\author{Luca De Feo\inst{1}\orcidID{0000-0002-9321-0773}
 \and Steven D. Galbraith\inst{2}\orcidID{0000-0001-7114-8377}}
\institute{
Universit{\' e} Paris-Saclay -- UVSQ, LMV, UMR CNRS 8100, Versailles, FR.
\url{https://defeo.lu/}
\and
Mathematics Department, University of Auckland, NZ.
\email{s.galbraith@auckland.ac.nz}
}



%\date{\today}


\begin{document}
\pagestyle{plain}

\maketitle


\begin{abstract}
We give a new signature scheme for isogenies that combines the class group actions of CSIDH with the notion of Fiat-Shamir with aborts.
Our techniques allow to have signatures of size less than one kilobyte at the 128-bit security level, even with tight security reduction (to a non-standard problem) in the quantum random oracle model.
Hence our signatures are potentially shorter than lattice signatures, but signing and verification are currently very expensive.
\end{abstract}



\section{Introduction}

Stolbunov~\cite{Sto12} was the first to sketch a signature scheme based on isogeny problems.
Stolbunov's scheme is in the framework of class group actions.
However the scheme was not analysed in the post-quantum setting, and a naive implementation would leak the private key.
Due to renewed interest in class group actions, especially CSIDH~\cite{CLMPR18} (due to Castryck, Lange, Martindale, Panny and Renes) and the scheme by De Feo, Kieffer and Smith~\cite{DFKS18}, it is of interest to develop a secure signature scheme in this setting.
Our main contribution is to use Lyubashevsky's ``Fiat-Shamir with aborts'' strategy~\cite{Lyu09} to obtain a secure signature scheme.
We also describe some methods to obtain much shorter signatures than in Stolbunov's original proposal.




Currently it is a major problem to get practical signatures from isogeny problems.
Yoo \emph{et al.} (see Table~1 of~\cite{YAJJS17}) state signatures of over 100~KiB
and signing/ve\-ri\-fi\-ca\-tion that take a few seconds on a PC.
This can be reduced using some optimisations. For example~\cite{GPS17} state approximately 12~KiB for this signature scheme (for classical 128-bit security level) and approximately 11~KiB for their main scheme.
In contrast, in this paper we are able to get signatures smaller than a kilobyte, which is better even than lattice signatures.
Unfortunately, signing and verification are very slow (the order of minutes), but we 
%might just about be able to live with that in certain applications.
hope that future work (see for example~\cite{DPV19}) will lead to more efficient schemes.


We now briefly summarise the main findings in the paper (for more details see Table~\ref{tab:comparison}).
For the parameters $(n,B) = (74,5)$ as used in CSIDH~\cite{CLMPR18} we propose a signature scheme whose public key is 4~MiB, signature size is 944 bytes, and verification time is under 3 minutes (signing time is three times longer than this on average, since rejection sampling requires repeating the signing algorithm). For the same parameters we show that one can reduce the public key size to only 32 bytes, but this increases the signature size to around 3~KiB and does not add any significant additional cost to signing or verification time.
One can obtain even shorter signatures by taking different choices of parameters, for example taking $(n,B) = (20,3275)$ leads to signatures as small as 416 bytes, but we do not have an estimate of the verification time for these parameters.


The paper is organised as follows.
Section~\ref{sec:basic-scheme} gives the basic signature scheme concept, that was proposed by Stolbunov, and our secure variant based on Fiat-Shamir with aborts.
Section~\ref{sec:smaller-sigs} explains how to get shorter signatures, at the expense of public key size, by using challenges that are more than just a single bit. This optimisation also leads to faster signing and verification.
Section~\ref{sec:smaller-keys} shows how to retain the benefit of shorter signatures, while also having a short public key, by using modified Merkle trees.
\longversion{
Section~\ref{sec:variants} sketches some optimisations and variants.
}
Section~\ref{sec:lossy-keys} shows how to use our scheme in the context of lossy keys, from which we obtain tight security in the quantum random oracle model via the results of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18} (and this security enhancement involves no increase in signature size, though the primes are larger so computations will be somewhat slower).
This is the first time that lossy keys have been used in the isogeny setting.
Section~\ref{sec:sig-relation-lattice} explains that, if a quantum computer is available during parameter generation, then a much more practical signature scheme can be obtained by following the methods in Stolbunov's thesis.


The name ``SeaSign'' is a reference to the name CSIDH, which is pronounced ``sea-side''.




\section{Background and notation}


We use the following notation: 
$\#X$ is the number of elements in a finite set $X$;
$\log$ denotes the logarithm in base $2$;
KiB and MiB denote kilobytes and megabytes respectively;
for $B \in \N$ we denote by $[-B,B]$ the set of integers $u$ with $-B \le u \le B$.


\subsection{Elliptic curves, isogenies, ideal class groups}


References for elliptic curves over finite fields and isogenies are Silverman~\cite{Sil86}, Washington~\cite{Was08}, Galbraith~\cite{Gal12}, Sutherland~\cite{Sut17} and De Feo~\cite{DF17}.
A good reference for ideal class groups and class group actions is Cox~\cite{Cox}.

Let $E$ be an elliptic curve over a field $K$ and let $P \in E( K )$ be a point of order $m$.
Then there is a unique (up to isomorphism) elliptic curve $E'$ and separable isogeny $\phi : E \to E'$ such that $\ker( \phi ) = \langle P \rangle$.
V{\' e}lu~\cite{velu71} gives an algorithm to compute an equation for $E'$ and rational functions that enable to compute $\phi$.
The complexity of this algorithm is linear in $m$ and requires field operations in $K$, so when $K$ is a finite field it has cost $O( m \log( \#K )^2 )$ bit operations using standard arithmetic.
In the worst case (i.e., when $m$ is large) this algorithm is exponential-time.
In practice this computation is only feasible when $m$ is relatively small (say $m < 1000$) and when the field $K$ over which $P$ is defined is not too large (say, at most a few thousand bits)
For an elliptic curve $E$ over a field $K$ we define $\End(E)$ to be the the ring of endomorphisms of $E$ defined over the algebraic closure of $K$, and $\End_K(E)$ to be the the ring of endomorphisms defined over $K$.
Since we are mostly concerned with the CSIDH~\cite{CLMPR18} approach, we will be interested in supersingular elliptic curves $E$ such that $j(E) \in \F_p$, where $p$ is a large prime.
In this case $\End( E )$ is a maximal order in a quaternion algebra, while $\End_{\F_p}(E)$ is an order in the imaginary quadratic field $\Q( \sqrt{-p} )$.
Indeed, $\Z[ \sqrt{-p} ] \subseteq \End_{\F_p}(E)$.

We will be concerned with the ideal class group of the order $\OO = \End_{\F_p}(E)$.
This is the quotient of the group of fractional invertible ideals in $\OO$ by the subgroup of principal fractional invertible ideals.
The principal ideal $(1) = \OO$ is the identity element of the ideal class group.
Given two invertible $\OO$-ideals $\a, \b$ we write $\a \equiv \b$ if $\a$ and $\b$ are equivalent (meaning that $\a \b^{-1}$ is a principal fractional $\OO$-ideal). 


 

\subsection{Class group actions and computational problems}

Let $p$ be a prime.
Let $E$ be an ordinary elliptic curve over $\F_p$ with $\End(E) \cong \OO$ or $E$ a supersingular curve over $\F_p$ with $\End_{\F_p}(E) \cong \OO$ where $\OO$ is an order in an imaginary quadratic field.
Let $\Cl(\OO )$ be the ideal class group of $\OO$.
One can define the action of an $\OO$-ideal $\a$ on the curve $E$ as the image curve $E'$ under the isogeny $\phi : E \to E'$ whose kernel is equal to the subgroup $E[ \a ] = \{ P \in E( \Fpbar ) : \alpha(P) = 0 \; \forall \alpha \in \a \}$.
We denote $E'$ by $\a * E$.

The set $\{ j(E) \}$ of isomorphism classes of elliptic curves with $\End(E) \cong \OO$ is a principal homogeneous space for $\Cl(\OO )$.
Good references for the details are Couveignes~\cite{Couv06} and Stolbunov~\cite{Sto12}.
The key exchange protocol proposed by Couveignes and Stolbunov is for Alice to send $\a * E$ to Bob and Bob to send $\b * E$ to Alice; the shared key is $(\a\b) * E$.


The difficulty is that if $\a\subset\OO$ is an arbitrary ideal then the subgroup $E[ \a ]$ is typically defined over a very large field extension and the computation of $\a*E$ has exponential complexity.
For efficient computation it is necessary to work with ideals that are a product of powers of small prime ideals, so it is necessary to find a ``smooth'' ideal in the ideal class of $\a$.
Techniques for smoothing an ideal class in the context of isogeny computation were first proposed in~\cite{GHS02} and developed further in~\cite{BCL08,JS10,biasse_fieker_jacobson_2016}.
The state of the art is~\cite{biasse_fieker_jacobson_2016} which computes $\a * E$ for any ideal class in subexponential complexity in $\log(\#\Cl(\OO))$.

Since subexponential complexity is not good enough for cryptographic applications it is necessary to choose ideals deliberately of the form $\a = \prod_{i=1}^n \l_i^{e_i}$ where $\l_1, \dots, \l_n$ are split prime $\OO$-ideals of small norm $\ell_i$ and where $(e_1, \dots, e_n)$ is an appropriately chosen vector of exponents.
Then, the action of $\a$ can be computed as a composition of isogenies of degree $\ell_i$.
Throughout the paper we assume that $\{ \l_1, \dots, \l_n \}$ is a set of non-principal prime ideals in $\OO$, generating $\Cl(\OO)$, of norm polynomial in the size of the class group.
Theoretically we have the bounds $\#\Cl(\OO) = O( \sqrt{p} \log(p) )$ and, assuming a generalised Riemann hypothesis, $\ell_i = O( \log(p)^2 )$.
% NdL: Is #Cl(O) = O(..) really what we want to say? â‰ˆ seems more appropriate
In practice one usually takes $\ell_i=O(\log(p))$ for efficiency reasons; heuristically, this is more than enough to generate the class group.

The basic computational assumption is to invert the action of an ideal.
Couveignes called Problem~\ref{defn:ass1} ``vectorisation'' and Stolbunov called it ``Group Action Inverse Problem (GAIP)''.
The CSIDH paper speaks of hard homogeneous spaces and calls the problem ``Key recovery''.

\begin{problem}\label{defn:ass1}
% (GAIP ?? ClAP (Cl Action Problem) ??)
Given two elliptic curves $E$ and $E_A$ tover the same field with $\End(E) = \End(E_A) = \OO$. Find an ideal $\a$ such that $j( E_A ) = j( \a * E )$.
\end{problem}

The best classical algorithms for this problem in the general case have exponential time (at least $\sqrt{ \# \Cl( \OO ) }$ isogeny computations).
Childs, Jao and Soukharev~\cite{childs2014constructing} were the first to point out that this problem can be formulated as a ``hidden shift'' problem, and so quantum algorithms for the hidden shift problem can be applied.
Hence, there are subexponential-time quantum algorithms for Problem~\ref{defn:ass1} based on the quantum algorithms of Kuperberg~\cite{Kup} and Regev~\cite{regev04}. 
It is still an active area of research to assess the exact quantum hardness of these problems; see the recent papers by Biasse-Iezzi-Jacobson~\cite{BIJ18}, Bonnetain-Schrottenloher~\cite{BS18}, Jao-LeGrow-Leonardi-Ruiz-Lopez~\cite{JLGLRL18} and Bernstein-Lange-Martindale-Panny\cite{cryptoeprint:2018:1059}.
But at the very least, Kuperberg's algorithm requires at least $\tilde{O}( 2^{\sqrt{\log(p)/2}} )$ quantum gates, thus taking 
\begin{equation} \label{con1}
   p>2^{2\lambda^2},
\end{equation}
where $\lambda$ is the security parameter,
should be sufficient to make Problem~\ref{defn:ass1} hard for a quantum computer.


If the ideals $\a$ in Problem~\ref{defn:ass1} are sampled uniformly at random then the problem admits a random self-reduction: given an instance $(E, E_A)$ one can choose random ideal classes $\b_1, \b_2$ and construct the instance $(E_1, E_2) = (\b_1 * E, \b_2 * E_A )$, which is now uniformly distributed across the set of pairs of isomorphism classes of curves in the isogeny class.
If $\a'$ is a solution to the instance $(E_1, E_2)$ then any ideal equivalent to the fractional ideal $\a'\b_1 \b_2^{-1}$ is a solution to the original instance.
This is a nice feature for security proofs that is not shared by SIDH~\cite{JDF2011}\footnote{On the other hand, SIDH has the advantage that no subexponential-time algorithm is known to break it.}; we use this idea in Section~\ref{sec:natural-problem}.


As already mentioned, when instantiating the group action in practice, one must choose parameters that make evaluating isogenies of degree $\ell_i$ as efficient as possible.
This is done both by choosing the primes $\ell_i$ to be as small as possible, and also by arranging that the kernel subgroups $E[ \ell_i ]$ are defined over as small a field extension as possible (so that V\'elu's formulas can be used).
In the ordinary case, the best technique currently available to select parameters is due to De~Feo, Kieffer and Smith~\cite{DFKS18}.
% : a prime of a special form is fixed, then elliptic curves are taken at random until a suitable one is found.
Despite the optimisations described in~\cite{DFKS18}, this technique requires years of CPU time to construct a good curve.
Like~\cite{DFKS18}, CSIDH~\cite{CLMPR18} chooses a special prime of the form $p+1 = 4\prod_{i=1}^n\ell_i$, but, instead of ordinary curves, it uses supersingular curves defined over $\F_p$.
This makes the search for a suitable curve virtually instantaneous, and produces very efficient parameters; indeed note that the formula for $p+1$ implies
% $p \equiv 3 \pmod{8}$, and so the maximal order in $\Q(\sqrt{-p})$ is $\Z[ (1 + \sqrt{-p})/2 ]$ and minimal polynomial of generator $\theta = (1 + \sqrt{-p})/2$ is $f(x) = x^2 + x + (p+1)/4$ satisfies $f(x) \equiv x(x+1) \pmod{\ell_i}$
that each prime $\ell_i$ splits in $\Q(\sqrt{-p})$ as a product $(\ell_i) = \l_i \bar{\l}_i$ of distinct prime ideals.
For key exchange, CSIDH samples the exponent vectors $\e = (e_1, \dots, e_n) \in [-B,B]^n \subseteq \Z^n$ for a suitable constant $B$.
% such that $(2B+1)^n\ge\#\Cl(\OO)\approx p\log p$; this ensures that, heuristically, the key space covers all of $\Cl(\OO)$.

This leads to a special case of Problem~\ref{defn:ass1} where the ideals may not be uniformly distributed in the ideal class group. For further discussion see Definition~\ref{defn:sampling-distributions} and the discussion that follows it.
In this special case one can also consider a straightforward meet-in-the-middle attack: Let $E$ and $\a * E$ be given, where $\a = \prod_{i=1}^n \l_i^{e_i}$ over $e_i \in [-B, B]$.
We compute lists (assume $n$ is even)
\[
   L_1 = \left\{ \left( \prod_{i=1}^{n/2} \l_i^{e_i} \right) * E : e_i \in [-B,B] \right\} 
 %\text{ \ \  and \ \  }
 ,
   L_2 = \left\{ \left( \prod_{i=n/2 + 1}^{n} \l_i^{e_i} \right) * E_A : e_i \in [-B,B] \right\}.
\]
If $L_1 \cap L_2 \ne \varnothing$ then we have solved the isogeny problem.
This attack is faster than general methods when the set of ideal classes generated is a small subset of $\Cl( \OO )$.
Hence for security we may require
\begin{equation} \label{con2}
   (2B+1)^n > 2^{2 \lambda},
\end{equation}
where $\lambda$ is the security parameter.
Further, there is a quantum algorithm due to Tani, which is straightforward to adapt to this problem (we refer to Section~5.2 of De Feo, Jao and Pl{\^{u}}t~\cite{FJP14} for details).
This means we might need to take $(2B+1)^n > 2^{3 \lambda}$ to have post-quantum security.
However, recent analyses~\cite{adj+menezes+al-isogenies,cryptoeprint:2019:103} question the pertinence of the complexity models of the meet-in-the-middle and Tani algorithms, and advocate for more relaxed bounds.
% Instead, they claim the fastest algorithm in practice (even considering quantum adversaries) for this problem is based on an approach by van Oorschot and Wiener that takes time $(2B+1)^n/M^{3/2}$, where $M$ is the number of processors.
% Since $M < (2B+1)^{n/3}$ in practice, this cost is larger than $(2B+1)^{n/2}$.

Choosing the best values of $B,n,p$ for large choices of $\lambda$ (e.g., satisfying the constraints of equations~(\ref{con1}) and~(\ref{con2})) is non-trivial, but will generally lead to sampling in a very small subset of the whole ideal class group.


We remark that Kuperberg's algorithm uses the entire class group, and there seems to be no way to improve the algorithm for the case where the ``hidden shift'' is sampled from a distribution far from the uniform distribution.
We leave the study of this question to future work.




By taking into account the best known attacks, the CSIDH authors propose parameters for the three NIST categories~\cite{NIST2016}, as summarised in Table~\ref{tab:csidh-parms}.
Note that in all CSIDH instances the set of sampled ideal classes is (heuristically) likely to cover the whole class group.
Their implementation of the smallest parameter size CSIDH-512 computes one class group action in 40ms on a 3.5GHz processor.


\begin{table}
  \centering
  \begin{tabular}{l | c | c | c | c | c | c | c | c}
    & $n$ & $\lfloor\log_2 p\rfloor$ & $B$ & NIST  & classical  & quantum  & message  & private  \\
    &   &  &  & level &   security &   security &   size &  key size \\

    \hline
    CSIDH-512 &  74 &  510 &  5 & 1 & 127 bits &  62 qbits &  64B &  32B\\
    CSIDH-1024 & 130 & 1019 &  8 & 3 & 257 bits &  94 qbits & 127B &  67B\\
    CSIDH-1792 & 208 & 1786 & 10 & 5 & 449 bits & 129 qbits & 223B & 114B
  \end{tabular}
  \caption{Proposed parameters for CSIDH~\cite{CLMPR18}.  Effective
    parameters $p$, $n$ and $B$ for CSIDH-1024 and CSIDH-1792 were not given
    in the paper, and are produced here following their methodology.
    Message size is the number of bytes to represent a $j$-invariant, and private key size is the space required to store the exponent vector $\e \in \Z^n$.}
  \label{tab:csidh-parms}
\end{table}

% NOTE: do the ``quantum security'' columns need to be updated due to the Bonnetain-Schrottenloher paper?



For our signature schemes we may work with more general primes than considered in CSIDH~\cite{CLMPR18}. For example, CSIDH takes $p+1 = 4\prod_{i=1}^n\ell_i$, whereas we may be able to use fewer primes and just multiply by a random co-factor to get a large enough $p$.




\subsection{Public key signature schemes}

One can describe Fiat-Shamir-type signatures in various ways, including the language of sigma protocols or identification schemes.
In the main body of our paper we mostly work with the language of signatures, and give proofs directly in this formulation.
In Section~\ref{sec:KLS-defns} we use the language of identification schemes, and introduce the terminology fully there.

A \emph{canonical identification scheme} consists of algorithms $(\KeyGen, \PP_1, \PP_2, \VV)$ and a set $\ChSet$. The randomised algorithm $\KeyGen( 1^\lambda )$ outputs a key pair $(pk,sk)$.
The deterministic algorithm $\PP_1$ takes $sk$ and randomness $r_1$ and computes $(W, \St) = P_1( sk, r_1 )$. 
Here $\St$ denotes state information to be passed to $P_2$.
A challenge $c$ is sampled uniformly from $\ChSet$. The deterministic algorithm $P_2$ then computes $Z = P_2( sk, W, c, \St, r_2 )$ or $\perp$, where $r_2$ is the randomness.
The output $\perp$ corresponds to an abort in the ``Fiat-Shamir with aborts'' paradigm.
We require that $\VV( pk, W, c, Z ) = 1$ for a correctly formed transcript $(W,c,Z)$.


A \emph{public key signature scheme} consists of algorithms $\KeyGen, \Sign, \Verify$.
The randomised algorithm $\KeyGen( 1^\lambda )$ outputs a pair $(pk,sk)$, where $\lambda$ is a security parameter.
The randomised algorithm $\Sign$ takes input the private key $sk$ and a message $\msg$, and  outputs $\sigma = \Sign( sk, \msg )$.
The verification algorithm $\Verify( pk, \msg, \sigma )$ returns $0$ or $1$.
We require $\Verify( pk, \msg, \Sign( sk, \msg )) = 1$.

The \emph{Fiat-Shamir transform} is a construction to turn a canonical identification scheme into a public key signature scheme. The main idea is to make the interactive identification scheme into a non-interactive scheme by replacing the challenge $c$ by a hash $H( W, \msg )$.

The standard notion of security is \emph{unforgeability against chosen-message attack (UF-CMA)}.
A UF-CMA adversary against the signature scheme is a randomised poly\-nomial-time algorithm $A$ that plays the following game against a challenger.
The challenger runs $\KeyGen$ to get $(pk,sk)$ and runs $A( pk )$.
The adversary $A$ sends messages $\msg$ to the challenger, and receives $\sigma = \Sign(sk, \msg)$ in return.
The adversary outputs $(\msg^*, \sigma^*)$ and wins if $\Verify( pk, \msg^*, \sigma^* ) = 1$ and if $\msg^*$ was not one of the messages previously sent by the adversary to the challenger.
A signature scheme is UF-CMA secure if there is no polynomial-time adversary that wins with non-negligible probability.



%There are various transforms to turn an ID protocol into a sig scheme for classical or post-quantum security~\cite{AABN02,DFG13,GCZ16,Katz10,Un15,Un17}.



\section{Basic Signature Scheme}\label{sec:basic-scheme}

This section contains our main ideas and presents a basic signature scheme.
We focus in this section on classical adversaries and proofs in the random oracle model.
Hence our signature is based on the traditional Fiat-Shamir transform.
For schemes and analysis against a post-quantum adversary see Section~\ref{sec:lossy-keys}.

For simplicity, we describe our schemes in the setting of a general class group action on a set of $j$-invariants of elliptic curves.
In Section~\ref{sec:CSIDH-implementation} we explain one small subtlety that arises when implementing the scheme in the setting of CSIDH.


\subsection{Stolbunov's scheme}\label{sec:Stolbunov}

Section 2.B of Stolbunov's PhD thesis~\cite{Sto12} contains a sketch of a signature scheme based on isogeny problems (though his description is not complete and he does not give a proof of security).
It is a Fiat-Shamir scheme based on an identification protocol.
Section 4 of Couveignes~\cite{Couv06} also sketches the identification protocol, but does not mention signature schemes.


The public key consists of $E$ and $E_A = \a * E$, where $\a = \prod_{i=1}^n \l_i^{e_i}$ is the private key.
To construct the private key one uniformly chooses an exponent vector $\e = (e_1, \dots, e_n) \in [-B,B]^n \subseteq \Z^n$ for some suitably chosen constant $B$.
Stolbunov assumes the relation lattice for the ideal class group is known, and uses it in Section 2.6.1 to sample ideal classes uniformly at random.
Section~2.6.2 of~\cite{Sto12} suggests an approach to approximate the uniform distribution.

In the identification protocol the prover generates $t$ random ideals $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ for $1 \le k \le t$ and computes $\E_k = \b_k * E$.
Here the exponent vectors $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ are uniformly and independently sampled in a region like $[-B,B]^n$ (Stolbunov assumes these ideal classes are uniformly sampled).
The prover sends $(j( \E_k ) : 1 \le k \le t )$ to the verifier.
The verifier responds with $t$ uniformly chosen challenge bits $b_1, \dots, b_t \in \{0,1\}$.
If $b_k = 0$ the prover responds with $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ and the verifier checks that $j(\E_k) = j( (\prod_{i=1}^n \l_i^{f_{k,i}}) * E )$.
If $b_k = 1$ the prover responds with a representation of $\b_k \a^{-1}$.
When $b_k=1$ the verifier checks that $j(\E_k) = j( (\b_k \a^{-1}) * E_A )$.
A cheating prover (who does not know the private key) can succeed with probability $1/2^t$.

The major problem with the above idea is how to represent the ideal class of $\b_k \a^{-1}$ in a way that does not leak $\a$.
Stolbunov notes that sending the vector $\f_k - \e = (f_{k,i} - e_i )_{1 \le i \le n}$ would not be secure as it would leak the private key.
Instead, Stolbunov (and also Couveignes) work in the setting where the relation lattice in the ideal class group is known; we discuss this further in Section~\ref{sec:sig-relation-lattice}.
%
% he gives a one sentence sketch of a solution that is applicable when the discrete logs of the primes $\l_i$ in the class group are known.
%Couveignes also does not explain how to prevent this leakage.
A main contribution of our paper is to give solutions to this problem (using Fiat-Shamir with aborts) that do not require to know the relation lattice.

To obtain a signature scheme Stolbunov applies the Fiat-Shamir transform, and hence obtains the challenge bits $b_k$ as the hash value $H( j(\E_1), \dots, j(\E_t) , \msg )$ where $H$ is a cryptographic hash function with $t$-bit output and $\msg$ is the message to be signed.
The signature consists of the binary string $b_1\cdots b_t$ and the representations of the ideal classes $\b_k$ when $b_k = 0$ and $\b_k \a^{-1}$ when $b_k = 1$.

The verifier computes, for $1 \le k \le t$, $\E_k = \b_k * E$ when $b_k = 0$ and $\E_k = \b_k \a^{-1} * E_A$ when $b_k = 1$. The verifier then computes $H( j( \E_1), \dots, j(\E_t), \msg )$ and checks whether this is equal to the binary string $b_1\cdots b_t$, and accepts the signature if and only if the strings agree.


We stress that neither Couveignes nor Stolbunov give a secure post-quantum signature scheme.
Both authors assume that the relations in the ideal class group have been computed (Stolbunov needs this to prevent leakage).
%, since he needs to know discrete logs).
However the cost to compute the relations in the ideal class group on a classical computer is in essentially the same asymptotic complexity class as the cost to break the scheme on a quantum computer (using the Kuperberg or Regev algorithms).
Hence it may not make sense to require the Key Generation algorithm of the scheme to compute the relations in the ideal class group.
On the other hand, in the fully post-quantum setting where quantum computers are readily available then the relation lattice can be computed in polynomial time.
We revisit this issue in Section~\ref{sec:sig-relation-lattice}.



%
%The main contribution of this paper is to give a solution to the problem of representing $\b_k \a^{-1}$ without leaking the private key and without needing to compute relations in the ideal class group.
%Our solution uses ideas from lattice cryptography (Fiat-Shamir with aborts) and we describe this in the remainder of the section.
% %An alternative solution requires a basis of a relation lattice in the ideal class group, which can be computed efficiently using a quantum computer. We describe this alternative solution in Appendix~\ref{sec:sig-relation-lattice}.





\subsection{Using rejection sampling}\label{sec:sig-reject-sample}

% The approach in Section~\ref{sec:sig-relation-lattice} is theoretically elegant, but the assumption that the relation lattice $L$ can be computed is doubtful for practical post-quantum signatures.
%Hence this section contains our main solution to the problem of representing the ideal class $\b_k \a^{-1}$.
To prevent signatures from leaking the private key, we use rejection sampling in exactly the way proposed by Lyubashevsky~\cite{Lyu09} in the context of lattice signatures.

Let $B > 0$ be a constant. When generating the private key we sample uniformly $e_i \in [-B, B]$ for $1 \le i \le n$. Let $\e = ( e_1, \dots, e_n )$.
The value $B$ may be chosen large enough that $\prod_{i=1}^n \l_i^{e_i}$ covers most ideal classes and so that the output distribution is close to uniformly distributed in $\Cl(\OO)$, but we avoid any explicit requirement or assumption that this distribution is uniform.
We refer to Definition~\ref{defn:sampling-distributions} for more discussion of this issue, and in Section~\ref{sec:lossy-keys} we consider a variant where the ideals are definitely not distributed uniformly in $\Cl(\OO)$.

Exponents $f_{k,i}$ are sampled uniformly in $[-(nt+1)B, (nt+1)B]$, where $t$ is the number of parallel rounds of the identification/signature protocol and $n$ is the number of primes.
Let $\f_k = (f_{k,1}, \dots, f_{k,n} )$, $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ and define $\E_k = \b_k * E $.


If the $k$-th challenge bit $b_k$ is zero then the prover responds with $\f_k = ( f_{k,1}, \dots, f_{k,n} )$ and the verifier checks that $j(\E_k) = j( (\prod_{i=1}^n \l_i^{f_{k,i}}) * E )$ as in the basic scheme above.\footnote{In the scheme and analysis we apply rejection sampling to the case $b_k = 0$ as well as the case $b_k = 1$. An alternative would be to only apply rejection sampling in the case $b_k = 1$. It doesn't really matter one way or the other, since in both settings we are able to simulate a signer in the random oracle model and so the security proof works.}
If $b_k = 1$ then the prover is required to provide a representation of $\b_k \a^{-1}$, the idea is to compute the vector $\z_k = (z_{k,1}, \dots, z_{k,n}) $ defined by $z_{k,i} = f_{k,i} - e_i $ for $1 \le i \le n$.
As already noted, outputting $\z$ directly would potentially leak the secret.
To prevent this leakage we only output $\z_k$ if all its entries satisfy $| z_{k,i} | \le nt B$.
We give the signature scheme in Figure~\ref{fig:sig-scheme}.
It remains to show that in the accepting case the vector leaks no information about the private key, and that the rejecting case occurs with low probability. We do this in the following two lemmas.

\begin{lemma} \label{lem:sim2}
The distribution of vectors $\z_k$ output by the signing algorithm is the uniform distribution and therefore is independent of the private key $\e$.
\end{lemma}

\begin{proof}
Let $U = [-(nt+1)B, (nt+1)B]$. Then $\#U = 2(nt + 1)B + 1$.
If $e \in [-B, B]$ then 
\[
    [-ntB, ntB] \subseteq  U - e = \{ f - e : f \in U \} \subseteq [-(nt+2)B, (nt+2)B ].
\]
Hence, when rejection sampling (only outputting values $f_{k,i} - e_i$ in the range $[-ntB, ntB]$) is applied then the output distribution of $\z_k$ is the uniform distribution on $[-ntB, ntB]^n$.
This argument does not depend on the choice of $\e$, so the output distribution is independent of $\e$. \qed
\end{proof}












%\begin{figure}[!htb]
\begin{figure}
\begin{minipage}{.45\textwidth}
\begin{algorithm}[H]
	\caption{KeyGen \label{alg:KeyGen}}
%	\caption{KeyGen}
	\textbf{Input:} $B$, $\l_1, \dots, \l_n$, $E$

	\textbf{Output:} $sk =\e$ and $pk = E_A$

	\begin{algorithmic}[1]
		\State $\e \leftarrow [-B,B]^n$ 
		\State $E_A = ( \prod_{i=1}^n \l_i^{e_i} ) * E$
		\State \Return $sk= \e$, $pk = E_A$
	\end{algorithmic}
\end{algorithm}

\vskip -1.2cm

\begin{algorithm}[H]
	\caption{Sign \label{alg:Sign}}
	\textbf{Input:} $\msg$, $(E,E_A)$, $\e$

	\textbf{Output:} $(\z_1, \dots, \z_t , b_1 , \dots, b_t)$

	\begin{algorithmic}[1]
		\For {$k=1 , \dots , t$}
		\State $\f_k \leftarrow [-(nt+1)B,(nt+1)B]^n$ 
		\State $\E_k = ( \prod_{i=1}^n \l_i^{f_{k,i}} ) * E$
		\EndFor
		\State $b_1 \Vert \cdots \Vert b_t = H( j(\E_1) , \dots, j(\E_t), \msg )$
		\For {$k=1, \dots, t$}
		\If{$b_k=0$}
		\State $\z_k = \f_k$
		\Else
		\State $\z_k = \f_k - \e$
		\EndIf
		\If{$\z_{k} \not\in [-ntB,ntB]^n$} \State \Return $\bot$ \EndIf
		\EndFor
		\State \Return $\sigma = (\z_1, \dots, \z_t , b_1 , \dots, b_t)$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{Verify \label{alg:Verify}}
	\textbf{Input:} $\msg$, $(E,E_A)$, $\sigma$

	\textbf{Output:} Valid/Invalid

	\begin{algorithmic}[1]
		\State Parse $\sigma$ as $(\z_1, \dots, \z_t, b_1 , \dots, b_t)$
		\For {$k=1 , \dots , t$}
		\If{$b_k=0$}
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E$
		\Else
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E_A$
		\EndIf
		\EndFor
		\State $b_1' \Vert \cdots \Vert b_t' = H( j(\E_1) , \dots, j(\E_t), \msg )$
		\If{$(b_1', \dots, b_t') = (b_1 , \dots, b_t)$} \State \Return Valid
		\Else \State \Return Invalid \EndIf
	\end{algorithmic}
\end{algorithm}
\end{minipage}
\caption{The basic signature scheme using rejection sampling.\label{fig:sig-scheme}}
\end{figure}






\begin{lemma}\label{lem:rejection}
The probability that the signing algorithm outputs a signature (i.e., does not output $\bot$) is at least $1/e > 1/3$.
\end{lemma}

\begin{proof}
Let notation be as in the proof of Lemma~\ref{lem:sim2}.
For fixed $e \in [-B, B]$ and uniformly sampled $f \in U = [-(nt+1)B, (nt+1)B]$, the probability that a value $f-e$ lies in $[-ntB, ntB]$ is
\[
   \frac{2ntB + 1}{2(nt+1)B + 1}  = 1 - \frac{2B}{2(nt+1)B + 1} \ge 1 - \frac{1}{nt+1}.
\]
Hence, the probability that all of the values $z_{k,i}$ over $1 \le k \le t, 1 \le i \le n$ lie in $[-ntB, ntB]$ is at least $(1 - 1/(nt+1))^{nt}$.
% Proof of the inequality: graph the functions
Using the inequality $1 - 1/(x+1) \ge e^{-1/x}$ for $x \ge 1$ it follows that the probability that all values are in the desired range is at least
\[
   \left( e^{-1/nt} \right)^{nt} = e^{-1}.
\]
This completes the proof. \qed
\end{proof}





We can therefore get a rough idea of parameters and efficiency for the scheme.
Let $\lambda$ be a security parameter (e.g., $\lambda=128$ or $\lambda=256$), for security
we need at least $t=\lambda$ so that an attacker cannot guess the hash value or invert the hash function (see also the proof of Theorem~\ref{thm:security-basic}).
We also need a large enough set of private keys, so we need $(2B+1)^n$ large enough.
The signature contains one hash value of $t$ bits, plus $t$ vectors $\f_k$ or $\z_k$ with entries of size bounded by $(nt+1)B$, for a total of $\lambda + t\lceil n\log(2(nt+1)B + 1)\rceil$ bits (assuming each vector is represented optimally). If we take $t=\lambda=128$, and $(n,B)=(74,5)$ as in CSIDH-512, we obtain signatures of around 20~KiB (see also Table~\ref{tab:comparison}).

To sign/verify one needs to evaluate the action of either of $\b_k$ and $\b_k\a^{-1}$ for every $1\le k\le t$,
which means that for each $k$ and each prime $\l_i$ one needs to compute up to $ntB$ isogenies of degree $\ell_i$.
Hence, the total number of isogeny computations is upper bounded by $(nt)^2 B$.
The quadratic dependence on $nt$ is a major inconvenience.
For example, taking $(n,t,B)=(74,128,5)$ gives around $2^{28}$ isogeny computations in signature/verification.
We can make $t$ small using the techniques in later sections, but one needs $n$ large unless $B$ is going to get very large. So even going down to $t=8$ still has signatures requiring around $2^{20}$ isogeny computations.
The acceptance probability estimate from Lemma~\ref{lem:rejection} is very close to the true value: for example, when $(n,t,B)=(74,128,5)$ then the true acceptance probability is approximately $0.36790$, while $e^{-1} \approx 0.36788$.

\longversion{
We discuss some possible optimisations in Section~\ref{sec:variants}, including the idea to use discrete Gaussians instead of uniform distributions for the vectors.
}

%
%% NOTE: $n=50, B=6$ is too small, as $(2B+1)^n \approx 2^{185}$. So I updated the above.
%Here is a table, for various $n$, of the smallest $B$ such that $(2B+1)^n > 2^{255}$.
%Maybe it would be better the other way around: smallest $n$ for various values of $B$.
%
%TODO: do we need this table? It's complicated going beyond $n\ge 74$, because then we have to take a larger $p$ and we're out of the CSIDH setting. And, among the other pairs, (74,5) is the optimum in terms of computation time (the worst in terms of sig size, though).
%
%\begin{center}
%\begin{tabular}{c||c|c|c|c|c|c|c|c|c|c}
% $n$     & 50 & 55 & 60 & 65 & 70 & 75 & 80 & 85 & 90 & 95 \\
%\hline
% min $B$ & 17 & 12 & 10 &  8 &  6 &  5 &  5 &  4 &  4 &  3 \\
%\end{tabular}
%\end{center}



\subsection{CSIDH implementation} \label{sec:CSIDH-implementation}

The above description represents the isomorphism class of $\a * E$ using a $j$-invariant.
But, as explained in~\cite{DG16,CLMPR18}, in the case of supersingular curves over $\F_p$ there are two isomorphism classes for each $j$-invariant and so the $j$-invariant alone is not an adequate representation for $\a * E$.
Castryck \emph{et al.}~\cite{CLMPR18} observe that the Montgomery model for these curves provides an elegant solution to the dilemma.
Instead of representing $\a * E$ with a $j$-invariant one uses the ``$A$ coefficient'' of the Montgomery equation.
This works when choosing $p \equiv 3 \pmod{8}$ and using curves whose endomorphism ring is on the ``floor'' of the 2-isogeny volcano; we refer to Proposition~8 of~\cite{CLMPR18} for the details. 

In short, when implementing our signature schemes using CSIDH one should choose $p \equiv 3 \pmod{8}$ and replace the words ``$j$-invariant'' by ``Montgomery coefficient''.
In terms of the security analysis, strictly speaking the security proofs use variants of the computational problems expressed in terms of Montgomery coefficients.
It is a simple exercise to show that these problems are equivalent to problems expressed using $j$-invariants.
Hence the theorem statements in our paper are all correct in the setting of CSIDH.




\subsection{Security proof}
\label{sec:security-proof}

We now prove security of the basic scheme in the random oracle model against a classical adversary. 
%The proof covers both cases.
The proof technique is the standard approach that uses the forking lemma.
In this section we do not consider quantum adversaries, or give a proof in the quantum random oracle model (QROM).
A proof in the QROM follows from the approach in Section~\ref{sec:lossy-keys}.

First we need to discuss some subtleties about the distribution of ideal classes coming from the key generation and signing algorithms.

\begin{definition} \label{defn:sampling-distributions}
Fix distinct ideals $\l_1, \dots, \l_n$.
For $B \in \N$, consider the random variable $\a$ which is the ideal class of $\prod_{i=1}^n \l_i^{e_i}$ over a uniformly random $\e \in [-B,B]^n$.
Define $\D_B$ to be the distribution on $\Cl( \OO )$ corresponding to this random variable.
%
Define $M_B$ to be an upper bound on the probability, over $\a, \b$ sampled from $\D_B$, that $\a \equiv \b$.
\end{definition}

In other words, $\D_B$ is the output distribution of the public key generation algorithm.
Understanding the distribution $\D_B$ is non-trivial in general.\footnote{Even the analogous problem of understanding the distribution of $\prod_i \ell_i^{e_i} \pmod{q}$, where $\ell_i$ are small primes and $q$ is some integer, is an open problem in general.}
For small $B$ and $n$ (so that $(2B+1)^n \ll \#\Cl(\OO)$) we expect $\D_B$ to be the uniform distribution on a subset of $\Cl(\OO)$ of size $(2B+1)^n$. For fixed $n$ and large enough $B$ it should be the case that $\D_B$ is very close to the uniform distribution on $\Cl(\OO)$.
A full study of the distribution $\D_B$ is beyond the scope of this paper, but is a good problem for future work.

For the isogeny problem to be hard for public keys we certainly need $M_B \le 1/2^\lambda$, where $\lambda$ is the security parameter.
In the proof we will need to use $M_{ntB}$, since the concern is about the auxiliary curves generated during the signing algorithm. We do not require these curves to be uniformly sampled, but in practice we can certainly assume that $M_{ntB} = O( 1/\sqrt{p} )$. In any case, it is negligible in the security parameter.



\begin{problem} \label{defn:ass1p}
% (Restricted ideal action problem ***)
Let notation be as in the key generation protocol of the scheme.
Given $(E, E_A)$, where $E_A = \a * E$ for some ideal $\a = \prod_{i=1}^n \l_i^{e_i}$ and where the exponent vector $\e = (e_1, \dots, e_n)$ is uniformly sampled in $[-B,B]^n \subseteq \Z^n$, to compute any ideal equivalent to $\a$.
\end{problem}

Depending on how close to uniform is the distribution $\D_B$, this problem may or may not be equivalent to Problem~\ref{defn:ass1} and may or may not have a random self-reduction.
Nevertheless, we believe this is a plausible assumption.


We recall the forking lemma, in the formulation of Bellare and Neven~\cite{BN06}.

\begin{lemma} \label{forking-lemma} (Bellare and Neven~\cite{BN06})
Fix an integer $Q \ge 1$. Let $A$ be a randomised algorithm that takes as input $h_1, \dots, h_Q \in \{0,1\}^t$ and outputs $(J, \sigma)$ where $ 1\le J \le Q$ with probability $\wp$.
Consider the following experiment: $h_1, \dots, h_Q$ are chosen uniformly at random in $\{0,1\}^t$; $A(h_1, \dots, h_Q )$ returns $(I,\sigma)$ such that $I \ge 1$; $h_I', \dots, h_Q'$ are chosen uniformly at random in $\{0,1\}^t$; $A( h_1, \dots, h_{I-1}, h_I', \dots, h_Q' )$ returns $(I', \sigma')$.
Then the probability that $I' = I$ and $h_{I}' \ne h_I$ is at least $\wp( \wp/Q - 1/2^t )$.
\end{lemma}


\begin{theorem}\label{thm:security-basic}
In the random oracle model, the basic signature scheme of Figure~\ref{fig:sig-scheme} is unforgeable under a chosen message attack under the assumption that Problem~\ref{defn:ass1p} is hard.
\end{theorem}

\begin{proof}
Consider a polynomial-time adversary $A$ against the signature scheme. So $A$ takes a public key, makes queries to the hash function $H$ and the signing oracle, and outputs a forgery of a signature with respect the public key.

Let $(E, E_A = \a * E )$ be an instance of Problem~\ref{defn:ass1p}.
The simulator runs the adversary $A$ with public key $(E, E_A)$.
% (or apply the random self-reduction mentioned earlier) in the random oracle model.

Suppose the adversary $A$ makes at most $Q$ (polynomial in the security parameter) queries in total to either the random oracle $H$ or the signing oracle. We now explain how the simulator responds to these queries. The simulator maintains a list, initially empty, of pairs $(x, H(x))$ for each value of the random oracle that has been defined.

\vskip 0.1cm

\noindent \textbf{Sign queries:}
To answer a Sign query on message $\msg$ the simulator chooses 
$t$ uniformly chosen bits $b_1, \dots, b_t \in \{0,1\}$.
When $b_k = 0$ the simulator randomly samples $z_k \leftarrow [-ntB,ntB]^n$ and sets $\b_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ and computes $\E_k = \b_k * E$, just like in the real signing algorithm.
When $b_k = 1$ the simulator chooses a random ideal $\c_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ for $z_{k,i} \in [-ntB, ntB]$
%(consistent with the protocol under consideration; so using Lemma~\ref{lem:sim2}) 
and computes $\E_k = \c_k * E_A$.
By Lemma~\ref{lem:sim2}, the values $j( \E_k )$ and $\z_k$ are distributed exactly as in the real signing algorithm.
We program the random oracle (update the hash list) so that $H( j( \E_1), \dots, j(\E_t), \msg ) := b_1 \cdots b_t$, unless the random oracle has already been defined on this input in which case the simulation fails and outputs $\perp$.
The probability of failure is at most $Q/M_{ntB}^t$, 
where $M_{ntB}$ is defined in Definition~\ref{defn:sampling-distributions} to be an upper bound on the probability of a collision in the sampling of ideal classes.
Note that $Q/M_{ntB}^t$ is negligible.
Assuming the simulation does not fail, the output is a valid signature and is indistinguishable from signatures output by the real scheme in the random oracle model.

\vskip 0.1cm

\noindent \textbf{Hash queries:}
To answer a random oracle query on input $x$ the simulator checks if $(x,y)$ already appears in the list, and if so returns $y$. Otherwise the simulator chooses uniformly at random $y \in \{0,1\}^t$ and sets $H(x) := y$ and adds $(x,y)$ to the list.

\vskip 0.1cm

Eventually $A$ outputs a forgery $(\msg, \sigma = (\z_1, \dots, \z_t, b_1\cdots b_t))$ that passes the verification equation.
Define $\c_k = \prod_i \l_i^{z_{k,i}}$.
The proof now invokes the Forking Lemma (see Bellare-Neven~\cite{BN06}). The adversary is replayed with the same random tape and the exact same simulation, except that one of the hash queries is answered with a different binary string.
With non-negligible probability the adversary outputs a forgery $\sigma = (\z_1', \dots, \z_t', b_1'\cdots b_t')$ for the same message $\msg$ and the same input $(j(\E_1), \dots, j(\E_t), \msg)$ to $H$, but a different output string $b_1'\cdots b_t'$. Let $k$ be an index such that $b_k \ne b_k'$ (without loss of generality $b_k = 0$ and $b_k' = 1$). Then the ideal classes $\c_k$ and $\c_k'$ in the two signatures are such that $j( \c_k * E ) = j( \c_k' * E_A )$ and so $\c_k' \c_k^{-1} = \prod_i \l_i^{z_{k,i}' - z_{k,i}}$ is a solution to the problem instance. \qed
\end{proof}


We make two observations about the use of the forking lemma.
First, as always, the proof is not tight since if the adversary succeeds with probability $\epsilon$ then the simulator solves the computational problem with probability proportional to $\epsilon^2$.
Second, the hash output length $t$ in Lemma~\ref{forking-lemma} only appears in the term $1/2^t$, so it suffices to take $t = \lambda$.
There may be situations where a larger hash output is needed; for more discussion about hash output sizes we refer to Neven, Smart and Warinschi~\cite{NSW09}.




\section{Smaller signatures and faster signing/verification}\label{sec:smaller-sigs}


The signature size of the basic scheme is rather large (around 20~KiB), since the sigma protocol that underlies the identification scheme only has single bit challenges. 
In practice we need $t \ge 128$, which means signatures are very large.
To get shorter signatures it is natural to try to increase the size of the challenges.
In this section we sketch an approach to obtain $s$-bit challenge values for any small integer $s \in \N$, by trading the challenge size with the public key size. 
This optimisation also dramatically speeds up signing and verification.
In the next section we explain how to shorten the public keys again.


The basic idea is to have public keys $( E_{A,0} = \a_0 * E , \dots , E_{A,2^s-1} = \a_{2^s-1} * E )$.
For each $0 \le m < 2^s$ we choose $\e_m \leftarrow [-B,B]^n$ and set $E_{A,m} = ( \prod_{i=1}^n \l_i^{e_{m,i}} ) * E$.
The signing algorithm for user A chooses $t$ random ideals $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$ and computes $\E_k = \b_k * E$, as before.
Now we have $s$-bit challenges $b_1, \dots, b_t \in \{0, 1, \dots, 2^s-1 \}$.
For each $1 \le k \le t$ the signer computes $\z_k = \f_k - \e_{b_k}$, which corresponds to the ideal class $\c_k = \b_k \a_{b_k}^{-1} $ and the verifier can check that $j( \E_k ) = j( \c_k * E_{A, b_k})$.

A signature consists of one hash value, plus $t$ vectors $\z_k$ with entries of size bounded by $ntB$, i.e., a total of $\lambda + t\lceil n\log(2ntB + 1)\rceil$ bits, similar to the previous section.
But now for security we only require $ts \ge \lambda$.
Taking, say, $\lambda = 128$ and $s = 16$ can mean $t$ as low as 8, and so only 8 vectors need to be transmitted as part of the signature, giving signatures of well under 1~KiB (see Table~\ref{tab:alt-params}).
Of course the public key now includes $2^{16}$ $j$-invariants (elements of $\F_p$) which would be around 4~MiB, and key generation is also $2^{16}$ times slower.


As far as we can tell, this idea cannot be applied to the schemes of Yoo \emph{et al.}~\cite{YAJJS17} or Galbraith \emph{et al.}~\cite{GPS17}.


%What params should we use for signatures. Can get sigs as low as we want by ignoring computation time.
%Limiting case is $n=1$ and $B = 2^{256}$ giving $32 + 16 = 48$ byte signatures. Obviously impossible.
%Sweet spot seems to be sigs with around 500 bytes.



\subsection{Security}

A trivial modification to the proof of Theorem~\ref{thm:security-basic} can be applied in this setting. But note that the forking lemma produces two signatures such that $b_k \ne b_k'$ for some index $k$.
Hence from a successful forger we derive two ideal classes $\c_k$ and $\c_k'$ such that $j( \c_k * E_{A, b_k} ) = j( \c_k' * E_{A, b_k'})$. It follows that $(\c_k')^{-1} \c_k$ is an ideal class corresponding to an isogeny $E_{A,b_k} \to E_{A,b_k'}$.
Hence the computational assumption underlying the scheme is the following.

\begin{problem}\label{defn:one-out-of-2s-problem}
% (One out of $2^s$ ideal action problem ***)
Let notation be as in the key generation protocol of the scheme.
Consider a set of $2^s$ elliptic curves $\{ E_{A,0}, \dots, E_{A,2^s-1} \}$, all of the form $E_{A,m} = \a_m * E$ for some ideal $\a_m = \prod_{i=1}^n \l_i^{e_{m,i}}$ where the exponent vectors $\e_m $ are uniformly sampled in $[-B,B]^n \subseteq \Z^n$.
The 
%``one out of $2^s$'' isogeny 
problem is to compute an ideal corresponding to any isogeny $E_{A,m} \to E_{A,m'}$ for some $m \ne m'$.
\end{problem}



We believe this problem is hard for classical and quantum computers. One can easily obtain a non-tight reduction of this problem to Problem~\ref{defn:ass1p}.
However, if the ideals $\a_m$ are not sampled uniformly at random from $\Cl(\OO)$ then we do not know how to obtain a random-self-reduction for this problem, which prevents us from having a tight reduction to Problem~\ref{defn:ass1p}.


\begin{theorem}\label{thm2}
In the random oracle model, the signature scheme of this section is unforgeable under a chosen message attack under the assumption that Problem~\ref{defn:one-out-of-2s-problem} is hard.
\end{theorem}

The proof of this theorem is almost identical to the proof of Theorem~\ref{thm:security-basic} and so is omitted.



\subsection{Variant based on a more natural problem} \label{sec:natural-problem}


Problem~\ref{defn:one-out-of-2s-problem} is a little un-natural.
It would be more pleasing to prove security based on Problem~\ref{defn:ass1} or Problem~\ref{defn:ass1p}.
We now explain that one can prove security based on Problem~\ref{defn:ass1}, under an assumption about uniform sampling of ideal classes.

Suppose in this section that the distribution $\D_B$ of Definition~\ref{defn:sampling-distributions} has negligible statistical distance (Renyi divergence can also be used here) from the uniform distribution.
This assumption is reasonable for bounded $n$ and very large $B$; but we leave for future work to determine whether practical parameters for isogeny based cryptography can be obtained under this constraint.


\begin{lemma}
Let parameters be such that the statistical distance between $\D_B$ and the uniform distribution on $\Cl(\OO)$ is negligible.
Suppose that all the prime ideals $\l_i$ have norm bounded as $O( \log(p) )$
Then given an algorithm that runs in time $T$ and solves Problem~\ref{defn:one-out-of-2s-problem} with probability $\epsilon$, there is an algorithm to solve Problem~\ref{defn:ass1} with time $T + O( 2^s \log(p)^5 )$ and success probability $\epsilon/2$.
\end{lemma}

\begin{proof}
Let $A$ be an algorithm for Problem~\ref{defn:one-out-of-2s-problem}, and let $(E, E_A = \a * E )$ be an instance of Problem~\ref{defn:ass1}.

Choose random ideal classes $\b_0, \dots, \b_{2^s-1}$
(chosen as $\b_m = \prod_{i=1}^n \l_i^{u_{i,m}}$ for $0 \le m < 2^s$ and $u_{i,m} \in [-B,B]$)
and compute $E_{A,m}' = \b_m * E$ for $0 \le m < 2^{s-1}$ and $E_{A,m}' = \b_m * E_A$ for $2^{s-1} \le m < 2^s$. Choose a random permutation $\pi$ on $\{ 0, 1, \dots, 2^s-1 \}$ and construct the sequence $E_{A,m} = E_{A,\pi(m)}'$.
This computation takes $O( 2^s \log(p)^5 )$ bit operations, since $n$ and $B$ and the norm $\ell_i$ of $\l_i$ are all $O( \log(p) )$.
Note that these curves are all uniformly sampled in the isogeny class, and so there is no way to distinguish whether any individual curve has been generated from $E$ or $E_A$.
This is where the subtlety about distributions appears: it is crucial that the curves derived from the pair $(E, E_A)$ are indistinguishable from the curves in Problem~\ref{defn:one-out-of-2s-problem}.

Now run the algorithm $A$ on this input. Since the input is indistinguishable from a real input, $A$ runs in time $T$ and succeeds with probability $\epsilon$.
In the case of success, we have an ideal $\c$ corresponding to an isogeny $E_{A,m} \to E_{A,m'}$ for some $m \ne m'$.
With probability $1/2$ we have that one of the curves, say $E_{A,m}$, is known to the simulator as  $\b * E$ and the other (i.e., $E_{A,m'}$) is known as $\b' * E_A$. If this event occurs then we have $\c \b * E = \b' * E_A$ (or vice versa) in which case $\c \b (\b')^{-1}$ is a solution to the original instance. \qed
\end{proof}


Note that this proof introduces an extra $1/2$ factor in the success probability, but this is not a serious issue since the security proof isn't tight anyway.


Using this result, the following theorem is an immediate consequence of Theorem~\ref{thm2}.

\begin{theorem}
Let parameters be such that the statistical distance between $\D_B$ and the uniform distribution on $\Cl(\OO)$ is negligible.
In the random oracle model, the signature scheme of this section is unforgeable under a chosen message attack under the assumption that Problem~\ref{defn:ass1} is hard.
\end{theorem}


%\begin{proof}
%Let $A$ be an adversary against the scheme and $(E, E_A = \a * E )$ be an instance of Definition~\ref{defn:ass1}.
%
%Choose random ideal classes $\b_0, \dots, \b_{2^s-1}$
%(chosen as $\b_m = \prod_{i=1}^n \l_i^{u_{i,m}}$ for $0 \le m < 2^s$ and $u_{i,m} \in [-B,B]$)
%and compute $E_{A,m}' = \b_m * E$ for $0 \le m < 2^{s-1}$ and $E_{A,m}' = \b_m * E_A$ for $2^{s-1} \le m < 2^s$. Choose a random permutation $\pi$ on $\{ 0, 1, \dots, 2^s-1 \}$ and set the public key to be the sequence $E_{A,m} = E_{A,\pi(m)}'$.
%Note that these curves are all uniformly sampled in the isogeny class, and so there is no way to distinguish whether the curve has been generated from $E$ or $E_A$.
%Now run the adversary on this public key.
%
%This is where the subtlety about distributions appears: it is crucial that the public key derived from the pair $(E, E_A)$ is indistinguishable from public keys output by the key generation algorithm.
%
%The simulator will handle hash and sign queries the same way as in the proof of Theorem~\ref{thm:security-basic}.
%When simulating the sign oracle we first choose the $t$ values $b_1, \dots, b_t \in \{0,1\}^s$, which are interpreted as the challenge values $0 \le b_k < 2^s$.
%For each $1 \le k \le t$ we choose a random ideal class $\c_k = \prod_{i=1}^n \l_i^{z_{k,i}}$ by choosing $z_{k,i} \in [-ntB, ntB]$, and then compute $\E_k = c_k * E_{A,b_k}$.
%One then defines the hash value $H( j(\E_1), \dots, j(\E_t), \msg )$ to be $b_1 \Vert b_2 \Vert \cdots \Vert b_t$.
%This simulation is indistinguishable to the real cryptosystem, assuming the distributions on ideal classes have negligible statistical distance.
%
%When the forking lemma is applied we have, for some index $k$, two different ideals $\c_k, \c_k'$ such that $j( \c_k * E_{A, b_k} ) = j( \c_k' * E_{A, b_k'})$ and $b_k' \ne b_k$
%With probability $1/2$ we have that one of the $E_{A,b_k}$ is known to the simulator as  $\b * E$ and the other is known as $\b' * E_A$. If this event occurs then we have $\c_k \b * E = \c_k' \b' * E_A$ (or vice versa) in which case $(c_k' \b')^{-1} c_k \b$ is a solution to the original instance. \qed
%\end{proof}


%Note that this proof has an extra $1/2$ factor in the success probability, but this is not a serious issue since the security proof isn't tight anyway.
We have a tight proof in Section~\ref{sec:lossy-keys} based on a less standard assumption (see Problem~\ref{defn:decisional-short-isogeny}). It is an open problem to have a tight proof and also the security based on Problem~\ref{defn:ass1}.



%Version 2: Have a computational assumption $(E, \a * E, \a^2 * E, \a^3 * E , \dots, a^{2^s - 1} * E )$ and 3-special soundness implies can get $\a$ with a good probability. This is cute but ultimately pointless.


\subsection{Reducing storage for private keys}\label{sec:private-key-compress}

Rather than storing all the private keys $\a_m$ for $0 \le m < 2^s$ one could have generated them using a pseudorandom function as $\PRF( \seed, i )$ where $\seed$ is a seed and $i$ is used to generate the $i$-th private key (which is an integer exponent vector).
The prover only needs to store $\seed$ and can then recompute the private keys as needed.
Of course, during key generation one needs to compute all the public keys, but during signing one only needs to determine $t \approx 8$ private keys (although this adds a cost to the signing algorithm).




\section{Smaller public keys} \label{sec:smaller-keys}

The approach of Section~\ref{sec:smaller-sigs} gives signatures that are potentially quite small, but at the expense of very large public keys. In some settings (e.g., software signing or licence checks) large public keys can be easily accommodated, while in other settings (e.g., certificate chains) it makes no sense to shorten signatures at the expense of public key size.
In this section we explain how to use techniques from hash-based signatures to compress the public key while also maintaining compact signatures.
The key idea is to use a Merkle tree~\cite{10.1007/0-387-34805-0_21} with leaves the public curves $E_{A,0}, \dots, E_{A,2^s-1}$, and use the tree root (a single hash value) as public key.
However, the security of plain Merkle trees depends on collision resistance of the underlying hash function, thus requiring hashes of size at least twice the security parameter.
Instead, we use a modified Merkle tree, as introduced in the hash-based signatures XMSS-T~\cite{10.1007/978-3-662-49384-7_15} and SPHINCS+~\cite{sphincs+}, whose security relies on the second-preimage resistance of a keyed hash function.

Let $\lambda$ be a security parameter, and let $n,B,s,t,p$ be as in the previous sections; we assume that $\lceil\log p\rceil > 2\lambda$, as this is the case in any secure instantiation.
Let the following (public) functions be given:

\begin{itemize}
\item $\PRFs: \{0,1\}^\lambda \times \{0,1\}^s \to [-B,B]^n$,
\item $\PRFk: \{0,1\}^\lambda \times \{0,1\}^{s+1} \to \{0,1\}^\lambda$,
\item $\PRFm: \{0,1\}^\lambda \times \{0,1\}^{s+1} \to \{0,1\}^{\lceil\log p\rceil}$ three pseudo-random functions, and
\item $M: \{0,1\}^\lambda \times \{0,1\}^{\lceil\log p\rceil} \to \{0,1\}^\lambda$ a keyed hash function (where we think of the first $\lambda$ bits as the key and the second $\lceil\log p\rceil$ bits as the input).
\end{itemize}

Finally, let $\PK.\seed$ and $\SK.\seed$ be two random seeds; as the names suggest, $\PK.\seed$ is part of the public key, while $\SK.\seed$ is part of the secret key.
Like in Section~\ref{sec:private-key-compress}, we define the secret ideals $\a_m = \prod_{i=1}^n \l_i^{e_{m,i}}$, where $\e_m=\PRFs(\SK.\seed, m)$, and the public curves $E_{A,m}=\a_m*E$, for $0 \le m < 2^s$.

We set up a hash tree by defining $h_{l,u}$ for $0 \le l \le s$ and $0 \le u < 2^{s-l}$.
First we set
\[h_{s,u} = M\bigl( \PRFk(\PK.\seed,2^s+u ),\; j( E_{A,u} ) \oplus \PRFm(\PK.\seed,2^s+u ) \bigr)\]
for $0 \le u < 2^s$, where $\oplus$ denotes bitwise XOR.
Now, for any $0 \le l < s$, the rows of the hash tree are defined as
\[
  h_{l,u} = M\bigl( \PRFk(\PK.\seed, 2^l+u ),\;
  (h_{l+1,2u}\Vert h_{l+1,2u+1}) \oplus \PRFm(\PK.\seed, 2^l+u) \bigr).
\]
Finally, the public key is set to the pair $(\PK.\seed, h_{0,0})$.

To prove that a value $E_{A,u}$ is in the hash tree, we use its \emph{authentication path}.
That is the list of the hash values $h_{l,u'}$, for $1\le l \le s$, occurring as siblings of the nodes on the path from $h_{s,u}$ to the root.
The proof in~\cite[Appendix~B]{10.1007/978-3-662-49384-7_15} shows that having $M$ output $\lambda$-bit hashes gives a (classical) security of approximately $2^\lambda$.
See~\cite{10.1007/978-3-662-49384-7_15,sphincs+} for more details.

Typically, in hash-based signatures the secret key would only contain $\SK.\seed$, since all secret and public values can be reconstructed from it at an acceptable cost.
However, in our case recomputing the leaves of the hash tree ($2^s$ class group actions) is much more expensive than recomputing the internal nodes ($2^s-1$ hash function evaluations), thus we set the secret key to the tuple $(\SK.\seed,h_{s,0},\dots,h_{s,2^s-1})$.
This is a considerably large secret key, e.g., around $1$~MiB when $\lambda=128$ and $s=16$, but it is offset by a more than tenfold gain in signing time.
Also note that the values $h_{s,u}$ can (and will) be leaked without any loss in security, they are indeed part of the uncompressed public key, thus they are more formally treated as auxiliary signer data, rather than as part of the secret key.

To sign we proceed like in Section~\ref{sec:smaller-sigs}, but the signature now needs to contain additional information.
The signer computes the random ideals $\b_1,\dots,\b_t$ and the associated curves $\E_1,\dots,\E_t$ to obtain the challenges $b_1,\dots,b_t$.
Then, using $\PRFs$, they obtain the secrets $\a_{b_1},\dots,\a_{b_t}$, recompute the public curves $E_{A,b_1},\dots,E_{A,b_t}$, and the ideals $\c_i=\a_{b_i}^{-1}\b_i$.
The signature is made of the ideals $\c_1,\dots,\c_t$, the curves $E_{A,b_1},\dots,E_{A,b_t}$, and their authentication paths in the hash tree.
The verifier computes $\E_i$ as $\c_i * E_{A,b_i}$, obtains the challenges $b_1,\dots,b_t$, and uses them to verify the authentication paths.
Hence, the signature contains $t$ ideals represented as vectors in $[-ntB,ntB]^n$, $t$ curves represented by their $j$-invariants, and $t$ authentication paths of length $s$.
The $t$ authentication paths eventually merge before the root, thus some hash values will be repeated.
We can save some space by only sending the hash values once, in some standardised order: the worst case happening when no path merges before level $\log(t)$, no more than $t(s-\log(t))$ hash values need to be sent as part of the signature.
In total, a signature requires at most $t\lceil n \log(2ntB+1)\rceil + t\log(p) + t\lambda(s-\log(t))$ bits.
For our parameters $t=8, s=16$ and $\lambda=128$, this adds about 2~KiB to the signature of Section~\ref{sec:smaller-sigs}.
Note that this is still more than twice smaller than the best stateless hash-based signature schemes (the NIST candidate SPHINCS+~\cite{BHHLNPSSWO15,sphincs+} has size-optimized signatures of 8080 bytes at the NIST security level 1), and is comparable in size to stateful hash-based signatures (e.g., the IETF draft XMSS~\cite[\S~5.3.1]{rfc8391}) and to the shortest known lattice-based signatures.

Concerning security, the proofs of the previous sections, and that of~\cite[Appendix~B]{10.1007/978-3-662-49384-7_15} can be combined to prove the following theorem.

\begin{theorem}
  The signature scheme of this section is unforgeable under a chosen
  message attack under the following assumptions:
  \begin{itemize}
  \item Problem~\ref{defn:one-out-of-2s-problem} is hard;
%The \emph{one out of $2^s$ ideal action} of Definition~\ref{defn:one-out-of-2s-problem};
  \item The \emph{multi-function multi-target second-preimage resistance} of
    the keyed hash function $M$;
  \item The pseudo-randomness of $\PRFs$;
  \end{itemize}
  when the hash function $H$ and the pseudo-random functions $\PRFk$
  and $\PRFm$ are modelled as random oracles (ideal random functions).
\end{theorem}

Like in the previous section, it is possible to replace Problem~\ref{defn:one-out-of-2s-problem} with Problem~\ref{defn:ass1}, modulo some additional assumptions.
Both proofs are straightforward adaptations, and we omit them for conciseness.
As already noted, the proofs are not tight, however the part concerned with the second-preimage resistance of $M$ is.


\section{Performance}


Table~\ref{tab:comparison} gives some estimates of cost for the schemes presented in Sections~\ref{sec:basic-scheme},~\ref{sec:smaller-sigs},~\ref{sec:smaller-keys}.
%, plus the naive and insecure version of Stolbunov's original scheme from Section~\ref{sec:Stolbunov}.
The rows of the table are divided into three sections.

The first section of the table (under the heading ``Exact'') reports the parameter sizes, as a number of bits, already computed in each section, where
$\lambda$ is the security parameter, $n,B$ and $s$ are as described previously (in Section~\ref{sec:basic-scheme} we have $s=1$).
To simplify the expressions we assume that all hash functions have $\lambda$-bit outputs, and we set the parameter $t=\lambda/s$.

In all sections we give a rough lower bound for the performance of the keygen and sign/verify algorithms, in terms of $\F_p$-operations.
The lower bound only takes into account the number of operations needed to compute and evaluate the isogeny path, and so the exact cost may be higher.





\begin{landscape}
  \begin{table}
    \pgfkeys{/pgf/fixed point arithmetic}
    \def\lam{128}
    \def\n{74}
    \def\B{5}
    \def\logp{510}
    \def\s{16}
    \def\CSIDHsecs{0.03}
    \pgfmathtruncatemacro{\t}{\lam / \s}
    % Sig size
    \pgfmathtruncatemacro{\BasSig}{round(\lam * ceil(\n * log2(2*\B + 1)) + \lam) / 8} 
    \pgfmathtruncatemacro{\RejSig}{round(\lam * ceil(\n * log2(2*\n*\lam*\B + 1)) + \lam) / 8}
    \pgfmathtruncatemacro{\ParSig}{round(\t * ceil(\n * log2(2*\n*\t*\B + 1)) + \lam) / 8}
    \pgfmathtruncatemacro{\ComSig}{round(\ParSig + (-\lam + \t * \logp  + \lam * (\lam - \t * log2(\t))) / 8)}
    % PK size
    \pgfmathtruncatemacro{\BasPK}{ceil(\logp / 8)}
    \pgfmathtruncatemacro{\RejPK}{\BasPK}
    \pgfmathtruncatemacro{\ParPK}{round(2^\s * \RejPK / 1024)}
    \pgfmathtruncatemacro{\ComPK}{2 * \lam / 8}
    % SK size
    \pgfmathtruncatemacro{\BasSK}{ceil(\n * log2(2*\B + 1)) / 8}
    \pgfmathtruncatemacro{\RejSK}{\BasSK}
    \pgfmathtruncatemacro{\ParSK}{\lam / 8}
    \pgfmathtruncatemacro{\ComSK}{(2^\s + 1) * \lam / 8 / 1024}
    % keygen time
    \pgfmathsetmacro{\BasKG}{\CSIDHsecs}
    \pgfmathsetmacro{\RejKG}{\BasKG}
    \pgfmathtruncatemacro{\ParKG}{round(2^\s * \BasKG)}
    \pgfmathtruncatemacro{\ComKG}{\ParKG}
    % sig time
    \pgfmathtruncatemacro{\BasTime}{round(\lam * \CSIDHsecs)}
    \pgfmathtruncatemacro{\RejTime}{\n * \lam * \BasTime}
    \pgfmathtruncatemacro{\ParTime}{round(\n * \t^2 * \CSIDHsecs)}
    \pgfmathtruncatemacro{\ComTime}{\ParTime}
    \centering
%    \begin{tabular}{l | c | c | c | c |}
    \begin{tabular}{l | c | c | c |}
%      & Stolbunov scheme (Section~\ref{sec:Stolbunov})
      & Rejection sampling (Section~\ref{sec:sig-reject-sample})
      & Shorter signatures (Section~\ref{sec:smaller-sigs})
      & Smaller public keys (Section~\ref{sec:smaller-keys}) \\
      \hline
%      \hspace{1em}\textbf{Exact} &&&&\\
      \hspace{1em}\textbf{Exact} &&&\\
      Sig size
%      & $\lambda\lceil n\log (2B+1)\rceil + \lambda$
      & $\lambda\lceil n\log (2n\lambda B + 1)\rceil + \lambda$
      & $\frac{\lambda}{s}\lceil n\log (2n\frac{\lambda}{s}B + 1)\rceil + \lambda$
      & $\frac{\lambda}{s}(\lceil n\log (2n\frac{\lambda}{s}B + 1)\rceil + \log p) + \lambda(\lambda-\frac{\lambda}{s}\log\frac{\lambda}{s})$\\
      PK size
%      & $\log p$ & $\log p$ & $2^s\log p$ & $2\lambda$ \\
       & $\log p$ & $2^s\log p$ & $2\lambda$ \\
      SK size
%      & $n\log(2B+1)$ & $n\log(2B+1)$ & $\lambda$ & $(2^s+1) \lambda$\\
       & $n\log(2B+1)$ & $\lambda$ & $(2^s+1) \lambda$\\
%      Performance ($\F_p$-ops) &&&&\\
      Performance ($\F_p$-ops) &&&\\
      $\to$ keygen
%      & $\Omega\bigl(Bn^2\log(n)\bigr)$
      & $\Omega\bigl(Bn^2\log(n)\bigr)$
      & $\Omega\bigl(2^sBn^2\log(n)\bigr)$
      & $\Omega\bigl(2^sBn^2\log(n)\bigr)$\\
      $\to$ sign/verify
%      & $\Omega\bigl(\lambda Bn^2\log(n)\bigr)$
      & $\Omega\bigl(\lambda^2Bn^3\log(n)\bigr)$
      & $\Omega\bigl((\lambda/s)^2Bn^3\log(n)\bigr)$
      & $\Omega\bigl((\lambda/s)^2Bn^3\log(n)\bigr)$\\
      \hline
%      \hspace{1em}\textbf{Asymptotic} &&&&\\
      \hspace{1em}\textbf{Asymptotic} &&&\\
      Sig size
%      & $O(\lambda^2)$ & $O(\lambda^2\log(\lambda))$ & $O((\lambda^2/s)\log(\lambda))$ & $O(\lambda^3/s)$\\
      & $O(\lambda^2\log(\lambda))$ & $O((\lambda^2/s)\log(\lambda))$ & $O(\lambda^3/s)$\\
      PK size
%      & $2\lambda^2$ & $2\lambda^2$ & $2^{s+1}\lambda^2$ & $2\lambda$\\
       & $2\lambda^2$ & $2^{s+1}\lambda^2$ & $2\lambda$\\
      SK size
%      & $3\lambda$ & $3\lambda$ & $\lambda$ & $(2^s+1)\lambda$\\
      & $3\lambda$ & $\lambda$ & $(2^s+1)\lambda$\\
%      Performance (bits) &&&&\\
      Performance (bits) &&&\\
      $\to$ keygen
%      & $\Omega\bigl(\lambda^4\log(\lambda)^2\bigr)$
      & $\Omega\bigl(\lambda^4\log(\lambda)^2\bigr)$
      & $\Omega\bigl(2^s\lambda^4\log(\lambda)^2\bigr)$
      & $\Omega\bigl(2^s\lambda^4\log(\lambda)^2\bigr)$\\
      $\to$ sign/verify
%      & $\Omega\bigl(\lambda^5\log(\lambda)^2\bigr)$
      & $\Omega\bigl(\lambda^7\log(\lambda)^2\bigr)$
      & $\Omega\bigl((\lambda^7/s^2)\log(\lambda)^2\bigr)$
      & $\Omega\bigl((\lambda^7/s^2)\log(\lambda)^2\bigr)$\\
      \hline
      \hspace{1em}\textbf{CSIDH} &&&\\
      Sig size
%      & \BasSig{} B & \RejSig{} B & \ParSig{} B & \ComSig{} B\\
      & \RejSig{} B & \ParSig{} B & \ComSig{} B\\
      PK size
%      & \BasPK{} B & \RejPK{} B & \ParPK{} KiB & \ComPK{} B\\
      & \RejPK{} B & \ParPK{} KiB & \ComPK{} B\\
      SK size
%      & \BasSK{} B & \RejSK{} B & \ParSK{} B & \ComSK{} KiB \\
      & \RejSK{} B & \ParSK{} B & \ComSK{} KiB \\
      Est. keygen time
%      & \BasKG{} s & \RejKG{} s & \ParKG{} s & \ComKG{} s\\
      & \RejKG{} s & \ParKG{} s & \ComKG{} s\\
      Est. verify time
%      & \BasTime{} s & \RejTime{} s & \ParTime{} s & \ComTime{} s
      & \RejTime{} s & \ParTime{} s & \ComTime{} s
    \end{tabular}
    \caption{Parameter size and performance of the various signature
      protocols.
      Parameters taken in the asymptotic analysis are:
      $\log p \sim 2\lambda^2$, $n\log(B)\sim 3\lambda$, $B = O(1)$.
The entry CSIDH is for parameters $(\lambda,n,B,\log(p)) = (128, 74, 5, 510)$ with $(s,t) = (1,128)$ in the first column and $(s,t)=(16,8)$ in the second two columns.
      All logarithms are in base 2.
      Estimated signature time is approximately 3 times the estimated verification time.
    }
    \label{tab:comparison}
  \end{table}
\end{landscape}




The operation count is based on the following estimates.
\begin{enumerate}
\item Based
  on~\cite{10.1007/978-3-319-70697-9_11,10.1007/978-3-319-79063-3_11},
  we estimate that computing/evaluating an isogeny of degree $\ell$, when given a kernel point,
  costs $O(\ell)$ operations.
\item By the prime number theorem $\sum_{i=1}^n\ell_i\sim\frac{1}{2}n^2\ln(n)$, and the estimate is very accurate already for $n>3$.
\end{enumerate}
Putting these estimates together, an ideal with exponent vector within $[-C,C]^n$ can be evaluated in $O(Cn^2\log(n))$ operations on average and in the worst case. We note that the above estimate is not likely to be the dominant part in the computation, especially asymptotically,
as scalar multiplications of elliptic points are likely to dominate.
However, estimating this part of the algorithm is much more complex and dependent on specific optimisations, we thus leave a more precise analysis for future work.

The second section of rows in the table (under the heading ``Asymptotic'') gives asymptotic estimates in terms only of the security parameter $\lambda$, and the parameter of $s$ of Section~\ref{sec:smaller-sigs}.
We now give a brief justification for the parameter restrictions in terms of $\lambda$.
\begin{enumerate}
\item Kuperberg's algorithm is believed to require at least $ 2^{\sqrt{\log(N)}}$ operations in a group of size $N$. In our case $N > \sqrt{p}$. Taking $\log(p) > 2 \lambda^2$ gives 
\[
   \sqrt{ \log(N)} > \sqrt{ \tfrac{1}{2} \log(p) } > \sqrt{ \tfrac{1}{2} 2 \lambda^2 } = \lambda.
\]
So we choose $\log(p) \approx 2 \lambda^2$.

\item 
To resist a classical meet-in-the-middle attack we need $(2B+1)^n > 2^{2 \lambda}$, although the work of Adj \emph{et al.}~\cite{adj+menezes+al-isogenies} suggests this may be too cautious.
For security against Tani's quantum algorithm we may require $(2B+1)^n > 2^{3 \lambda}$, and so $n \log(B) \sim 3 \lambda$, though again this may not be necessary~\cite{cryptoeprint:2019:103}. In any case, we have $n \log(B) = \Omega( \lambda )$.

%The table below states  $n\log B\sim \lambda^2$, which may not be relevant in our situation as we base our security on a different assumption to other works.

%(*** So, do we abandon approximating the uniform distribution or not? This only affects the ``Asymptotic'' part of the table, of course, but then we should say that Theorem 3 does not apply.)

%\item If one is choosing primes of the form $p+1 = 4\prod_{i=1}^n\ell_i$, as in CSIDH~\cite{CLMPR18}, then one is restricted to taking $n$ not too large compared with $p$.
%Approximating $\ell_i \approx n \log(n)$ it follows that $p \approx (n \log(n))^n$ and so we must have $n \log(n) < \log(p)$.
%
%In the table below this is specified as the third condition $n \log(n) \sim 2 \lambda^2$, on the assumption that it is usually appropriate to use as large as possible $n$ in any given situation.

\item Assuming that one wants to optimise for (asymptotic) performance, the best choice is then to take $B=O(1)$ and $n=\Omega(\lambda)$, which means that the prime ideals $\l_i$ have norm $\ell_i = \Omega( n \log(n)) =  \Omega( \lambda \log(\lambda))$. Note that this is compatible with the requirement $\log(p)>2\lambda^2$, since $\sum_{i=1}^n\ln(\ell_i)\sim n\ln(n) \sim \lambda\log(\lambda)^2$.

\item Instead of measuring performance in terms of $\F_p$-operations, here we measure them in terms of bit-operations. After substituting $B$ and $n$, this adds a factor $\lambda^2\log(\lambda)$ in front of the lower bound if using fast (quasi-linear complexity) modular arithmetic.

\end{enumerate}

Note that our asymptotic choices forbid the key space from covering the whole class group.
If the conditions of Problem~\ref{defn:ass1} are wanted, different choices must be made for $n$ and $B$.
In this case it is best to choose primes of the form $p+1 = 4\prod_{i=1}^n\ell_i$, as in CSIDH~\cite{CLMPR18}.
Then, $n\log(n)\sim\log(p)\sim 2\lambda^2$ and so we have  $n \sim \lambda^2 / \log(\lambda)$.
To have a distribution of ideal classes close to uniform we need $(2B+1)^n \gg \sqrt{p}$ and so $\log(B) > \log( \sqrt{p} )/n \sim \log(\lambda)$.
Hence $B > \sqrt{n}$, making all asymptotic bounds considerably worse.

The third block of rows (under the heading ``CSIDH'') gives concrete sizes obtained by fixing $\lambda=128$ and $s=16$ and using the CSIDH-512 primitive, i.e., $(n,B,\log(p)) = (74,5,510)$.
We estimate these parameters to correspond to the NIST-1 security level.
Note that we are able to get smaller signatures at similar cost, for example see the various options in Table~\ref{tab:alt-params} (and one can also potentially consider $s > 16$, such as $(s,t)=(21,6)$).
However, for Table~\ref{tab:comparison} we choose the same parameters as~\cite{CLMPR18} so that we are able to refer to their running-time computations.
We estimate real-world performance, using as baseline the worst-case time for one isogeny action in CSIDH.
In~\cite{CLMPR18,cryptoeprint:2018:782}, for an exponent vector in $[-B,B]^n$, this time is reported to be around $30$ milliseconds.
Accordingly, we multiply this time by the size of the exponent vector to obtain our estimates.
Note that the estimates are very rough, as they purposely ignore other factors such as hash tree computations.
However the results in~\cite{10.1007/978-3-662-49384-7_15,sphincs+} show that hash trees much larger than ours can be computed in a fraction of the time we need to compute isogenies.




\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|} \hline
  $n$ & B & $\lceil \log_2( 2ntB + 1) \rceil$ & Signature size (bytes) \\
\hline
  20 & 3275 & 20 & 416 \\
  28 & 293 & 17 & 492 \\
  33 & 124 & 16 & 544 \\
  37 & 55 & 15 & 571 \\
  46 & 22 & 14 & 660 \\
\hline
\end{tabular}
\end{center}
\caption{Parameter choices for small signatures, with $(s,t)=(16,8)$, at around 128-bit classical security level. Signature size is $nt \lceil \log_2( 2ntB + 1) \rceil + 128$ bits. \label{tab:alt-params}}
\end{table}




%\appendix


\longversion{  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Variants}\label{sec:variants}

One can consider various ideas to get more efficient (i.e., faster signing and verification) or more compact signatures.

\begin{enumerate}
\item Following Stolbunov one could use higher powers for the smaller primes, but it is unclear that this provides any benefit in practice.

%This is definitely worth looking at. We could take $B=1$ for some of the larger primes (e.g., the ones bigger than 50), and then use much larger values for $B$ for the primes $3, 5, 7$ etc. If $B_i$ is the bound used for $\l_i$ then the full key space is $\prod_i (2B_i + 1)$.

%The main problem is that a change to a single $B_i$ makes very little difference to the key size. For example, doubling $B_1$ only adds roughly $+1$ to the logarithm of the product, which is the security parameter.
%Hence the main factor in having a large security parameter is using lots of distinct primes $\l_i$, which automatically means a high cost for signing and verification since almost all $f_{k,i}$ will be non-zero.



\item A natural idea is to sample the exponents $e_i$ from a discrete Gaussian distribution (or perhaps some other distribution), as has been done with lattice signatures. We could hope that this leads to shorter signatures.

Suppose the $e_i$ are sampled from a discrete Gaussian distribution with parameter $\sigma$, so that the standard deviation is close to $\sigma$. The entropy of the continuous Gaussian distribution with standard deviation $\sigma$ is $\log( 2 \pi e \sigma^2 )/2$.
% so we need the $n$-th multiple of this to be larger than the security parameter.

For example, take $n=50$, $s = 16, t = 8$ and choose $\sigma = 5$ (so almost all values $e_{i}$ will lie in $[-15,15]$ but occasionally one is larger than this. Then
\[
   n \log( 2 \pi e \sigma^2 )/2 \approx 218
\]
so determining the $e_i$ using a meet-in-the-middle strategy should require at least $2^{109}$ iterations, and realistically much more than this since organising a search based on the entropy is hard to do. For post-quantum security we might want to replace $2 \lambda$ with $3\lambda$ in the above.

We follow the methods and results of Lyubashevsky~\cite{Lyu12}. Lemma 4.3(3) of~\cite{Lyu12} shows we can bound the norm $\Vert \e \Vert$ by $T = 2 \sigma \sqrt{n}$.
Now we need to choose the $f_{k,i}$ from a discrete Gaussian with parameter $\sigma'$, so that the distribution of $f_{k,i} - e_i$ is close (within statistical distance, though we could probably use Renyi divergence to get better results) to the discrete Gaussian with parameter $\sigma'$.
Lemma 4.6 of~\cite{Lyu12} suggests that $\sigma' = T \sqrt{\log(n)}$ is sufficient, though in practice one usually chooses $\sigma' = \alpha T $ where $\alpha \approx 10$.
In our case we need to apply rejection sampling to all $t$ vectors $\z_k$ simultaneously,
which leads to an additional factor.

For our choices $n=50, t = 8, \sigma = 5$ this gives $\sigma' \approx 3500$.
% (experiments ongoing).
If we use some kind of compact coding of integers distributed as Gaussians~\cite{DDLL13} then signature size would be at best $nt \log_2( 2 \pi e (\sigma')^2 )/2$ bits.
For our example parameters this would be between 7000-8000 bits, or around 1~KiB again.
% More work is needed to work out the exact details and determine the rejection sampling probabilities. 

% TODO: This \item needs updating, esp. regarding concrete parameters below
The best approach seems to be to sample $\e$ \emph{uniformly} with coefficients in $[-B, B]$, while sampling $\f$ from a discrete Gaussian. Taking $n=74, B = 5$ we have $\Vert \e \vert \le T = 24$ with reasonable probability. Taking $\sigma' = 10 \sqrt{t} T \approx 790$ potentially gives signatures of around 800-900 bytes.

In conclusion, the use of discrete Gaussians does not seem to lead to shorter or faster signatures than using uniform distributions. Hence we suggest to use uniform distributions since the implementation of rejection sampling is much simpler and less error-prone.


% TODO: the negative result below is not very interesting, isn't it?
\item One might try to trade-off the size of exponent vectors and the rejection probability. Lemma~\ref{lem:rejection} is about sampling $f_{k,i} \in [ -(nt+1)B, (nt+1)B ]$ and gives probability of acceptance $\approx 1/e \approx 0.368$.
A simple modification of the proof shows that, for any $u > 0$, if one samples $f_{k,i} \in [ -u(nt+1)B, u(nt+1)B ]$ and accepts only those $\z_{k,i} \in [ -untB, untB ]$, then the acceptance probability is approximately $e^{-1/u}$.

Taking $u = 1/2$ roughly halves the time spent on computing $\b_k * E$, but changes the acceptance probability to $e^{-2}  \approx 0.135$; overall this is worse than the original proposal since $2 e^{-2} \approx 0.271 < e^{-1}$.
Similarly, taking $u = 2$ doubles the time spent on computing $\b_k * E$, but changes the acceptance probability to $e^{-1/2} \approx 0.607$; again this is worse on average than our proposal.

Indeed, if $T$ is the cost for $nt$ computations of $\b_k * E$ then the expected cost of signing is $u T e^{1/u}$. Since $f(x) = x e^{1/x}$ is minimised at $x=1$ it follows that taking $u=1$ is the optimal choice.

\end{enumerate}

}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  


\section{Tight security reduction based on lossy keys}\label{sec:lossy-keys}


We now explain how to implement lossy keys in our setting.
This allows us to use the methods of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18} (that build on work of Abdalla, Fouque, Lyubashevsky and Tibouchi~\cite{AFLT12}) to obtain signatures from lossy identification schemes. This approach gives a \emph{tight reduction} in the \emph{quantum random oracle model}.


Here's the basic idea to get a lossy scheme, using uniform distributions for simplicity (one can also use discrete Gaussians in this setting):
Take a very large prime $p$ so that the ideal class group is very large, but use relatively small values for $n$ and $B$ so that $\{ \a = \prod_{i=1}^n \l_i^{e_i} : |e_i| \le B \}$ is a very small subset of the class group.\footnote{It might even be possible to consider working with subgroups, in the quantum algorithm case where the class group structure is known. For example, private keys could be sampled from a large subgroup and lossy keys from a non-trivial coset.}
The real key is $(E, E_A = \a*E )$ for such an $\a$.
The lossy key is $(E, E_A )$ where $E_A$ is a uniformly random curve in the isogeny class.
Further, choose parameters so that the $f_{k,i}$ are also such that $\{ \b = \prod_{i=1}^n \l_i^{f_{k,i}} : |f_{k,i}| \le (nt+1)B \}$ is a small subset of the ideal class group.
In the case of a real key, the signatures define ideals that correspond to ``short'' paths from $E$ or $E_A$ to a  curve $\E$.
In the case of a lossy key, then such ideals do not exist, as for a curve $\E$ it is not the case that there is a short path from $E$ to $\E$ AND a short path from $E_A$ to $\E$.

In the remainder of this section we develop these ideas.


\subsection{Background definitions} \label{sec:KLS-defns}

We closely follow Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}.
A \emph{canonical identification scheme} consists of algorithms $(\IGen, \PP_1, \PP_2, \VV)$ and a set $\ChSet$. The randomised algorithm $\IGen( 1^\lambda )$ outputs a key pair $(pk,sk)$.
The deterministic algorithm $\PP_1$ takes $sk$ and randomness $r_1$ and computes $(W, \St) = \PP_1( sk, r_1 )$. 
Here $\St$ denotes state information to be passed to $\PP_2$.
A challenge $c$ is sampled uniformly from $\ChSet$. The deterministic algorithm $\PP_2$ then computes $Z = \PP_2( sk, W, c, \St, r_2 )$ or $\perp$, where $r_2$ is the randomness.
The output $\perp$ corresponds to an abort in the ``Fiat-Shamir with aborts'' paradigm.
We require that $\VV( pk, W, c, Z ) = 1$ for a correctly formed transcript $(W,c,Z)$.

We assume, for each value of $\lambda$, there are well-defined sets $\Wset$ and $\Zset$, such that $\Wset$ contains all $W$ output by $\PP_1$ and $\Zset$ contains all $Z$ output by $\PP_2$. 
The scheme is \emph{commitment recoverable} if, given $c$ and $Z = \PP_2( sk, W, c, \St )$, there is a unique $W \in \Wset$ such that $\VV( pk, W, c, Z ) = 1$ and this $W$ can be efficiently computed from $(pk, c, Z)$

A canonical identification scheme is $\epsilon_{zk}$-naHVZK \emph{non-abort honest verifier zero knowledge} if there is a simulator that given only $pk$ outputs $(W, c, Z)$ whose distribution has statistical distance at most $\epsilon_{zk}$ from the output distribution of the real protocol conditioned on $\PP_2( sk, W, c, \St, r_2 ) \ne \perp$.

% Don't need this:
% ***We say $W$ has $\alpha$ \emph{bits of min entropy} if the probability any -- not needed to define

A \emph{lossy identification scheme} is a canonical identification scheme as above together with a lossy key generation algorithm $\LossIGen$, which is a randomised algorithm that on input $1^\lambda$ outputs $pk$.
An adversary against a lossy identification scheme is a randomised algorithm $A$ that takes an input $pk$ and returns $0$ or $1$.
\longversion{
The advantage of an adversary against a lossy identification scheme is 
\[
   \Adv^{\textsf{LOSS}}(A) = \left|
   \Pr\left( A( pk ) = 1 : pk \leftarrow \LossIGen(1^\lambda) \right) - \Pr\left( A( pk ) = 1 : pk \leftarrow \IGen( 1^\lambda ) \right) \right|.
\]
}
\shortversion{
The advantage $\Adv^{\textsf{LOSS}}(A)$ of an adversary against a lossy identification scheme is defined to be
\[
\left|   \Pr\left( A( pk ) = 1 : pk \leftarrow \LossIGen(1^\lambda) \right) - \Pr\left( A( pk ) = 1 : pk \leftarrow \IGen( 1^\lambda ) \right) \right|.
\]
}
The two security properties of a lossy identification scheme are:
\begin{enumerate}
\item There is no polynomial-time adversary that has non-negligible advantage $\Adv^{\textsf{LOSS}}$ in distinguishing real and lossy keys.
\item The probability, over $(pk, W, c)$ where $pk$ is an output of the lossy key generation algorithm $\LossIGen$, $W \leftarrow \Wset$ and $c \leftarrow \ChSet$, that there is some $Z \in \Zset$ with $\VV( pk, W, c, Z ) = 1$, is negligible.

This will allow to show that no unbounded quantum adversary can pass the identification protocol (or, once we have applied Fiat-Shamir, forge a signature) with respect to a lossy public key, because with overwhelming probability no such signature exists.
\end{enumerate}


\subsection{Scheme}

We can re-write our scheme in this setting, see Figure~\ref{fig:id-scheme}.
Here we are assuming that $E$ is a supersingular elliptic curve with $j(E) \in \F_p$ where $p$ satisfies the constraint
\begin{equation} \label{eq:lossy-p-bound}
  \sqrt{p} > (4(nt+1)B + 1)^{n} 2^\lambda
\end{equation}
This bound is sufficient for the keys to be lossy.


\begin{figure}
\begin{minipage}{.45\textwidth}
\begin{algorithm}[H]
	\caption{$\IGen$}
%	\caption{KeyGen}
	\textbf{Input:} $B$, $\l_1, \dots, \l_n$, $E$

	\textbf{Output:} $sk =\e$ and $pk = E_A$

	\begin{algorithmic}[1]
		\State $\e \leftarrow [-B,B]^n$ 
		\State $E_A = ( \prod_{i=1}^n \l_i^{e_i} ) * E$
		\State \Return $sk= \e$, $pk = E_A$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{$\PP_1$}
	\textbf{Input:} $(E,E_A)$,  $r_1$

	\textbf{Output:} $W = ( j(\E_1) , \dots, j(\E_t) )$, $\St = (\f_1, \dots, \f_t )$

	\begin{algorithmic}[1]
		\For {$k=1 , \dots , t$}
		\State $\f_k \leftarrow [-(nt+1)B,(nt+1)B]^n$ using $\PRF( r_1 )$
		\State $\E_k = ( \prod_{i=1}^n \l_i^{f_{k,i}} ) * E$
		\EndFor
		\State \Return $( j(\E_1) , \dots, j(\E_t) )$, $(\f_1, \dots, \f_t )$
	\end{algorithmic}
\end{algorithm}
\end{minipage}



\begin{minipage}{0.45\textwidth}
\begin{algorithm}[H]
	\caption{$\PP_2$}
	\textbf{Input:} $(E,E_A)$, $\e$, $W$, $c$, $\St$, $r_2$

	\textbf{Output:} $Z = (\z_1, \dots, \z_t)$

	\begin{algorithmic}[1]
		\State Parse $c$ as $b_1 \Vert \cdots \Vert b_t$
		\For {$k=1, \dots, t$}
		\If{$b_k=0$}
		\State $\z_k = \f_k$
		\Else
		\State $\z_k = \f_k - \e$
		\EndIf
		\If{$\z_{k} \not\in [-ntB,ntB]^n$} \State \Return $\bot$ \EndIf
		\EndFor
		\State \Return $\sigma = (\z_1, \dots, \z_t)$
	\end{algorithmic}
\end{algorithm}
\end{minipage}
 \ \ \ \ \ \ \ \ \ \ \ \ 
\begin{minipage}{0.45\textwidth}
% \vskip -1.2cm
\begin{algorithm}[H]
	\caption{$\VV$}
	\textbf{Input:} $(E,E_A)$, $(W,c,Z)$

	\textbf{Output:} Valid/Invalid

	\begin{algorithmic}[1]
		\State Parse $W$ as $(j_1 , \dots, j_t)$
		\State Parse $c$ as $b_1 \Vert \cdots \Vert b_t$
		\State Parse $Z$ as $(\z_1, \dots, \z_t)$
		\For {$k=1 , \dots , t$}
		\If{$b_k=0$}
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E$
		\Else
		\State $\E_k = ( \prod_{i=1}^n \l_i^{z_{k,i}} ) * E_A$
		\EndIf
		\EndFor
		\If{$(j_1, \dots, j_t) = (j(\E_1) , \dots, j(\E_t))$} \State \Return Valid
		\Else \State \Return Invalid \EndIf
	\end{algorithmic}
\end{algorithm}
\end{minipage}
\caption{The identification protocol. Note that $P_1$ does not need $sk$, while $P_2$ does not use $r_2$ (it really is deterministic) and does not use $W$. Also note that the scheme is commitment recoverable. \label{fig:id-scheme}}
\end{figure}


\shortversion{
We use the generic deterministic signature construction from Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}, and use the fact that signatures can be shortened because the identification protocol is commitment recoverable. We refer to the full version of the paper for details.
}
\longversion{
Now we state the generic deterministic signature construction from Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}:
The key generation and verification algorithms are the same as Figure~\ref{fig:id-scheme}. The signing algorithm is given in Figure~\ref{fig:sign}. 
Since the identification protocol is commitment recoverable, the signatures can be shortened to be $(c, Z )$ instead of $(W,Z)$.

\begin{figure}
\begin{algorithm}[H]
	\caption{Deterministic Signing algorithm}
	\textbf{Input:} $(pk,sk)$, $K$, $\msg$

	\textbf{Output:} $\sigma$

	\begin{algorithmic}[1]
		\State $l = 0$, $Z = \perp$
		\While{$Z = \perp$ and $l \le l_0$}
		\State $(W,\St) = \PP_1( sk, \PRF_K( 0, \msg, l ))$
		\State $c = H( W, \msg )$ 
		\State $Z = \PP_2( sk, W, c, \St, \PRF_K( 1, \msg, l ))$
		\EndWhile
		\If{$Z = \perp$}
		\State \Return $\perp$
		\Else
		\State \Return $(W,Z)$
		\EndIf
	\end{algorithmic}
\end{algorithm}
\caption{The deterministic signature scheme of Kiltz, Lyubashevsky and Schaffner~\cite{KLS18}. Here $K$ is a PRF key that is internal to the signing algorithm and is not required for verification. \label{fig:sign}}
\end{figure}
}

\subsection{Proofs}

We now explain that our identification scheme satisfies the required properties, from which the security of the signature scheme will follow from Theorem 3.1 of~\cite{KLS18}.

We make some heuristic assumptions.
%(I'm not sure if all these are needed)
\begin{description}
\item[Heuristic 1:] There are at least $\sqrt{p}$ supersingular elliptic curves with $j$-invariant in $\F_p$.

This assumption, combined with the bound $\sqrt{p} \gg (4(nt+1)B)^n $ of equation~(\ref{eq:lossy-p-bound}), implies that the curves $\E_k$ constructed by algorithm $\PP_1$ are a negligibly small proportion of all such curves.

\item[Heuristic 2:] Each choice of $\f_k \in [-(nt+1)B,(nt+1)B]^n$ gives a unique value for $j(\E_k)$.

This is extremely plausible given equation~(\ref{eq:lossy-p-bound}). It implies that the min-entropy of the values $W$ output by $\PP_1$ is extremely high (more than sufficient for the security proofs).

%\item[Heuristic 3:] For each choice of $\f_k \in [-(nt+1)B,(nt+1)B]^{2n}$ except $\f_k = 0$, the ideal class of $\prod_{i=1}^n \l_i^{f_{k,i}}$ is non-trivial.
%
%This is also a reasonable assumption given equation~(\ref{eq:lossy-p-bound}).
\end{description}

Under heuristic assumption 1, we now show that the keys are lossy.
The lossy key generator outputs a pair $(E,E_A)$ where $E$ and $E_A$ are randomly sampled supersingular elliptic curves with $j(E), j(E_A) \in \F_p$.
To implement this one constructs a supersingular curve with $j$-invariant in $\F_p$
% using Br{\" o}ker's algorithm~\cite{Bro09} 
and then runs long pseudorandom walks in the isogeny graph until the uniform mixing bounds imply that $E_A$ is uniformly distributed.

\begin{lemma}\label{lem:isogeny count}
Let parameters satisfy the bound of equation~(\ref{eq:lossy-p-bound}) and suppose heuristic 1 holds. Let $(E,E_A)$ be a key output by the lossy key generator. Then with overwhelming probability there is no ideal $\a = \prod_{i=1}^n \l_i^{f_{i}}$ such that $\f \in [-2(nt+1)B,2(nt+1)B]^{n}$ and $j(E_A) = j( \a * E )$.
\end{lemma}

\begin{proof}
If $f_i \in [-2(nt+1)B,2(nt+1)B]$ then there are $4(nt+1)B + 1$ choices for each $f_i$ and so at most $(4 (nt+1)B + 1)^{n}$ choices for $\a$.
Given $E$ it means there are at most that many $j( \a * E )$. Since $E_A$ is uniformly and independently sampled from a set of size at least $\sqrt{p} > (4 (nt+1)B + 1)^{n} 2^\lambda$, the probability that $j(E_A)$ lies in the set of all possible $j( \a * E )$ is at most $1/2^\lambda$, which is negligible. \qed
\end{proof}

% Note to self (Steven): it is not necessary to consider the birthday paradox in the analysis of Lemma~\ref{lem:isogeny count}. Due to the bound of equation~(\ref{eq:lossy-p-bound}), we are sampling curves far from uniformly and so the probability of a collision is not controlled by the birthday paradox.

We consider the following decisional problem.
It is an open challenge to give a ``search to decision'' reduction in this context (showing that if one can solve Problem~\ref{defn:decisional-short-isogeny} then one can solve Problem~\ref{defn:ass1p}). This seems to be non-trivial.

\begin{problem} \label{defn:decisional-short-isogeny}
Consider two distributions on pairs $(E, E_A)$ of supersingular elliptic curves over $\F_p$.
Let $\D_1$ be the output distribution of the algorithm $\IGen$.
Let $\D_2$ be the uniform distribution (i.e., output distribution of the lossy key generation algorithm).
The \emph{decisional short isogeny problem} is to distinguish the two distributions when given one sample.
\end{problem}

The next result shows the second part of the security property for lossy keys.

\begin{lemma}
Assume heuristic 1.
Let $pk$ be an output of the lossy key generation algorithm $\LossIGen$.
Let $W \leftarrow \Wset$ be an output of $\PP_1$.
Let $c \leftarrow \ChSet$ be a uniformly chosen challenge.
Then the probability that there is some $Z \in \Zset$ with $\VV( pk, W, c, Z ) = 1$, is negligible.
\end{lemma}

\begin{proof}
Let $pk = (E, E_A )$ be an output of $\LossIGen( 1^\lambda )$.
By Lemma~\ref{lem:isogeny count} we have that with overwhelming probability $j(E_A) \ne j( \a * E )$ for all ideals $\a$ of the form in Lemma~\ref{lem:isogeny count}.
Let $W = (j(\E_1), \dots, j(\E_t) )$ be an element of $\Wset$, so that each $\E_k$ is of the form $\a_k * E$ where $\a_k = \prod_i \l_i^{f_{k,i}}$ for $f_{k,i} \in [-(nt+1)B, (nt+1)B ]$.


Let $c \leftarrow \ChSet$ be a uniformly chosen challenge, which means that $c \ne 0$ with overwhelming probability.
Then there is some $k$ with $c_k \ne 0$ and so if $Z$ was to satisfy the verification algorithm
$\VV( pk, W, c, Z ) = 1$ then it would follow that $\z_k$ gives an ideal $\c_k$ such that $j(\E_k) = j( \c_k * E_A )$.
From $\a_k * E  \cong \E_k \cong \c_k * E_A$ it follows that $E_A \cong (\c_k^{-1} \a_k ) * E$.
But $\c_k^{-1} \a_k = \prod_i \l_i^{f_{k,i} - z_{k,i}}$, which violates the claim about $E_A$ corresponding to Lemma~\ref{lem:isogeny count}. Hence with overwhelming probability $Z$ does not exist, and the result is proved. \qed
\end{proof}


Note that Heuristic 2 also shows that there are ``unique responses'' in the sense of Definition 2.7 of~\cite{KLS18} (not just computationally unique, but actually unique). But we won't need this for the result we state.


We now discuss \emph{no-abort honest verifier zero-knowledge} (naHVZK).
This is simply the requirement that there is a simulator that produces transcripts $(W,c,Z)$ that are statistically close to real transcripts output by the protocol.


\begin{lemma}
The identification scheme (sigma protocol) of Figure~\ref{fig:id-scheme} has no-abort honest verifier zero-knowledge.
\end{lemma}

\begin{proof}
This is simple to show in our setting (due to the rejection sampling): Instead of choosing $W = ( j( (\prod_i \l_i^{f_{1,i}}) * E) , \dots, j( ( \prod_i \l_i^{f_{k,i}}) * E ))$, then $c$, and then $Z = (\z_1, \dots, \z_k)$ the simulator chooses $Z$ first, then $c$, and then sets, for $1 \le k \le t$, $j_k = j( (\prod_i \l_i^{z_{k,i}}) * E )$ when $c_k=0$ and $j_k = j( (\prod_i \l_i^{z_{k,i}} ) * E_A )$ when $c_k = 1$.
Setting $W = (j_1,\dots, j_k)$ it follows that $(W, c, Z )$ is a transcript that satisfies the verification algorithm.
Further, the distribution of triples $(W,c,Z)$ is identical to the distribution from the real protocol since, for any choice of the private key, this choice of $W$ would have arisen for some choice of the original vectors $\f_k$. \qed
\end{proof}


 

\begin{theorem}
Assume Heuristic 1,  and the hardness of Problem~\ref{defn:ass1p}.
Then the signature scheme (applying Figure~\ref{fig:sign} to Figure~\ref{fig:id-scheme}) has UF-CMA security in the quantum random oracle model, with a tight security reduction.
\end{theorem}
 

\begin{proof}
See Theorem 3.1 of~\cite{KLS18}.
In particular this theorem gives a precise statement of the advantage. \qed
\end{proof}


One can then combine this proof with the optimisations of Sections~\ref{sec:smaller-sigs} and~\ref{sec:smaller-keys}, to get a compact signature scheme with tight post-quantum security based on a merger of the assumptions corresponding to Problems~\ref{defn:one-out-of-2s-problem} and~\ref{defn:decisional-short-isogeny}.




\section{Using the relation lattice}\label{sec:sig-relation-lattice}

This section explains an alternative solution to the problem of representing an ideal class without leaking the private key of the signature scheme.
This variant can be considered if a quantum computer is available during system setup.
Essentially, this is the scheme from Stolbunov's thesis (see Section~\ref{sec:Stolbunov}), which can be used securely once the relation lattice is known.
Note that this section is about signatures that involve sampling ideal classes uniformly and so the techniques can't be used in the lossy keys setting.


Let $( \l_1, \dots, \l_n )$ be a sequence of $\OO$-ideals that generates $\Cl( \OO )$.
Define 
\[
   L = \left\{ (x_1, \dots, x_n ) \in \Z^n : \prod_{i=1}^n \l_i^{x_i} \equiv (1) \right\}.
\]
Then $L$ is a rank $n$ lattice with volume equal to $\#\Cl(\OO)$.
Indeed, we have the exact sequence of Abelian groups
\[
   0 \rightarrow L \rightarrow \Z^n \rightarrow \Cl( \OO ) \rightarrow 1
\]
where the map $f : \Z^n \rightarrow \Cl( \OO )$ is the group homomorphism $(x_1, \dots, x_n) \mapsto \prod_i \l_i^{x_i}$.
We call $L$ the \emph{relation lattice}.

A basis for this lattice can be constructed in subexponential time using classical algorithms~\cite{hafner1989rigorous,biasse_fieker_jacobson_2016}.
However, of interest to us is that a basis can be constructed
in probabilistic polynomial time using quantum algorithms: the function $f:\Z^n\to\Cl(\OO)$ 
%by $f(x_1,\dots,x_n)=\prod_{i=1}^n\l_i^{x_i}$, then $f$ 
defined in the previous paragraph
can be evaluated in polynomial time~\cite{shanks1989gauss,Cohen1993}, and finding a basis for $L=\ker f$ is an instance of the Hidden Subgroup Problem for $\Z^n$, which can be solved in polynomial time using Kitaev's generalisation of Shor's algorithm~\cite{kitaev1995hsp}.
The classical approach is not very interesting since the underlying computational assumption is only subexponentially hard for quantum computers, but it might make sense in a certain setting.
The quantum case would make sense in a post-quantum world where a quantum computer can be used to set up the system parameters for the system and then is not required for further use.
It might also be possible to construct $(E, p )$ such that computing the relation lattice is efficient (e.g., constructing $E$ so that $\Cl( \End(E))$ has smooth order), but we do not consider such approaches in this paper.

For the remainder of this section we assume that the relation lattice is known.
Let $\{ \x_1, \dots, \x_n \}$ be a basis for $L$.
Let $\FF = \{ \sum_{i=1}^n : u_i \x_i : -1/2 \le u_i < 1/2 \}$ be the centred fundamental domain of the basis of $L$.
Then there is a one-to-one correspondence between $\FF \cap \Z^n$ and $\Cl(\OO)$ by
$(z_1, \dots, z_n ) \in \FF \cap \Z^n  \mapsto \prod_{i=1}^n \l_i^{z_i}$.



Returning to Stolbunov's signature scheme, the solution to the problem is then straightforward:
Given $\a = \prod_{i=1}^n \l_i^{e_i}$ and $\b_k = \prod_{i=1}^n \l_i^{f_{k,i}}$,
a representation of $\b_k \a^{-1}$ is obtained by computing the vector $\z' = \f_k - \e$
% = (f_{k,i} - e_i)$
and then using Babai rounding to get the unique vector $\z$ in $\FF \cap (\z' + L )$.
The vector $\z$ is sent as the response to the $k$-th challenge.
Since $\b_k$ is a uniformly chosen ideal class, the class $\b_k \a^{-1}$ is also uniformly distributed as an ideal class, and hence the vector $\z \in \FF \cap \Z^n$ is uniformly distributed and carries no information about the private key.

\begin{lemma}
If $\b_k$ is a uniformly chosen ideal class then the vector 
$\z \in \FF \cap \Z^n$ corresponding to $\f_k - \e$ is uniformly distributed.
\end{lemma}

\begin{proof}
For fixed $\e$ the vector $\z$ depends only on the ideal class of $\b_k$.
But $\b_k$ is uniform and independent of $\e$ and not known to verifier. \qed
\end{proof}



The above discussion fixes a particular fundamental domain and uses Babai rounding to compute an element in it, but this may not lead to the most efficient signature scheme.
One can consider different fundamental domains and different ``reduction'' algorithms to compute $\z$. 
Since the cost of signature verification depends on the size of the entries in $\z$, a natural computational problem is to efficiently compute a short vector $(z_1, \dots, z_n)$ corresponding to a given ideal class; we discuss this problem in the next subsection.



\subsection{Solving close vector problems in the relation lattice}


Let $\w = (w_1, \dots, w_n ) \in \Z^n$ be given and suppose we want to compute the isogeny $\a * E$ where $\a = \prod_{i=1}^n \l_i^{w_i}$. Since the computation of the isogeny depends on the sizes of $|w_i|$ it is natural to first compute a short vector $(z_1, \dots, z_n)$ that represents the same element of $\Z^n / L$.
This can be done by solving a close vector problem in the lattice $L$. 
Namely, if $\v \in L$ is such that $\Vert \w - \v \Vert$ is short, then $\z = \w - \v$ is a short vector that can be used to compute $\a * E$.
Hence, the problem of interest is the close vector problem in the relation lattice.

Note that most literature and algorithms for solving close lattice vector problems are with respect to the Euclidean norm, whereas for isogeny problems the natural norms are the $1$-norm $\Vert \z \Vert_1  = \sum_{i=1}^n | z_i |$ or the $\infty$-norm $\Vert \z \Vert_\infty = \max_i | z_i |$.
The choice of norm depends on how the isogeny is computed. The algorithm for computing $\a * E$ given in~\cite{CLMPR18} depends mostly on the $\infty$-norm, since the V{\'e}lu formulae are used and a block of isogenies are handled together in each iteration.
However, the intuitive cost of the isogeny (and this is appropriate when using modular polynomials to compute the isogenies) is given by the $1$-norm.
If the entries $z_i$ are uniformly distributed in $[ -\Vert \z \Vert_\infty , \Vert \z \Vert_\infty ]$ then we have  $ \Vert \z \Vert_\infty \approx \sqrt{3/n} \Vert \z \Vert_2$ and $\Vert \z \Vert_1 \approx \tfrac{n}{2} \Vert \z \Vert_\infty  \approx \sqrt{3n/4} \Vert \z \Vert_2$.


There are many approaches to solving the close vector problem.
All methods start with pre-processing the lattice using some basis reduction, and in our case one can perform a major precomputation to produce a basis customised for solving close vector problems.
Once the instance $\w$ is provided one can perform one of the following three approaches: the Babai nearest plane method (or an iterative version of it, as done by Lindner and Peikert~\cite{LP11}); enumeration; reducing to SVP (the Kannan embedding technique) and running a basis reduction algorithm.
The choice of method depends on the quality of the original basis, the amount of time available to spend on solving CVP (note that a reduction in the sizes of the $|z_i|$ pays dividends in the time to compute $\a * E$, and so it may be worth to devote more than a few cycles to this problem).

For this paper we focus on the Babai nearest plane algorithm.
Let $\bb_1, \dots, \bb_n$ be the (ordered) reduced lattice basis and $\bb_1^*, \dots, \bb_n^*$ the Gram-Schmidt vectors.
Equation (4.3) of Babai~\cite{Bab86} shows that the nearest plane algorithm on input $\w$ outputs a vector $\v \in L$ with
\begin{equation} \label{eq1}
    \Vert \w -\v \Vert_2^2 \le (\Vert \bb_1^*\Vert_2^2 + \Vert \bb_2^*\Vert_2^2 + \cdots + \Vert \bb_n^*\Vert_2^2 )/4 .
\end{equation}
Bounds on $\Vert \bb_i^* \Vert$ are regularly discussed in the literature. For example, much work on the BKZ algorithm is devoted to understanding the sizes of these vectors; see Gama-Nguyen and Chen-Nguyen~\cite{CN11}.

Fukase and Kashiwabara~\cite{FK15} have discussed lattice reduction algorithms that produce a basis that minimises the right hand size of equation~(\ref{eq1}) and hence are good for solving CVP using the nearest-plane algorithm.
Bl{\"o}mer~\cite{Blo00} has given a variant of the near-plane algorithm that efficiently solves CVP when given a dual-HKZ-reduced basis.


For our calculations we simply consider a BKZ-reduced lattice basis and, following Chen-Nguyen~\cite{CN11}, assume that
\[
   \Vert \bb_i^* \Vert_2 \approx \Vert \bb_1 \Vert_2^{1 - 0.0263(i-1)}.
\]
Some similar calculations are given in~\cite{BS18}.


%One final remark: In the security proof we need to be able to simulate the signing oracle, and hence we need to produce uniformly chosen vectors $\z \in \FF \cap \Z^n$.
%The simplest way to do this is to uniformly sample $\z'$ in a large box in $\Z^n$ and then apply Babai rounding as above.
%It is an open problem to obtain rigorous results about the uniform distribution of ideal classes in this setting.



%\begin{lemma} \label{lem:sim1}
%Let $B \in \N$. Let $\D_1$ be the distribution on ideal classes obtained by computing $\prod_{i=1}^n \l_i^{x_i}$ over uniformly sampled $x_i \in [-B,B]$.
%Suppose the statistical distance between $\D_1$ and the uniform distribution on $\Cl(\OO)$ is bounded by $\epsilon$.
%Let $\D_2$ be the distribution on $\FF \cap \Z^n$ defined by uniformly sampling vectors $\x \in [-B,B]^n$ and applying Babai rounding.
%Let $U$ be the uniform distribution on $\FF \cap \Z^n$.
%Then the statistical distance between $\D_2$ and $U$ is at most $\epsilon$.
%\end{lemma}

% % Note $[-B,B]$ is the set of integers $u$ with $-B \le u \le B$.


%\begin{proof}
%The distribution of ideal classes $\prod_{i=1}^n \l_i^{x_i}$ in $\Cl(\OO)$ is the same as the distribution of vectors in $\FF \cap \Z^n$ obtained by Babai rounding of $\x=(x_1, \dots, x_n)$.
%Hence, if one distribution is close to uniform then so is the other.
%\qed
%\end{proof}


\subsection{Optimal signature size}


We now use an idea that is implicit in the work of Couveignes~\cite{Couv06} and Stolbunov~\cite{Sto12} that gives signatures of optimal size when the relation lattice is known.
%
% he gives a one sentence sketch of a solution that is applicable when the discrete logs of the primes $\l_i$ in the class group are known.
%
Suppose the ideal class group is cyclic of order $N$ and let $\g$ be a generator (whose factorisation over $( \l_1, \dots, \l_n )$ is known).
Then one can choose the private key by uniformly sampling an integer $0 \le x < N$ and letting $\a = \g^x$ in $\Cl(\OO)$.
The public key is $E_A = \a * E$ as before (this computation requires ``smoothing'' the ideal class using the relation lattice).
When signing one chooses the $t$ random ideals $\b_k$ by choosing uniform integers $y_k$ in $[0,N)$ and computing $\b_k = \g^{y_k}$.
As before $\E_k = \b_k * E$.
Finally, in the scheme, when $b_k = 0$ we return $y_k$ and when $b_k = 1$ we return $y_k - x \pmod{N}$.
The verifier just sees a uniformly distributed integer modulo $N$, and uses this to recompute $\E_k$ from either $E$ or $E_A$ (again, this requires reducing a vector modulo the relation lattice and then computing the corresponding isogenies).
This scheme is clearly optimal from the point of view of signature size, since one cannot represent a random element of a group of order $N$ in fewer than $\log_2(N)$ bits.

The method used to compute the isogenies during verification is left for the verifier to decide.
In practice all users will work with the same prime $p$ (e.g., the 512-bit CSIDH prime) in which case the relation lattice can be precomputed and optimised. 
The verifier then solves the CVP instances using their preferred method and then computes the isogenies.

\shortversion{The full version of the paper contains a table of parameters for this scheme.}

\longversion{  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

One can then prove a variant of Theorem~\ref{thm:security-basic} and adapt the optimisations of Sections~\ref{sec:smaller-sigs} and~\ref{sec:smaller-keys}. 
This approach gives rise to smaller signatures, and much faster signature and verification times: in terms of the security parameter $\lambda$ the size gain is logarithmic gain, while the performance gain is quadratic.
Public/private key sizes and key generation time are unaffected.
We summarise the obtained parameters and expected performance in Table~\ref{tab:stolbunov}, using the same conventions as in Table~\ref{tab:comparison}; we only report data on signature size and sign/verify performance, and we refer to Table~\ref{tab:comparison} for the other (unchanged) entries.


\begin{table}
  \pgfkeys{/pgf/fixed point arithmetic}
  \def\lam{128}
  \def\n{74}
  \def\B{15}
  \def\logp{510}
  \def\s{16}
  \def\CSIDHsecs{0.1}
  \pgfmathtruncatemacro{\t}{\lam / \s}
  % Sig size
  \pgfmathtruncatemacro{\StoSig}{round(\lam * ceil(\n * log2(2*\B + 1)) + \lam) / 8}
  \pgfmathtruncatemacro{\ParSig}{round(\logp + \lam) / 8}
  \pgfmathtruncatemacro{\ComSig}{round(\ParSig + (-\lam + \t * \logp  + \lam * (\lam - \t * log2(\t))) / 8)}
  % sig time
  \pgfmathtruncatemacro{\StoTime}{round(\lam * \CSIDHsecs)}
  \pgfmathtruncatemacro{\ParTime}{\t * \CSIDHsecs * 3}
  \pgfmathtruncatemacro{\ComTime}{\ParTime}
  \centering
  \begin{tabular}{l | c | c | c |}
    & Stolbunov scheme
    & Shorter signatures
    & Smaller public keys\\
    \hline
    \hspace{1em}\textbf{Exact} &&&\\
    Sig size
    & $\lambda\lceil n\log (2B+1)\rceil + \lambda$
    & $\frac{\lambda}{s}\lceil n\log (2B+1)\rceil + \lambda$
    & $\frac{\lambda}{s}(\lceil n\log (2B+1)\rceil + \log p) + \lambda(\lambda-\frac{\lambda}{s}\log\frac{\lambda}{s})$\\
    Performance ($\F_p$-ops)
    & $\Omega\bigl(\lambda Bn^2\log(n)\bigr)$
    & $\Omega\bigl((\lambda/s)Bn^2\log(n)\bigr)$
    & $\Omega\bigl((\lambda/s)Bn^2\log(n)\bigr)$\\
    \hline
    \hspace{1em}\textbf{Asymptotic} &&&\\
    Sig size
    & $O(\lambda^2)$ & $O(\lambda^2/s)$ & $O(\lambda^3/s)$\\
    Performance (bits)
    & $\Omega\bigl(\lambda^5\log(\lambda)^2\bigr)$
    & $\Omega\bigl((\lambda^5/s)\log(\lambda)^2\bigr)$
    & $\Omega\bigl((\lambda^5/s)\log(\lambda)^2\bigr)$\\
    \hline
    \hspace{1em}\textbf{CSIDH} &&&\\
    Sig size             & \StoSig{} B & \ParSig{} B & \ComSig{} B\\
    Est. verify time & \StoTime{} s & \ParTime{} s & \ComTime{} s
  \end{tabular}
  \caption{Signature size and sign/verify performance of Stolbunov's
    protocol, when combined with the variants of
    Sections~\ref{sec:smaller-sigs} and~\ref{sec:smaller-keys}.  The
    conventions are the same as in Table~\ref{tab:comparison}:
    $\log p \sim 2\lambda^2$, $n\log(B)\sim 3\lambda$, $B = O(1)$ for
    asymptotic analysis,
    $(\lambda,n,\log(p)) = (128, 74, 510)$ with
    $(s,t) = (1,128)$ or $(16,8)$ for the CSIDH entry.  All logarithms
    are in base 2.}
  \label{tab:stolbunov}
\end{table}


}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}


We have given a signature scheme suitable for the CSIDH isogeny setting.
This solves an unresolved problem in Stolbunov's thesis.
We have also shown how to get shorter signatures by increasing the public key size.
We do not know how to obtain a similar trade-off between public key size and signature size for the schemes of Yoo \emph{et al.}~\cite{YAJJS17} or Galbraith \emph{et al.}~\cite{GPS17} based on the SIDH setting.


\section*{Acknowledgements}

Thanks to Samuel Dobson for doing some experiments with discrete Gaussians.
 Thanks to Lorenz Panny for comments and suggestions.
Thanks to Damien Stehl{\'{e}} for references about solving close vector problems.
Thanks to the Eurocrypt referees for their careful reading of the paper.


Luca De Feo was supported by the French \emph{Programme
  d'Investissements d'Avenir} under the national project RISQ
n\textsuperscript{o} P141580-3069086/DOS0044212.



\bibliographystyle{splncs04}
\bibliography{biblio}




\end{document}
